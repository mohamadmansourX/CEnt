{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Carla_New_git.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4_lPGM0Cof6V",
        "gORUyJ9X9joX"
      ],
      "mount_file_id": "1KyBMkcB7Nq2KKnIzYra1oi5OBNaQaVpJ",
      "authorship_tag": "ABX9TyM4NQUnUhM6VnXm58/deeBd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "20a56e4db7144b168b251af410b26916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a97d3d731ae54e5286dece9a4fdcbd2f",
              "IPY_MODEL_98b1667e11414cc59556fc18ecd31e9b",
              "IPY_MODEL_7054be177e7142c7b9d7720dc04956be"
            ],
            "layout": "IPY_MODEL_bd50dd3065144316aebe7cad9ece3fa5"
          }
        },
        "a97d3d731ae54e5286dece9a4fdcbd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dad21ba5e9840dfb9035151318b7624",
            "placeholder": "​",
            "style": "IPY_MODEL_1e3c962a81334bc18ba7ca2ce039a47c",
            "value": "100%"
          }
        },
        "98b1667e11414cc59556fc18ecd31e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ab73af5fff144a6b40c0c94c599f91e",
            "max": 60000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4d8513da93d4982a6405fb5f18e6583",
            "value": 60000
          }
        },
        "7054be177e7142c7b9d7720dc04956be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1016e422f2444a028d8a8f934261a177",
            "placeholder": "​",
            "style": "IPY_MODEL_c90fab67bd9047a9a67ac0c01f35ae72",
            "value": " 60000/60000 [00:17&lt;00:00, 3532.10it/s]"
          }
        },
        "bd50dd3065144316aebe7cad9ece3fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dad21ba5e9840dfb9035151318b7624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e3c962a81334bc18ba7ca2ce039a47c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ab73af5fff144a6b40c0c94c599f91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d8513da93d4982a6405fb5f18e6583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1016e422f2444a028d8a8f934261a177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90fab67bd9047a9a67ac0c01f35ae72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ff840674aad4742be61a6caccd138a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e149c530397649f886bdc33b4aa179aa",
              "IPY_MODEL_af57ce72a1164f80ac1f216d032b1f0c",
              "IPY_MODEL_5af6624ac2ae454991fb6259a560a87a"
            ],
            "layout": "IPY_MODEL_d65cb059e67141aba0b20f2627dbd6e3"
          }
        },
        "e149c530397649f886bdc33b4aa179aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f5fbc52b7bd478bad14bd3fdf77a810",
            "placeholder": "​",
            "style": "IPY_MODEL_ba6471dd3f074005abc50db015ad40dd",
            "value": "100%"
          }
        },
        "af57ce72a1164f80ac1f216d032b1f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1b78be17cdd42d9bd47577ce69a785f",
            "max": 60000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d0bbdbcf29c404ba3629a86c34ad4e4",
            "value": 60000
          }
        },
        "5af6624ac2ae454991fb6259a560a87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ac3fb337d7548428767be7af9931402",
            "placeholder": "​",
            "style": "IPY_MODEL_c2ee438ce1084467972d5541cea44ecf",
            "value": " 60000/60000 [00:28&lt;00:00, 1890.00it/s]"
          }
        },
        "d65cb059e67141aba0b20f2627dbd6e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f5fbc52b7bd478bad14bd3fdf77a810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba6471dd3f074005abc50db015ad40dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1b78be17cdd42d9bd47577ce69a785f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d0bbdbcf29c404ba3629a86c34ad4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ac3fb337d7548428767be7af9931402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ee438ce1084467972d5541cea44ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamadmansourX/TreeBased_Carla/blob/main/CEM_MNIST_Carla_New_git.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations"
      ],
      "metadata": {
        "id": "dBWxFq8njvIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pynndescent==0.5.7 -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNwO0ece2spO",
        "outputId": "f85aad26-1f92-44e7-e6da-beda57629828"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 573 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 583 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 593 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 604 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 614 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 624 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 634 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 645 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 655 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 665 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 675 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 686 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 696 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 706 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 716 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 727 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 737 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 747 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 757 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 768 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 778 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 788 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 798 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 808 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 819 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 829 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 839 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 849 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 860 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 870 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 880 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 890 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 901 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 911 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 921 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 931 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 942 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 952 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 962 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 972 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 983 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 993 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s \n",
            "\u001b[?25h  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree('/content/TreeBased_Carla')"
      ],
      "metadata": {
        "id": "riGiEFr7n4AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk8sb__tGjM6",
        "outputId": "265d152e-231d-46d4-b66c-0803018fced5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'TreeBased_Carla'...\n",
            "remote: Enumerating objects: 718, done.\u001b[K\n",
            "remote: Counting objects: 100% (718/718), done.\u001b[K\n",
            "remote: Compressing objects: 100% (590/590), done.\u001b[K\n",
            "remote: Total 718 (delta 203), reused 587 (delta 108), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (718/718), 8.76 MiB | 13.08 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://<PAT>@github.com/<username>/TreeBased_Carla.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/TreeBased_Carla"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeSpmrAIG7PF",
        "outputId": "b85988b6-db76-46ec-f336-52ebda4c6294"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TreeBased_Carla\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "echo \"\"\"pip install -U pip setuptools wheel -q\n",
        "pip install -e . -q\n",
        "\"\"\" > mm_bash_setup.sh"
      ],
      "metadata": {
        "id": "_zHXgpeMG7T6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash mm_bash_setup.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "264ZRhdkG7WM",
        "outputId": "5a998fa2-00dc-4d8b-f383-58ef8e3d7516"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 48.0 MB/s \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.3/109.3 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.7/776.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.0/224.0 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.6/377.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.0/297.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.5/488.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.7/381.7 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.4 which is incompatible.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.7.0 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.30 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n",
            "fastai 2.7.7 requires torchvision>=0.8.2, but you have torchvision 0.8.1 which is incompatible.\n",
            "cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.19.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''!pip uninstall pandas -y\n",
        "!pip install pandas==1.3.5 -q'''"
      ],
      "metadata": {
        "id": "Njk26HLCG7Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pynndescent==0.5.7 -q\n",
        "!pip install scipy==1.4.1 -q\n",
        "!pip install scikit_learn==1.4.1 -q\n",
        "!pip install setuptools==57.4.0 -q"
      ],
      "metadata": {
        "id": "ZmX3e_e2G7RY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f24ade-392b-44c3-c9e1-a3e8a57fc006"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.4 which is incompatible.\n",
            "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.4.1 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\n",
            "jaxlib 0.3.14+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.14 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "fastai 2.7.7 requires torchvision>=0.8.2, but you have torchvision 0.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 1.1.0 Requires-Python >=3.8; 1.1.0rc1 Requires-Python >=3.8; 1.1.1 Requires-Python >=3.8; 1.1.2 Requires-Python >=3.8\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scikit_learn==1.4.1 (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0b1, 0.15.0b2, 0.15.0, 0.15.1, 0.15.2, 0.16b1, 0.16.0, 0.16.1, 0.17b1, 0.17, 0.17.1, 0.18, 0.18.1, 0.18.2, 0.19b2, 0.19.0, 0.19.1, 0.19.2, 0.20rc1, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21rc2, 0.21.0, 0.21.1, 0.21.2, 0.21.3, 0.22rc2.post1, 0.22rc3, 0.22, 0.22.1, 0.22.2, 0.22.2.post1, 0.23.0rc1, 0.23.0, 0.23.1, 0.23.2, 0.24.dev0, 0.24.0rc1, 0.24.0, 0.24.1, 0.24.2, 1.0rc1, 1.0rc2, 1.0, 1.0.1, 1.0.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for scikit_learn==1.4.1\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.22.0 which is incompatible.\n",
            "fastai 2.7.7 requires torchvision>=0.8.2, but you have torchvision 0.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements-dev.txt -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8EeUGeAhxst",
        "outputId": "f7b27ef2-c0ed-4465-e521-56c9ef5888d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.4 which is incompatible.\n",
            "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.6.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "fastai 2.7.7 requires torchvision>=0.8.2, but you have torchvision 0.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pynndescent"
      ],
      "metadata": {
        "id": "9ZhOI-CoI7Ru"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/TreeBased_Carla\n",
        "import shutil\n",
        "shutil.rmtree('outputs')"
      ],
      "metadata": {
        "id": "JCVTHjxwmFVP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "4cd512e9-e883-4c52-e7e8-cb0791786da6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TreeBased_Carla\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-276761f63b53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd /content/TreeBased_Carla'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# lstat()/open()/fstat() trick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python becnhmark_experiment.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpC-pjz1ojC_",
        "outputId": "22124752-8593-4613-cb7c-b19e80cf4ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend.\n",
            "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n",
            "[INFO] NumExpr defaulting to 2 threads. [utils.py _init_num_threads]\n",
            "['cote', 'dice', 'growing_spheres', 'clue', 'causal_recourse', 'cchvae', 'cruds', 'focus', 'actionable_recourse', 'cem', 'revisewachter', 'face', 'feature_tweak']\n",
            "######################################################################\n",
            "Starting experiment for dataset adult\n",
            "######################################################################\n",
            "\n",
            "Loading models... --- logs will be saved to ./outputs/adult/models_logs.txt\n",
            "Starting VAE for benchmarking\n",
            "    myvae_params : \n",
            "         input_dim : 13\n",
            "         kld_weight : 0.00025\n",
            "         layers : [25]\n",
            "         latent_dim : 8\n",
            "         hidden_activation : relu\n",
            "         dropout : 0.2\n",
            "         batch_norm : True\n",
            "         batch_size : 32\n",
            "         epochs : 20\n",
            "         learning_rate : 0.001\n",
            "         weight_decay : 0.0\n",
            "         cuda : False\n",
            "         verbose : True\n",
            "         train : True\n",
            "         save_dir : ./vae_model/\n",
            "{'input_dim': 13, 'kld_weight': 0.00025, 'layers': [25], 'latent_dim': 8, 'hidden_activation': 'relu', 'dropout': 0.2, 'batch_norm': True, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001, 'weight_decay': 0.0, 'cuda': False, 'verbose': True, 'train': True, 'save_dir': './vae_model/'}\n",
            "./vae_model/adult\n",
            "Epoch: 0, ELBO Loss: 34.72982406616211, Test MSELoss: 16.001251220703125\n",
            "Epoch: 0, Best ELBO Loss: 34.72982406616211\n",
            "Epoch: 1, ELBO Loss: 13.519771575927734, Test MSELoss: 12.110159873962402\n",
            "BEST Epoch: 1, Best ELBO Loss: 13.519771575927734\n",
            "Epoch: 2, ELBO Loss: 11.476521492004395, Test MSELoss: 10.941570281982422\n",
            "BEST Epoch: 2, Best ELBO Loss: 11.476521492004395\n",
            "Epoch: 3, ELBO Loss: 10.797196388244629, Test MSELoss: 10.350683212280273\n",
            "BEST Epoch: 3, Best ELBO Loss: 10.797196388244629\n",
            "Epoch: 4, ELBO Loss: 10.249598503112793, Test MSELoss: 10.227388381958008\n",
            "BEST Epoch: 4, Best ELBO Loss: 10.249598503112793\n",
            "Epoch: 5, ELBO Loss: 9.95100212097168, Test MSELoss: 9.867229461669922\n",
            "BEST Epoch: 5, Best ELBO Loss: 9.95100212097168\n",
            "Epoch: 6, ELBO Loss: 9.946008682250977, Test MSELoss: 9.771702766418457\n",
            "BEST Epoch: 6, Best ELBO Loss: 9.946008682250977\n",
            "Epoch: 7, ELBO Loss: 9.8098783493042, Test MSELoss: 9.793225288391113\n",
            "BEST Epoch: 7, Best ELBO Loss: 9.8098783493042\n",
            "Epoch: 8, ELBO Loss: 9.769009590148926, Test MSELoss: 9.789472579956055\n",
            "BEST Epoch: 8, Best ELBO Loss: 9.769009590148926\n",
            "Epoch: 9, ELBO Loss: 9.863548278808594, Test MSELoss: 9.770635604858398\n",
            "Epoch: 10, ELBO Loss: 9.702892303466797, Test MSELoss: 9.659040451049805\n",
            "BEST Epoch: 10, Best ELBO Loss: 9.702892303466797\n",
            "Epoch: 11, ELBO Loss: 9.691383361816406, Test MSELoss: 9.705284118652344\n",
            "BEST Epoch: 11, Best ELBO Loss: 9.691383361816406\n",
            "Epoch: 12, ELBO Loss: 9.705540657043457, Test MSELoss: 9.73548698425293\n",
            "Epoch: 13, ELBO Loss: 9.763699531555176, Test MSELoss: 9.521398544311523\n",
            "Epoch: 14, ELBO Loss: 9.639328002929688, Test MSELoss: 9.745467185974121\n",
            "BEST Epoch: 14, Best ELBO Loss: 9.639328002929688\n",
            "Epoch: 15, ELBO Loss: 9.734818458557129, Test MSELoss: 9.67697811126709\n",
            "Epoch: 16, ELBO Loss: 9.651959419250488, Test MSELoss: 9.772038459777832\n",
            "Epoch: 17, ELBO Loss: 9.660207748413086, Test MSELoss: 9.625574111938477\n",
            "Epoch: 18, ELBO Loss: 9.717869758605957, Test MSELoss: 9.65811824798584\n",
            "Epoch: 19, ELBO Loss: 9.681147575378418, Test MSELoss: 9.64972972869873\n",
            "Figure(1000x500)\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cote\n",
            "\n",
            "\n",
            "    data_name : data_name\n",
            "    n_search_samples : 300\n",
            "    p_norm : 1\n",
            "    step : 0.1\n",
            "    max_iter : 10\n",
            "    clamp : True\n",
            "    binary_cat_features : True\n",
            "    myvae_params : \n",
            "         input_dim : 13\n",
            "         kld_weight : 0.00025\n",
            "         layers : [25]\n",
            "         latent_dim : 8\n",
            "         hidden_activation : relu\n",
            "         dropout : 0.2\n",
            "         batch_norm : True\n",
            "         batch_size : 32\n",
            "         epochs : 10\n",
            "         learning_rate : 0.001\n",
            "         weight_decay : 0.0\n",
            "         cuda : False\n",
            "         verbose : True\n",
            "         train : True\n",
            "         save_dir : ./vae_model/\n",
            "    tree_params : \n",
            "         min_entries_per_label : 975\n",
            "         grid_search_jobs : -1\n",
            "         min_weight_gini : 100\n",
            "         max_search : 100\n",
            "         grid_search : \n",
            "              cv : 1\n",
            "              splitter : ['best']\n",
            "              criterion : ['gini']\n",
            "              max_depth : [3, 4, 5, 6, 7, 8, 9, 10]\n",
            "              min_samples_split : [1.0, 2, 3]\n",
            "              min_samples_leaf : [1, 2, 3]\n",
            "              max_features : [0.4, 0.6, 0.8]\n",
            "{'input_dim': 13, 'kld_weight': 0.00025, 'layers': [25], 'latent_dim': 8, 'hidden_activation': 'relu', 'dropout': 0.2, 'batch_norm': True, 'batch_size': 32, 'epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'cuda': False, 'verbose': True, 'train': True, 'save_dir': './vae_model/'}\n",
            "./vae_model/adult\n",
            "Epoch: 0, ELBO Loss: 32.51565170288086, Test MSELoss: 14.448325157165527\n",
            "Epoch: 0, Best ELBO Loss: 32.51565170288086\n",
            "Epoch: 1, ELBO Loss: 12.957364082336426, Test MSELoss: 12.059304237365723\n",
            "BEST Epoch: 1, Best ELBO Loss: 12.957364082336426\n",
            "Epoch: 2, ELBO Loss: 11.311707496643066, Test MSELoss: 10.96855354309082\n",
            "BEST Epoch: 2, Best ELBO Loss: 11.311707496643066\n",
            "Epoch: 3, ELBO Loss: 10.620694160461426, Test MSELoss: 10.226024627685547\n",
            "BEST Epoch: 3, Best ELBO Loss: 10.620694160461426\n",
            "Epoch: 4, ELBO Loss: 10.283780097961426, Test MSELoss: 10.079082489013672\n",
            "BEST Epoch: 4, Best ELBO Loss: 10.283780097961426\n",
            "Epoch: 5, ELBO Loss: 10.045452117919922, Test MSELoss: 9.94314956665039\n",
            "BEST Epoch: 5, Best ELBO Loss: 10.045452117919922\n",
            "Epoch: 6, ELBO Loss: 9.94941234588623, Test MSELoss: 9.825261116027832\n",
            "BEST Epoch: 6, Best ELBO Loss: 9.94941234588623\n",
            "Epoch: 7, ELBO Loss: 9.798535346984863, Test MSELoss: 9.833724975585938\n",
            "BEST Epoch: 7, Best ELBO Loss: 9.798535346984863\n",
            "Epoch: 8, ELBO Loss: 9.8410005569458, Test MSELoss: 9.662520408630371\n",
            "Epoch: 9, ELBO Loss: 9.835465431213379, Test MSELoss: 9.652071952819824\n",
            "DT Warming Up...\n",
            "{'criterion': 'gini', 'max_depth': 7, 'max_features': 0.8, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "    data_name : data_name\n",
            "    n_search_samples : 300\n",
            "    p_norm : 1\n",
            "    step : 0.1\n",
            "    max_iter : 10\n",
            "    clamp : True\n",
            "    binary_cat_features : True\n",
            "    myvae_params : \n",
            "         input_dim : 13\n",
            "         kld_weight : 0.00025\n",
            "         layers : [25]\n",
            "         latent_dim : 8\n",
            "         hidden_activation : relu\n",
            "         dropout : 0.2\n",
            "         batch_norm : True\n",
            "         batch_size : 32\n",
            "         epochs : 10\n",
            "         learning_rate : 0.001\n",
            "         weight_decay : 0.0\n",
            "         cuda : False\n",
            "         verbose : True\n",
            "         train : True\n",
            "         save_dir : ./vae_model/\n",
            "    tree_params : \n",
            "         min_entries_per_label : 975\n",
            "         grid_search_jobs : -1\n",
            "         min_weight_gini : 100\n",
            "         max_search : 100\n",
            "         grid_search : \n",
            "              cv : 1\n",
            "              splitter : ['best']\n",
            "              criterion : ['gini']\n",
            "              max_depth : [3, 4, 5, 6, 7, 8, 9, 10]\n",
            "              min_samples_split : [1.0, 2, 3]\n",
            "              min_samples_leaf : [1, 2, 3]\n",
            "              max_features : [0.4, 0.6, 0.8]\n",
            "{'input_dim': 13, 'kld_weight': 0.00025, 'layers': [25], 'latent_dim': 8, 'hidden_activation': 'relu', 'dropout': 0.2, 'batch_norm': True, 'batch_size': 32, 'epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'cuda': False, 'verbose': True, 'train': True, 'save_dir': './vae_model/'}\n",
            "./vae_model/adult\n",
            "Epoch: 0, ELBO Loss: 35.32400894165039, Test MSELoss: 15.76980972290039\n",
            "Epoch: 0, Best ELBO Loss: 35.32400894165039\n",
            "Epoch: 1, ELBO Loss: 14.00074291229248, Test MSELoss: 12.778131484985352\n",
            "BEST Epoch: 1, Best ELBO Loss: 14.00074291229248\n",
            "Epoch: 2, ELBO Loss: 11.81933879852295, Test MSELoss: 11.047590255737305\n",
            "BEST Epoch: 2, Best ELBO Loss: 11.81933879852295\n",
            "Epoch: 3, ELBO Loss: 10.789068222045898, Test MSELoss: 10.389669418334961\n",
            "BEST Epoch: 3, Best ELBO Loss: 10.789068222045898\n",
            "Epoch: 4, ELBO Loss: 10.360299110412598, Test MSELoss: 10.165364265441895\n",
            "BEST Epoch: 4, Best ELBO Loss: 10.360299110412598\n",
            "Epoch: 5, ELBO Loss: 10.211774826049805, Test MSELoss: 9.931077003479004\n",
            "BEST Epoch: 5, Best ELBO Loss: 10.211774826049805\n",
            "Epoch: 6, ELBO Loss: 10.154069900512695, Test MSELoss: 9.824923515319824\n",
            "BEST Epoch: 6, Best ELBO Loss: 10.154069900512695\n",
            "Epoch: 7, ELBO Loss: 9.979416847229004, Test MSELoss: 9.889720916748047\n",
            "BEST Epoch: 7, Best ELBO Loss: 9.979416847229004\n",
            "Epoch: 8, ELBO Loss: 9.938798904418945, Test MSELoss: 9.815783500671387\n",
            "BEST Epoch: 8, Best ELBO Loss: 9.938798904418945\n",
            "Epoch: 9, ELBO Loss: 9.893542289733887, Test MSELoss: 9.842004776000977\n",
            "BEST Epoch: 9, Best ELBO Loss: 9.893542289733887\n",
            "DT Warming Up...\n",
            "{'criterion': 'gini', 'max_depth': 5, 'max_features': 0.8, 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method dice\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method growing_spheres\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method clue\n",
            "\n",
            "\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] \n",
            "Network: [train.py train_VAE]\n",
            "[INFO] \n",
            "Train: [train.py train_VAE]\n",
            "[INFO] init cost variables: [train.py train_VAE]\n",
            "[INFO] it 0/1, vlb -10.241698,  [train.py train_VAE]\n",
            "[INFO] time: 6.690467 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] vlb -2.825338 (-inf)\n",
            " [train.py train_VAE]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_adult_models/theta_best.dat\n",
            " [utils.py save]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_adult_models/theta_last.dat\n",
            " [utils.py save]\n",
            "[INFO] average time: 7.354111 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "RESULTS: [train.py train_VAE]\n",
            "[INFO] best_vlb_dev: -2.825338 [train.py train_VAE]\n",
            "[INFO] best_vlb_train: -10.241698 [train.py train_VAE]\n",
            "[INFO] nb_parameters: 1237 (1.21KB)\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] Reading /root/carla/models/autoencoders/clue/fc_VAE_adult_models/theta_best.dat\n",
            " [utils.py load]\n",
            "[INFO] restoring epoch: 1, lr: 0.001000 [utils.py load]\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] \n",
            "Network: [train.py train_VAE]\n",
            "[INFO] \n",
            "Train: [train.py train_VAE]\n",
            "[INFO] init cost variables: [train.py train_VAE]\n",
            "[INFO] it 0/1, vlb -10.241698,  [train.py train_VAE]\n",
            "[INFO] time: 6.698150 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] vlb -2.825338 (-inf)\n",
            " [train.py train_VAE]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_adult_models/theta_best.dat\n",
            " [utils.py save]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_adult_models/theta_last.dat\n",
            " [utils.py save]\n",
            "[INFO] average time: 7.283839 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "RESULTS: [train.py train_VAE]\n",
            "[INFO] best_vlb_dev: -2.825338 [train.py train_VAE]\n",
            "[INFO] best_vlb_train: -10.241698 [train.py train_VAE]\n",
            "[INFO] nb_parameters: 1237 (1.21KB)\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] Reading /root/carla/models/autoencoders/clue/fc_VAE_adult_models/theta_best.dat\n",
            " [utils.py load]\n",
            "[INFO] restoring epoch: 1, lr: 0.001000 [utils.py load]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method causal_recourse\n",
            "\n",
            "\n",
            "Exception for causal_recourse\n",
            "\n",
            "Exception for causal_recourse\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cchvae\n",
            "\n",
            "\n",
            "[INFO] Start training of Variational Autoencoder... [vae.py fit]\n",
            "[INFO] [Epoch: 0/5] [objective: 3.188] [vae.py fit]\n",
            "[INFO] [ELBO train: 3.188] [vae.py fit]\n",
            "[INFO] [ELBO train: 0.575] [vae.py fit]\n",
            "[INFO] [ELBO train: 0.467] [vae.py fit]\n",
            "[INFO] [ELBO train: 0.388] [vae.py fit]\n",
            "[INFO] [ELBO train: 0.257] [vae.py fit]\n",
            "[INFO] ... finished training of Variational Autoencoder. [vae.py fit]\n",
            "[INFO] Start training of Variational Autoencoder... [vae.py fit]\n",
            "[INFO] [Epoch: 0/5] [objective: 12.334] [vae.py fit]\n",
            "[INFO] [ELBO train: 12.334] [vae.py fit]\n",
            "[INFO] [ELBO train: 6.85] [vae.py fit]\n",
            "[INFO] [ELBO train: 6.793] [vae.py fit]\n",
            "[INFO] [ELBO train: 6.469] [vae.py fit]\n",
            "[INFO] [ELBO train: 6.145] [vae.py fit]\n",
            "[INFO] ... finished training of Variational Autoencoder. [vae.py fit]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cruds\n",
            "\n",
            "\n",
            "[INFO] Start training of CSVAE... [csvae.py fit]\n",
            "  0% 0/5 [00:00<?, ?it/s][INFO] epoch 0: x recon loss: 0.14963275981215005 [csvae.py fit]\n",
            "[INFO] epoch 0: y recon loss: 30.43396956642521 [csvae.py fit]\n",
            " 20% 1/5 [00:27<01:51, 27.76s/it][INFO] epoch 1: x recon loss: 0.13160560296928978 [csvae.py fit]\n",
            "[INFO] epoch 1: y recon loss: 26.911378154904625 [csvae.py fit]\n",
            " 40% 2/5 [00:55<01:23, 27.92s/it][INFO] epoch 2: x recon loss: 0.12425415574781704 [csvae.py fit]\n",
            "[INFO] epoch 2: y recon loss: 25.730862256687978 [csvae.py fit]\n",
            " 60% 3/5 [01:24<00:56, 28.15s/it][INFO] epoch 3: x recon loss: 0.11931628159700183 [csvae.py fit]\n",
            "[INFO] epoch 3: y recon loss: 25.134538322101257 [csvae.py fit]\n",
            " 80% 4/5 [01:52<00:28, 28.34s/it][INFO] epoch 4: x recon loss: 0.1161944342696573 [csvae.py fit]\n",
            "[INFO] epoch 4: y recon loss: 24.776809572142355 [csvae.py fit]\n",
            "100% 5/5 [02:20<00:00, 28.13s/it]\n",
            "[INFO] ... finished training of CSVAE [csvae.py fit]\n",
            "[INFO] Start training of CSVAE... [csvae.py fit]\n",
            "  0% 0/5 [00:00<?, ?it/s][INFO] epoch 0: x recon loss: 0.14138446379633593 [csvae.py fit]\n",
            "[INFO] epoch 0: y recon loss: 29.833063528078412 [csvae.py fit]\n",
            " 20% 1/5 [00:32<02:08, 32.15s/it][INFO] epoch 1: x recon loss: 0.12696726569908318 [csvae.py fit]\n",
            "[INFO] epoch 1: y recon loss: 26.62890343709823 [csvae.py fit]\n",
            " 40% 2/5 [01:04<01:36, 32.17s/it][INFO] epoch 2: x recon loss: 0.12203820881239709 [csvae.py fit]\n",
            "[INFO] epoch 2: y recon loss: 25.538940099713688 [csvae.py fit]\n",
            " 60% 3/5 [01:35<01:03, 31.93s/it][INFO] epoch 3: x recon loss: 0.11954739748416066 [csvae.py fit]\n",
            "[INFO] epoch 3: y recon loss: 24.99200326243359 [csvae.py fit]\n",
            " 80% 4/5 [02:07<00:31, 31.96s/it][INFO] epoch 4: x recon loss: 0.11735095180580844 [csvae.py fit]\n",
            "[INFO] epoch 4: y recon loss: 24.66359838358228 [csvae.py fit]\n",
            "100% 5/5 [02:39<00:00, 32.00s/it]\n",
            "[INFO] ... finished training of CSVAE [csvae.py fit]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method focus\n",
            "\n",
            "\n",
            "[WARNING] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where [deprecation.py new_func]\n",
            "[WARNING] Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives. [backprop.py gradient]\n",
            "Exception for focus\n",
            "\"None of [Index(['marital-status_Non-Married', 'native-country_US', 'occupation_Other',\\n       'race_White', 'relationship_Non-Husband', 'sex_Male',\\n       'workclass_Private'],\\n      dtype='object')] are in the [columns]\"\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method actionable_recourse\n",
            "\n",
            "\n",
            "Exception for actionable_recourse\n",
            "Recourse method not known  actionable_recourse\n",
            "Exception for actionable_recourse\n",
            "Recourse method not known  actionable_recourse\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cem\n",
            "\n",
            "\n",
            "Exception for cem\n",
            "Session Methods not supported yet\n",
            "Exception for cem\n",
            "Session Methods not supported yet\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method revisewachter\n",
            "\n",
            "\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method face\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method feature_tweak\n",
            "\n",
            "\n",
            "Exception for feature_tweak\n",
            "\"None of [Index(['marital-status_Non-Married', 'native-country_US', 'occupation_Other',\\n       'race_White', 'relationship_Non-Husband', 'sex_Male',\\n       'workclass_Private'],\\n      dtype='object')] are in the [columns]\"\n",
            "######################################################################\n",
            "Starting experiment for dataset compas\n",
            "######################################################################\n",
            "\n",
            "Loading models... --- logs will be saved to ./outputs/compas/models_logs.txt\n",
            "Starting VAE for benchmarking\n",
            "    myvae_params : \n",
            "         input_dim : 7\n",
            "         kld_weight : 0.00025\n",
            "         layers : [16]\n",
            "         latent_dim : 7\n",
            "         hidden_activation : relu\n",
            "         dropout : 0.2\n",
            "         batch_norm : True\n",
            "         batch_size : 32\n",
            "         epochs : 20\n",
            "         learning_rate : 0.001\n",
            "         weight_decay : 0.0\n",
            "         cuda : False\n",
            "         verbose : True\n",
            "         train : True\n",
            "         save_dir : ./vae_model/\n",
            "{'input_dim': 7, 'kld_weight': 0.00025, 'layers': [16], 'latent_dim': 7, 'hidden_activation': 'relu', 'dropout': 0.2, 'batch_norm': True, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001, 'weight_decay': 0.0, 'cuda': False, 'verbose': True, 'train': True, 'save_dir': './vae_model/'}\n",
            "./vae_model/compas\n",
            "Epoch: 0, ELBO Loss: 56.025264739990234, Test MSELoss: 32.618202209472656\n",
            "Epoch: 0, Best ELBO Loss: 56.025264739990234\n",
            "Epoch: 1, ELBO Loss: 26.158130645751953, Test MSELoss: 21.483137130737305\n",
            "BEST Epoch: 1, Best ELBO Loss: 26.158130645751953\n",
            "Epoch: 2, ELBO Loss: 18.932239532470703, Test MSELoss: 16.172679901123047\n",
            "BEST Epoch: 2, Best ELBO Loss: 18.932239532470703\n",
            "Epoch: 3, ELBO Loss: 14.0352144241333, Test MSELoss: 12.29037094116211\n",
            "BEST Epoch: 3, Best ELBO Loss: 14.0352144241333\n",
            "Epoch: 4, ELBO Loss: 11.33474063873291, Test MSELoss: 10.294452667236328\n",
            "BEST Epoch: 4, Best ELBO Loss: 11.33474063873291\n",
            "Epoch: 5, ELBO Loss: 9.808307647705078, Test MSELoss: 9.466313362121582\n",
            "BEST Epoch: 5, Best ELBO Loss: 9.808307647705078\n",
            "Epoch: 6, ELBO Loss: 9.109269142150879, Test MSELoss: 8.833210945129395\n",
            "BEST Epoch: 6, Best ELBO Loss: 9.109269142150879\n",
            "Epoch: 7, ELBO Loss: 8.557812690734863, Test MSELoss: 8.006571769714355\n",
            "BEST Epoch: 7, Best ELBO Loss: 8.557812690734863\n",
            "Epoch: 8, ELBO Loss: 8.026115417480469, Test MSELoss: 8.310015678405762\n",
            "BEST Epoch: 8, Best ELBO Loss: 8.026115417480469\n",
            "Epoch: 9, ELBO Loss: 8.094027519226074, Test MSELoss: 8.016027450561523\n",
            "Epoch: 10, ELBO Loss: 7.670757293701172, Test MSELoss: 7.63050651550293\n",
            "BEST Epoch: 10, Best ELBO Loss: 7.670757293701172\n",
            "Epoch: 11, ELBO Loss: 7.456665992736816, Test MSELoss: 7.351341724395752\n",
            "BEST Epoch: 11, Best ELBO Loss: 7.456665992736816\n",
            "Epoch: 12, ELBO Loss: 7.447570323944092, Test MSELoss: 7.348835468292236\n",
            "BEST Epoch: 12, Best ELBO Loss: 7.447570323944092\n",
            "Epoch: 13, ELBO Loss: 7.071273326873779, Test MSELoss: 7.718304634094238\n",
            "BEST Epoch: 13, Best ELBO Loss: 7.071273326873779\n",
            "Epoch: 14, ELBO Loss: 7.022832870483398, Test MSELoss: 7.115408897399902\n",
            "BEST Epoch: 14, Best ELBO Loss: 7.022832870483398\n",
            "Epoch: 15, ELBO Loss: 7.0250725746154785, Test MSELoss: 7.123038291931152\n",
            "Epoch: 16, ELBO Loss: 7.0128865242004395, Test MSELoss: 6.633187294006348\n",
            "BEST Epoch: 16, Best ELBO Loss: 7.0128865242004395\n",
            "Epoch: 17, ELBO Loss: 6.71834659576416, Test MSELoss: 7.082525730133057\n",
            "BEST Epoch: 17, Best ELBO Loss: 6.71834659576416\n",
            "Epoch: 18, ELBO Loss: 6.61831521987915, Test MSELoss: 6.991052150726318\n",
            "BEST Epoch: 18, Best ELBO Loss: 6.61831521987915\n",
            "Epoch: 19, ELBO Loss: 6.616466045379639, Test MSELoss: 6.635242938995361\n",
            "BEST Epoch: 19, Best ELBO Loss: 6.616466045379639\n",
            "Figure(1000x500)\n",
            "Figure(1000x500)\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cote\n",
            "\n",
            "\n",
            "    data_name : data_name\n",
            "    n_search_samples : 300\n",
            "    p_norm : 1\n",
            "    step : 0.1\n",
            "    max_iter : 10\n",
            "    clamp : True\n",
            "    binary_cat_features : True\n",
            "    myvae_params : \n",
            "         input_dim : 7\n",
            "         kld_weight : 0.00025\n",
            "         layers : [16]\n",
            "         latent_dim : 7\n",
            "         hidden_activation : relu\n",
            "         dropout : 0.2\n",
            "         batch_norm : True\n",
            "         batch_size : 32\n",
            "         epochs : 10\n",
            "         learning_rate : 0.001\n",
            "         weight_decay : 0.0\n",
            "         cuda : False\n",
            "         verbose : True\n",
            "         train : True\n",
            "         save_dir : ./vae_model/\n",
            "    tree_params : \n",
            "         min_entries_per_label : 900\n",
            "         grid_search_jobs : -1\n",
            "         min_weight_gini : 100\n",
            "         max_search : 100\n",
            "         grid_search : \n",
            "              cv : 1\n",
            "              splitter : ['best']\n",
            "              criterion : ['gini']\n",
            "              max_depth : [3, 4, 5, 6, 7, 8, 9, 10]\n",
            "              min_samples_split : [1.0, 2, 3]\n",
            "              min_samples_leaf : [1, 2, 3]\n",
            "              max_features : [0.4, 0.6, 0.8]\n",
            "{'input_dim': 7, 'kld_weight': 0.00025, 'layers': [16], 'latent_dim': 7, 'hidden_activation': 'relu', 'dropout': 0.2, 'batch_norm': True, 'batch_size': 32, 'epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'cuda': False, 'verbose': True, 'train': True, 'save_dir': './vae_model/'}\n",
            "./vae_model/compas\n",
            "Epoch: 0, ELBO Loss: 63.21875762939453, Test MSELoss: 36.44132614135742\n",
            "Epoch: 0, Best ELBO Loss: 63.21875762939453\n",
            "Epoch: 1, ELBO Loss: 28.391664505004883, Test MSELoss: 21.939027786254883\n",
            "BEST Epoch: 1, Best ELBO Loss: 28.391664505004883\n",
            "Epoch: 2, ELBO Loss: 18.10952377319336, Test MSELoss: 15.391965866088867\n",
            "BEST Epoch: 2, Best ELBO Loss: 18.10952377319336\n",
            "Epoch: 3, ELBO Loss: 13.744545936584473, Test MSELoss: 12.711118698120117\n",
            "BEST Epoch: 3, Best ELBO Loss: 13.744545936584473\n",
            "Epoch: 4, ELBO Loss: 12.07812786102295, Test MSELoss: 11.38533878326416\n",
            "BEST Epoch: 4, Best ELBO Loss: 12.07812786102295\n",
            "Epoch: 5, ELBO Loss: 10.852309226989746, Test MSELoss: 10.483452796936035\n",
            "BEST Epoch: 5, Best ELBO Loss: 10.852309226989746\n",
            "Epoch: 6, ELBO Loss: 10.12944221496582, Test MSELoss: 10.021614074707031\n",
            "BEST Epoch: 6, Best ELBO Loss: 10.12944221496582\n",
            "Epoch: 7, ELBO Loss: 9.602581977844238, Test MSELoss: 9.760858535766602\n",
            "BEST Epoch: 7, Best ELBO Loss: 9.602581977844238\n",
            "Epoch: 8, ELBO Loss: 9.051565170288086, Test MSELoss: 8.411442756652832\n",
            "BEST Epoch: 8, Best ELBO Loss: 9.051565170288086\n",
            "Epoch: 9, ELBO Loss: 8.821364402770996, Test MSELoss: 8.482393264770508\n",
            "BEST Epoch: 9, Best ELBO Loss: 8.821364402770996\n",
            "DT Warming Up...\n",
            "{'criterion': 'gini', 'max_depth': 4, 'max_features': 0.4, 'min_samples_leaf': 1, 'min_samples_split': 2.0, 'splitter': 'best'}\n",
            "Exception for cote\n",
            "min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the float 2.0\n",
            "    data_name : data_name\n",
            "    n_search_samples : 300\n",
            "    p_norm : 1\n",
            "    step : 0.1\n",
            "    max_iter : 10\n",
            "    clamp : True\n",
            "    binary_cat_features : True\n",
            "    myvae_params : \n",
            "         input_dim : 7\n",
            "         kld_weight : 0.00025\n",
            "         layers : [16]\n",
            "         latent_dim : 7\n",
            "         hidden_activation : relu\n",
            "         dropout : 0.2\n",
            "         batch_norm : True\n",
            "         batch_size : 32\n",
            "         epochs : 10\n",
            "         learning_rate : 0.001\n",
            "         weight_decay : 0.0\n",
            "         cuda : False\n",
            "         verbose : True\n",
            "         train : True\n",
            "         save_dir : ./vae_model/\n",
            "    tree_params : \n",
            "         min_entries_per_label : 900\n",
            "         grid_search_jobs : -1\n",
            "         min_weight_gini : 100\n",
            "         max_search : 100\n",
            "         grid_search : \n",
            "              cv : 1\n",
            "              splitter : ['best']\n",
            "              criterion : ['gini']\n",
            "              max_depth : [3, 4, 5, 6, 7, 8, 9, 10]\n",
            "              min_samples_split : [1.0, 2, 3]\n",
            "              min_samples_leaf : [1, 2, 3]\n",
            "              max_features : [0.4, 0.6, 0.8]\n",
            "{'input_dim': 7, 'kld_weight': 0.00025, 'layers': [16], 'latent_dim': 7, 'hidden_activation': 'relu', 'dropout': 0.2, 'batch_norm': True, 'batch_size': 32, 'epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'cuda': False, 'verbose': True, 'train': True, 'save_dir': './vae_model/'}\n",
            "./vae_model/compas\n",
            "Epoch: 0, ELBO Loss: 67.23190307617188, Test MSELoss: 36.44828414916992\n",
            "Epoch: 0, Best ELBO Loss: 67.23190307617188\n",
            "Epoch: 1, ELBO Loss: 26.99355697631836, Test MSELoss: 19.933849334716797\n",
            "BEST Epoch: 1, Best ELBO Loss: 26.99355697631836\n",
            "Epoch: 2, ELBO Loss: 16.657621383666992, Test MSELoss: 13.991470336914062\n",
            "BEST Epoch: 2, Best ELBO Loss: 16.657621383666992\n",
            "Epoch: 3, ELBO Loss: 12.696000099182129, Test MSELoss: 11.068679809570312\n",
            "BEST Epoch: 3, Best ELBO Loss: 12.696000099182129\n",
            "Epoch: 4, ELBO Loss: 10.489808082580566, Test MSELoss: 10.152073860168457\n",
            "BEST Epoch: 4, Best ELBO Loss: 10.489808082580566\n",
            "Epoch: 5, ELBO Loss: 9.67952823638916, Test MSELoss: 9.113783836364746\n",
            "BEST Epoch: 5, Best ELBO Loss: 9.67952823638916\n",
            "Epoch: 6, ELBO Loss: 9.086423873901367, Test MSELoss: 8.778521537780762\n",
            "BEST Epoch: 6, Best ELBO Loss: 9.086423873901367\n",
            "Epoch: 7, ELBO Loss: 8.66524887084961, Test MSELoss: 8.5048828125\n",
            "BEST Epoch: 7, Best ELBO Loss: 8.66524887084961\n",
            "Epoch: 8, ELBO Loss: 8.273858070373535, Test MSELoss: 8.421968460083008\n",
            "BEST Epoch: 8, Best ELBO Loss: 8.273858070373535\n",
            "Epoch: 9, ELBO Loss: 7.944301605224609, Test MSELoss: 7.617988586425781\n",
            "BEST Epoch: 9, Best ELBO Loss: 7.944301605224609\n",
            "DT Warming Up...\n",
            "{'criterion': 'gini', 'max_depth': 6, 'max_features': 0.8, 'min_samples_leaf': 3, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method dice\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method growing_spheres\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method clue\n",
            "\n",
            "\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] \n",
            "Network: [train.py train_VAE]\n",
            "[INFO] \n",
            "Train: [train.py train_VAE]\n",
            "[INFO] init cost variables: [train.py train_VAE]\n",
            "[INFO] it 0/1, vlb -11.090858,  [train.py train_VAE]\n",
            "[INFO] time: 0.792933 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] vlb -7.911866 (-inf)\n",
            " [train.py train_VAE]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_compas_models/theta_best.dat\n",
            " [utils.py save]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_compas_models/theta_last.dat\n",
            " [utils.py save]\n",
            "[INFO] average time: 0.882251 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "RESULTS: [train.py train_VAE]\n",
            "[INFO] best_vlb_dev: -7.911866 [train.py train_VAE]\n",
            "[INFO] best_vlb_train: -11.090858 [train.py train_VAE]\n",
            "[INFO] nb_parameters: 1111 (1.08KB)\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] Reading /root/carla/models/autoencoders/clue/fc_VAE_compas_models/theta_best.dat\n",
            " [utils.py load]\n",
            "[INFO] restoring epoch: 1, lr: 0.001000 [utils.py load]\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] \n",
            "Network: [train.py train_VAE]\n",
            "[INFO] \n",
            "Train: [train.py train_VAE]\n",
            "[INFO] init cost variables: [train.py train_VAE]\n",
            "[INFO] it 0/1, vlb -11.090858,  [train.py train_VAE]\n",
            "[INFO] time: 0.809643 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] vlb -7.911866 (-inf)\n",
            " [train.py train_VAE]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_compas_models/theta_best.dat\n",
            " [utils.py save]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_compas_models/theta_last.dat\n",
            " [utils.py save]\n",
            "[INFO] average time: 0.892350 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "RESULTS: [train.py train_VAE]\n",
            "[INFO] best_vlb_dev: -7.911866 [train.py train_VAE]\n",
            "[INFO] best_vlb_train: -11.090858 [train.py train_VAE]\n",
            "[INFO] nb_parameters: 1111 (1.08KB)\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] Reading /root/carla/models/autoencoders/clue/fc_VAE_compas_models/theta_best.dat\n",
            " [utils.py load]\n",
            "[INFO] restoring epoch: 1, lr: 0.001000 [utils.py load]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method causal_recourse\n",
            "\n",
            "\n",
            "Exception for causal_recourse\n",
            "\n",
            "Exception for causal_recourse\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cchvae\n",
            "\n",
            "\n",
            "[INFO] Start training of Variational Autoencoder... [vae.py fit]\n",
            "[INFO] [Epoch: 0/5] [objective: 29.324] [vae.py fit]\n",
            "[INFO] [ELBO train: 29.324] [vae.py fit]\n",
            "[INFO] [ELBO train: 13.137] [vae.py fit]\n",
            "[INFO] [ELBO train: 6.669] [vae.py fit]\n",
            "[INFO] [ELBO train: 3.72] [vae.py fit]\n",
            "[INFO] [ELBO train: 3.12] [vae.py fit]\n",
            "[INFO] ... finished training of Variational Autoencoder. [vae.py fit]\n",
            "[INFO] Start training of Variational Autoencoder... [vae.py fit]\n",
            "[INFO] [Epoch: 0/5] [objective: 30.788] [vae.py fit]\n",
            "[INFO] [ELBO train: 30.788] [vae.py fit]\n",
            "[INFO] [ELBO train: 14.757] [vae.py fit]\n",
            "[INFO] [ELBO train: 8.721] [vae.py fit]\n",
            "[INFO] [ELBO train: 6.816] [vae.py fit]\n",
            "[INFO] [ELBO train: 4.762] [vae.py fit]\n",
            "[INFO] ... finished training of Variational Autoencoder. [vae.py fit]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cruds\n",
            "\n",
            "\n",
            "[INFO] Start training of CSVAE... [csvae.py fit]\n",
            "  0% 0/5 [00:00<?, ?it/s][INFO] epoch 0: x recon loss: 0.247624294977114 [csvae.py fit]\n",
            "[INFO] epoch 0: y recon loss: 59.8061230911492 [csvae.py fit]\n",
            " 20% 1/5 [00:04<00:16,  4.14s/it][INFO] epoch 1: x recon loss: 0.1947874173020143 [csvae.py fit]\n",
            "[INFO] epoch 1: y recon loss: 42.158045274606025 [csvae.py fit]\n",
            " 40% 2/5 [00:08<00:12,  4.07s/it][INFO] epoch 2: x recon loss: 0.1747562452790445 [csvae.py fit]\n",
            "[INFO] epoch 2: y recon loss: 35.42599120658914 [csvae.py fit]\n",
            " 60% 3/5 [00:12<00:08,  4.10s/it][INFO] epoch 3: x recon loss: 0.16449085734977623 [csvae.py fit]\n",
            "[INFO] epoch 3: y recon loss: 32.03521721103648 [csvae.py fit]\n",
            " 80% 4/5 [00:16<00:04,  4.09s/it][INFO] epoch 4: x recon loss: 0.15823768805808971 [csvae.py fit]\n",
            "[INFO] epoch 4: y recon loss: 29.996004470271767 [csvae.py fit]\n",
            "100% 5/5 [00:20<00:00,  4.08s/it]\n",
            "[INFO] ... finished training of CSVAE [csvae.py fit]\n",
            "[INFO] Start training of CSVAE... [csvae.py fit]\n",
            "  0% 0/5 [00:00<?, ?it/s][INFO] epoch 0: x recon loss: 0.3225665979589205 [csvae.py fit]\n",
            "[INFO] epoch 0: y recon loss: 44.75676221303989 [csvae.py fit]\n",
            " 20% 1/5 [00:04<00:17,  4.46s/it][INFO] epoch 1: x recon loss: 0.2325456711642174 [csvae.py fit]\n",
            "[INFO] epoch 1: y recon loss: 33.341864734115994 [csvae.py fit]\n",
            " 40% 2/5 [00:09<00:13,  4.53s/it][INFO] epoch 2: x recon loss: 0.20022577473279313 [csvae.py fit]\n",
            "[INFO] epoch 2: y recon loss: 29.49485577861674 [csvae.py fit]\n",
            " 60% 3/5 [00:13<00:09,  4.52s/it][INFO] epoch 3: x recon loss: 0.18370947461826195 [csvae.py fit]\n",
            "[INFO] epoch 3: y recon loss: 27.574704726125294 [csvae.py fit]\n",
            " 80% 4/5 [00:18<00:04,  4.50s/it][INFO] epoch 4: x recon loss: 0.1736462662102645 [csvae.py fit]\n",
            "[INFO] epoch 4: y recon loss: 26.421802740146457 [csvae.py fit]\n",
            "100% 5/5 [00:22<00:00,  4.49s/it]\n",
            "[INFO] ... finished training of CSVAE [csvae.py fit]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method focus\n",
            "\n",
            "\n",
            "Exception for focus\n",
            "\"None of [Index(['c_charge_degree_M', 'race_Other', 'sex_Male'], dtype='object')] are in the [columns]\"\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method actionable_recourse\n",
            "\n",
            "\n",
            "Exception for actionable_recourse\n",
            "Recourse method not known  actionable_recourse\n",
            "Exception for actionable_recourse\n",
            "Recourse method not known  actionable_recourse\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cem\n",
            "\n",
            "\n",
            "Exception for cem\n",
            "Session Methods not supported yet\n",
            "Exception for cem\n",
            "Session Methods not supported yet\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method revisewachter\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method face\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method feature_tweak\n",
            "\n",
            "\n",
            "Exception for feature_tweak\n",
            "\"None of [Index(['c_charge_degree_M', 'race_Other', 'sex_Male'], dtype='object')] are in the [columns]\"\n",
            "######################################################################\n",
            "Starting experiment for dataset give_me_some_credit\n",
            "######################################################################\n",
            "\n",
            "Loading models... --- logs will be saved to ./outputs/give_me_some_credit/models_logs.txt\n",
            "Starting VAE for benchmarking\n",
            "    myvae_params : \n",
            "         input_dim : 10\n",
            "         kld_weight : 0.00025\n",
            "         layers : [16]\n",
            "         latent_dim : 7\n",
            "         hidden_activation : relu\n",
            "         dropout : 0.2\n",
            "         batch_norm : True\n",
            "         batch_size : 32\n",
            "         epochs : 20\n",
            "         learning_rate : 0.001\n",
            "         weight_decay : 0.0\n",
            "         cuda : False\n",
            "         verbose : True\n",
            "         train : True\n",
            "         save_dir : ./vae_model/\n",
            "{'input_dim': 10, 'kld_weight': 0.00025, 'layers': [16], 'latent_dim': 7, 'hidden_activation': 'relu', 'dropout': 0.2, 'batch_norm': True, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001, 'weight_decay': 0.0, 'cuda': False, 'verbose': True, 'train': True, 'save_dir': './vae_model/'}\n",
            "./vae_model/give_me_some_credit\n",
            "Epoch: 0, ELBO Loss: 5.496260643005371, Test MSELoss: 2.265110969543457\n",
            "Epoch: 0, Best ELBO Loss: 5.496260643005371\n",
            "Epoch: 1, ELBO Loss: 2.1350269317626953, Test MSELoss: 2.0664267539978027\n",
            "BEST Epoch: 1, Best ELBO Loss: 2.1350269317626953\n",
            "Epoch: 2, ELBO Loss: 2.044372797012329, Test MSELoss: 2.01336932182312\n",
            "BEST Epoch: 2, Best ELBO Loss: 2.044372797012329\n",
            "Epoch: 3, ELBO Loss: 2.0056772232055664, Test MSELoss: 1.962849736213684\n",
            "BEST Epoch: 3, Best ELBO Loss: 2.0056772232055664\n",
            "Epoch: 4, ELBO Loss: 1.9846817255020142, Test MSELoss: 1.9584388732910156\n",
            "BEST Epoch: 4, Best ELBO Loss: 1.9846817255020142\n",
            "Epoch: 5, ELBO Loss: 1.9751861095428467, Test MSELoss: 1.9358576536178589\n",
            "BEST Epoch: 5, Best ELBO Loss: 1.9751861095428467\n",
            "Epoch: 6, ELBO Loss: 1.9670897722244263, Test MSELoss: 1.9615919589996338\n",
            "BEST Epoch: 6, Best ELBO Loss: 1.9670897722244263\n",
            "Epoch: 7, ELBO Loss: 1.9623501300811768, Test MSELoss: 1.9480739831924438\n",
            "BEST Epoch: 7, Best ELBO Loss: 1.9623501300811768\n",
            "Epoch: 8, ELBO Loss: 1.9623558521270752, Test MSELoss: 1.9389030933380127\n",
            "Epoch: 9, ELBO Loss: 1.937484622001648, Test MSELoss: 1.9554884433746338\n",
            "BEST Epoch: 9, Best ELBO Loss: 1.937484622001648\n",
            "Epoch: 10, ELBO Loss: 1.947546362876892, Test MSELoss: 1.9195590019226074\n",
            "Epoch: 11, ELBO Loss: 1.9429128170013428, Test MSELoss: 1.9216986894607544\n",
            "Epoch: 12, ELBO Loss: 1.939284324645996, Test MSELoss: 1.905229091644287\n",
            "Epoch: 13, ELBO Loss: 1.9434901475906372, Test MSELoss: 1.9462897777557373\n",
            "Epoch: 14, ELBO Loss: 1.9326417446136475, Test MSELoss: 1.902618646621704\n",
            "BEST Epoch: 14, Best ELBO Loss: 1.9326417446136475\n",
            "Epoch: 15, ELBO Loss: 1.936871886253357, Test MSELoss: 1.9090057611465454\n",
            "Epoch: 16, ELBO Loss: 1.9322987794876099, Test MSELoss: 1.9199128150939941\n",
            "BEST Epoch: 16, Best ELBO Loss: 1.9322987794876099\n",
            "Epoch: 17, ELBO Loss: 1.933171272277832, Test MSELoss: 1.9268823862075806\n",
            "Epoch: 18, ELBO Loss: 1.9158259630203247, Test MSELoss: 1.929323434829712\n",
            "BEST Epoch: 18, Best ELBO Loss: 1.9158259630203247\n",
            "Epoch: 19, ELBO Loss: 1.9344534873962402, Test MSELoss: 1.8826836347579956\n",
            "Figure(1000x500)\n",
            "Figure(1000x500)\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cote\n",
            "\n",
            "\n",
            "    data_name : data_name\n",
            "    n_search_samples : 300\n",
            "    p_norm : 1\n",
            "    step : 0.1\n",
            "    max_iter : 10\n",
            "    clamp : True\n",
            "    binary_cat_features : True\n",
            "    myvae_params : \n",
            "         input_dim : 10\n",
            "         kld_weight : 0.00025\n",
            "         layers : [16]\n",
            "         latent_dim : 7\n",
            "         hidden_activation : relu\n",
            "         dropout : 0.2\n",
            "         batch_norm : True\n",
            "         batch_size : 32\n",
            "         epochs : 10\n",
            "         learning_rate : 0.001\n",
            "         weight_decay : 0.0\n",
            "         cuda : False\n",
            "         verbose : True\n",
            "         train : True\n",
            "         save_dir : ./vae_model/\n",
            "    tree_params : \n",
            "         min_entries_per_label : 2309\n",
            "         grid_search_jobs : -1\n",
            "         min_weight_gini : 100\n",
            "         max_search : 100\n",
            "         grid_search : \n",
            "              cv : 1\n",
            "              splitter : ['best']\n",
            "              criterion : ['gini']\n",
            "              max_depth : [3, 4, 5, 6, 7, 8, 9, 10]\n",
            "              min_samples_split : [1.0, 2, 3]\n",
            "              min_samples_leaf : [1, 2, 3]\n",
            "              max_features : [0.4, 0.6, 0.8]\n",
            "{'input_dim': 10, 'kld_weight': 0.00025, 'layers': [16], 'latent_dim': 7, 'hidden_activation': 'relu', 'dropout': 0.2, 'batch_norm': True, 'batch_size': 32, 'epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'cuda': False, 'verbose': True, 'train': True, 'save_dir': './vae_model/'}\n",
            "./vae_model/give_me_some_credit\n",
            "Epoch: 0, ELBO Loss: 5.086032390594482, Test MSELoss: 2.1833393573760986\n",
            "Epoch: 0, Best ELBO Loss: 5.086032390594482\n",
            "Epoch: 1, ELBO Loss: 2.095021963119507, Test MSELoss: 2.05198335647583\n",
            "BEST Epoch: 1, Best ELBO Loss: 2.095021963119507\n",
            "Epoch: 2, ELBO Loss: 2.018298387527466, Test MSELoss: 2.001270055770874\n",
            "BEST Epoch: 2, Best ELBO Loss: 2.018298387527466\n",
            "Epoch: 3, ELBO Loss: 1.9862347841262817, Test MSELoss: 2.016669750213623\n",
            "BEST Epoch: 3, Best ELBO Loss: 1.9862347841262817\n",
            "Epoch: 4, ELBO Loss: 1.9628138542175293, Test MSELoss: 1.9784868955612183\n",
            "BEST Epoch: 4, Best ELBO Loss: 1.9628138542175293\n",
            "Epoch: 5, ELBO Loss: 1.9627097845077515, Test MSELoss: 1.9510979652404785\n",
            "BEST Epoch: 5, Best ELBO Loss: 1.9627097845077515\n",
            "Epoch: 6, ELBO Loss: 1.965569019317627, Test MSELoss: 1.9455338716506958\n",
            "Epoch: 7, ELBO Loss: 1.9626777172088623, Test MSELoss: 1.9740972518920898\n",
            "BEST Epoch: 7, Best ELBO Loss: 1.9626777172088623\n",
            "Epoch: 8, ELBO Loss: 1.943859338760376, Test MSELoss: 1.95078706741333\n",
            "BEST Epoch: 8, Best ELBO Loss: 1.943859338760376\n",
            "Epoch: 9, ELBO Loss: 1.9465495347976685, Test MSELoss: 1.9325560331344604\n",
            "DT Warming Up...\n",
            "{'criterion': 'gini', 'max_depth': 3, 'max_features': 0.6, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "    data_name : data_name\n",
            "    n_search_samples : 300\n",
            "    p_norm : 1\n",
            "    step : 0.1\n",
            "    max_iter : 10\n",
            "    clamp : True\n",
            "    binary_cat_features : True\n",
            "    myvae_params : \n",
            "         input_dim : 10\n",
            "         kld_weight : 0.00025\n",
            "         layers : [16]\n",
            "         latent_dim : 7\n",
            "         hidden_activation : relu\n",
            "         dropout : 0.2\n",
            "         batch_norm : True\n",
            "         batch_size : 32\n",
            "         epochs : 10\n",
            "         learning_rate : 0.001\n",
            "         weight_decay : 0.0\n",
            "         cuda : False\n",
            "         verbose : True\n",
            "         train : True\n",
            "         save_dir : ./vae_model/\n",
            "    tree_params : \n",
            "         min_entries_per_label : 2309\n",
            "         grid_search_jobs : -1\n",
            "         min_weight_gini : 100\n",
            "         max_search : 100\n",
            "         grid_search : \n",
            "              cv : 1\n",
            "              splitter : ['best']\n",
            "              criterion : ['gini']\n",
            "              max_depth : [3, 4, 5, 6, 7, 8, 9, 10]\n",
            "              min_samples_split : [1.0, 2, 3]\n",
            "              min_samples_leaf : [1, 2, 3]\n",
            "              max_features : [0.4, 0.6, 0.8]\n",
            "{'input_dim': 10, 'kld_weight': 0.00025, 'layers': [16], 'latent_dim': 7, 'hidden_activation': 'relu', 'dropout': 0.2, 'batch_norm': True, 'batch_size': 32, 'epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'cuda': False, 'verbose': True, 'train': True, 'save_dir': './vae_model/'}\n",
            "./vae_model/give_me_some_credit\n",
            "Epoch: 0, ELBO Loss: 6.770657539367676, Test MSELoss: 2.2171058654785156\n",
            "Epoch: 0, Best ELBO Loss: 6.770657539367676\n",
            "Epoch: 1, ELBO Loss: 2.1201651096343994, Test MSELoss: 2.0677366256713867\n",
            "BEST Epoch: 1, Best ELBO Loss: 2.1201651096343994\n",
            "Epoch: 2, ELBO Loss: 2.025564432144165, Test MSELoss: 2.001093626022339\n",
            "BEST Epoch: 2, Best ELBO Loss: 2.025564432144165\n",
            "Epoch: 3, ELBO Loss: 1.9934040307998657, Test MSELoss: 1.9828135967254639\n",
            "BEST Epoch: 3, Best ELBO Loss: 1.9934040307998657\n",
            "Epoch: 4, ELBO Loss: 1.9663892984390259, Test MSELoss: 1.9727181196212769\n",
            "BEST Epoch: 4, Best ELBO Loss: 1.9663892984390259\n",
            "Epoch: 5, ELBO Loss: 1.9716684818267822, Test MSELoss: 1.9571549892425537\n",
            "Epoch: 6, ELBO Loss: 1.9617067575454712, Test MSELoss: 1.9587621688842773\n",
            "BEST Epoch: 6, Best ELBO Loss: 1.9617067575454712\n",
            "Epoch: 7, ELBO Loss: 1.956634759902954, Test MSELoss: 1.9496099948883057\n",
            "BEST Epoch: 7, Best ELBO Loss: 1.956634759902954\n",
            "Epoch: 8, ELBO Loss: 1.9464340209960938, Test MSELoss: 1.954648494720459\n",
            "BEST Epoch: 8, Best ELBO Loss: 1.9464340209960938\n",
            "Epoch: 9, ELBO Loss: 1.953666090965271, Test MSELoss: 1.97243070602417\n",
            "DT Warming Up...\n",
            "{'criterion': 'gini', 'max_depth': 3, 'max_features': 0.6, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method dice\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method growing_spheres\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method clue\n",
            "\n",
            "\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] \n",
            "Network: [train.py train_VAE]\n",
            "[INFO] \n",
            "Train: [train.py train_VAE]\n",
            "[INFO] init cost variables: [train.py train_VAE]\n",
            "[INFO] it 0/1, vlb -1.974530,  [train.py train_VAE]\n",
            "[INFO] time: 15.198714 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] vlb -0.667592 (-inf)\n",
            " [train.py train_VAE]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_give_me_some_credit_models/theta_best.dat\n",
            " [utils.py save]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_give_me_some_credit_models/theta_last.dat\n",
            " [utils.py save]\n",
            "[INFO] average time: 16.499006 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "RESULTS: [train.py train_VAE]\n",
            "[INFO] best_vlb_dev: -0.667592 [train.py train_VAE]\n",
            "[INFO] best_vlb_train: -1.974530 [train.py train_VAE]\n",
            "[INFO] nb_parameters: 1174 (1.15KB)\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] Reading /root/carla/models/autoencoders/clue/fc_VAE_give_me_some_credit_models/theta_best.dat\n",
            " [utils.py load]\n",
            "[INFO] restoring epoch: 1, lr: 0.001000 [utils.py load]\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] \n",
            "Network: [train.py train_VAE]\n",
            "[INFO] \n",
            "Train: [train.py train_VAE]\n",
            "[INFO] init cost variables: [train.py train_VAE]\n",
            "[INFO] it 0/1, vlb -1.974530,  [train.py train_VAE]\n",
            "[INFO] time: 14.758408 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] vlb -0.667592 (-inf)\n",
            " [train.py train_VAE]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_give_me_some_credit_models/theta_best.dat\n",
            " [utils.py save]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_give_me_some_credit_models/theta_last.dat\n",
            " [utils.py save]\n",
            "[INFO] average time: 16.075912 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "RESULTS: [train.py train_VAE]\n",
            "[INFO] best_vlb_dev: -0.667592 [train.py train_VAE]\n",
            "[INFO] best_vlb_train: -1.974530 [train.py train_VAE]\n",
            "[INFO] nb_parameters: 1174 (1.15KB)\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] Reading /root/carla/models/autoencoders/clue/fc_VAE_give_me_some_credit_models/theta_best.dat\n",
            " [utils.py load]\n",
            "[INFO] restoring epoch: 1, lr: 0.001000 [utils.py load]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method causal_recourse\n",
            "\n",
            "\n",
            "Exception for causal_recourse\n",
            "\n",
            "Exception for causal_recourse\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cchvae\n",
            "\n",
            "\n",
            "[INFO] Start training of Variational Autoencoder... [vae.py fit]\n",
            "[INFO] [Epoch: 0/5] [objective: 5.944] [vae.py fit]\n",
            "[INFO] [ELBO train: 5.944] [vae.py fit]\n",
            "[INFO] [ELBO train: 3.262] [vae.py fit]\n",
            "[INFO] [ELBO train: 2.367] [vae.py fit]\n",
            "[INFO] [ELBO train: 1.754] [vae.py fit]\n",
            "[INFO] [ELBO train: 1.468] [vae.py fit]\n",
            "[INFO] ... finished training of Variational Autoencoder. [vae.py fit]\n",
            "[INFO] Start training of Variational Autoencoder... [vae.py fit]\n",
            "[INFO] [Epoch: 0/5] [objective: 5.934] [vae.py fit]\n",
            "[INFO] [ELBO train: 5.934] [vae.py fit]\n",
            "[INFO] [ELBO train: 2.732] [vae.py fit]\n",
            "[INFO] [ELBO train: 1.908] [vae.py fit]\n",
            "[INFO] [ELBO train: 1.706] [vae.py fit]\n",
            "[INFO] [ELBO train: 1.577] [vae.py fit]\n",
            "[INFO] ... finished training of Variational Autoencoder. [vae.py fit]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cruds\n",
            "\n",
            "\n",
            "[INFO] Start training of CSVAE... [csvae.py fit]\n",
            "  0% 0/5 [00:00<?, ?it/s][INFO] epoch 0: x recon loss: 0.025089461879448296 [csvae.py fit]\n",
            "[INFO] epoch 0: y recon loss: 17.953964237095875 [csvae.py fit]\n",
            " 20% 1/5 [01:30<06:02, 90.54s/it][INFO] epoch 1: x recon loss: 0.0238102588876597 [csvae.py fit]\n",
            "[INFO] epoch 1: y recon loss: 17.242411664172046 [csvae.py fit]\n",
            " 40% 2/5 [03:01<04:32, 90.73s/it][INFO] epoch 2: x recon loss: 0.023382672250733712 [csvae.py fit]\n",
            "[INFO] epoch 2: y recon loss: 17.0037621014184 [csvae.py fit]\n",
            " 60% 3/5 [04:32<03:02, 91.02s/it][INFO] epoch 3: x recon loss: 0.023167451817054343 [csvae.py fit]\n",
            "[INFO] epoch 3: y recon loss: 16.884461359052043 [csvae.py fit]\n",
            " 80% 4/5 [06:03<01:31, 91.07s/it][INFO] epoch 4: x recon loss: 0.023038599696923363 [csvae.py fit]\n",
            "[INFO] epoch 4: y recon loss: 16.8127793825224 [csvae.py fit]\n",
            "100% 5/5 [07:34<00:00, 90.84s/it]\n",
            "[INFO] ... finished training of CSVAE [csvae.py fit]\n",
            "[INFO] Start training of CSVAE... [csvae.py fit]\n",
            "  0% 0/5 [00:00<?, ?it/s][INFO] epoch 0: x recon loss: 0.023776539274352356 [csvae.py fit]\n",
            "[INFO] epoch 0: y recon loss: 19.70321962952911 [csvae.py fit]\n",
            " 20% 1/5 [01:38<06:34, 98.60s/it][INFO] epoch 1: x recon loss: 0.02314612597066675 [csvae.py fit]\n",
            "[INFO] epoch 1: y recon loss: 18.11682671121995 [csvae.py fit]\n",
            " 40% 2/5 [03:15<04:53, 97.76s/it][INFO] epoch 2: x recon loss: 0.022937262747159935 [csvae.py fit]\n",
            "[INFO] epoch 2: y recon loss: 17.587607990899794 [csvae.py fit]\n",
            " 60% 3/5 [04:53<03:15, 97.60s/it][INFO] epoch 3: x recon loss: 0.022832114855884964 [csvae.py fit]\n",
            "[INFO] epoch 3: y recon loss: 17.32254805468483 [csvae.py fit]\n",
            " 80% 4/5 [06:30<01:37, 97.58s/it][INFO] epoch 4: x recon loss: 0.022768949990257997 [csvae.py fit]\n",
            "[INFO] epoch 4: y recon loss: 17.16386176230537 [csvae.py fit]\n",
            "100% 5/5 [08:07<00:00, 97.47s/it]\n",
            "[INFO] ... finished training of CSVAE [csvae.py fit]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method focus\n",
            "\n",
            "\n",
            "Exception for focus\n",
            "ValueError: too many values to unpack (expected 5)\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 207, in __call__\n",
            "    return func(device, token, args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 109, in __call__\n",
            "    ret = self._func(*args)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 195, in f\n",
            "    self._prob_from_input,\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 58, in _filter_hinge_loss\n",
            "    filtered_loss = model_fn(filtered_input, sigma, temperature)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 265, in _prob_from_input\n",
            "    temperature=temperature,\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 127, in get_prob_classification_forest\n",
            "    tree_l = [tree_parser(estimator) for estimator in model.tree_iterator][\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 127, in <listcomp>\n",
            "    tree_l = [tree_parser(estimator) for estimator in model.tree_iterator][\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 120, in tree_parser\n",
            "    return get_prob_classification_tree(tree, feat_columns, feat_input, sigma)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 76, in get_prob_classification_tree\n",
            "    tree, feat_columns, feat_input, split_function\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 28, in _parse_class_tree\n",
            "    children_left, children_right, threshold, feature, scores = parse_booster(tree)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/parse_xgboost.py\", line 81, in parse_booster\n",
            "    ) = _parse_node(node)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/parse_xgboost.py\", line 52, in _parse_node\n",
            "    node_id, threshold, left_child, right_child, _ = numbers\n",
            "\n",
            "ValueError: too many values to unpack (expected 5)\n",
            "\n",
            "\n",
            "\t [[node EagerPyFunc_4 (defined at /content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py:249) ]]\n",
            "\n",
            "Original stack trace for 'EagerPyFunc_4':\n",
            "  File \"becnhmark_experiment.py\", line 323, in <module>\n",
            "    benchmark = Benchmark(model, rcmethod,  data_models.factuals.copy().reset_index(drop=True))\n",
            "  File \"/content/TreeBased_Carla/carla/evaluation/benchmark.py\", line 41, in __init__\n",
            "    self._counterfactuals = recourse_method.get_counterfactuals(factuals).astype(float)\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 249, in get_counterfactuals\n",
            "    pf = tfe.py_func(f, [best_perturb], tf.float32)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 392, in eager_py_func\n",
            "    return _internal_py_func(func=func, inp=inp, Tout=Tout, eager=True, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 281, in _internal_py_func\n",
            "    input=inp, token=token, Tout=Tout, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_script_ops.py\", line 74, in eager_py_func\n",
            "    \"EagerPyFunc\", input=input, token=token, Tout=Tout, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method actionable_recourse\n",
            "\n",
            "\n",
            "Exception for actionable_recourse\n",
            "Recourse method not known  actionable_recourse\n",
            "Exception for actionable_recourse\n",
            "Recourse method not known  actionable_recourse\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cem\n",
            "\n",
            "\n",
            "Exception for cem\n",
            "Session Methods not supported yet\n",
            "Exception for cem\n",
            "Session Methods not supported yet\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method revisewachter\n",
            "\n",
            "\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method face\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method feature_tweak\n",
            "\n",
            "\n",
            "Exception for feature_tweak\n",
            "ValueError: too many values to unpack (expected 5)\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 207, in __call__\n",
            "    return func(device, token, args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 109, in __call__\n",
            "    ret = self._func(*args)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 195, in f\n",
            "    self._prob_from_input,\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 58, in _filter_hinge_loss\n",
            "    filtered_loss = model_fn(filtered_input, sigma, temperature)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 265, in _prob_from_input\n",
            "    temperature=temperature,\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 127, in get_prob_classification_forest\n",
            "    tree_l = [tree_parser(estimator) for estimator in model.tree_iterator][\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 127, in <listcomp>\n",
            "    tree_l = [tree_parser(estimator) for estimator in model.tree_iterator][\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 120, in tree_parser\n",
            "    return get_prob_classification_tree(tree, feat_columns, feat_input, sigma)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 76, in get_prob_classification_tree\n",
            "    tree, feat_columns, feat_input, split_function\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 28, in _parse_class_tree\n",
            "    children_left, children_right, threshold, feature, scores = parse_booster(tree)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/parse_xgboost.py\", line 81, in parse_booster\n",
            "    ) = _parse_node(node)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/parse_xgboost.py\", line 52, in _parse_node\n",
            "    node_id, threshold, left_child, right_child, _ = numbers\n",
            "\n",
            "ValueError: too many values to unpack (expected 5)\n",
            "\n",
            "\n",
            "\t [[node EagerPyFunc_5 (defined at /content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py:249) ]]\n",
            "\n",
            "Original stack trace for 'EagerPyFunc_5':\n",
            "  File \"becnhmark_experiment.py\", line 323, in <module>\n",
            "    benchmark = Benchmark(model, rcmethod,  data_models.factuals.copy().reset_index(drop=True))\n",
            "  File \"/content/TreeBased_Carla/carla/evaluation/benchmark.py\", line 41, in __init__\n",
            "    self._counterfactuals = recourse_method.get_counterfactuals(factuals).astype(float)\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 249, in get_counterfactuals\n",
            "    pf = tfe.py_func(f, [best_perturb], tf.float32)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 392, in eager_py_func\n",
            "    return _internal_py_func(func=func, inp=inp, Tout=Tout, eager=True, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 281, in _internal_py_func\n",
            "    input=inp, token=token, Tout=Tout, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_script_ops.py\", line 74, in eager_py_func\n",
            "    \"EagerPyFunc\", input=input, token=token, Tout=Tout, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "######################################################################\n",
            "Starting experiment for dataset heloc\n",
            "######################################################################\n",
            "\n",
            "Loading models... --- logs will be saved to ./outputs/heloc/models_logs.txt\n",
            "Starting VAE for benchmarking\n",
            "    myvae_params : \n",
            "         input_dim : 21\n",
            "         kld_weight : 0.00025\n",
            "         layers : [25, 16]\n",
            "         latent_dim : 12\n",
            "         hidden_activation : relu\n",
            "         dropout : 0.2\n",
            "         batch_norm : True\n",
            "         batch_size : 32\n",
            "         epochs : 20\n",
            "         learning_rate : 0.001\n",
            "         weight_decay : 0.0\n",
            "         cuda : False\n",
            "         verbose : True\n",
            "         train : True\n",
            "         save_dir : ./vae_model/\n",
            "{'input_dim': 21, 'kld_weight': 0.00025, 'layers': [25, 16], 'latent_dim': 12, 'hidden_activation': 'relu', 'dropout': 0.2, 'batch_norm': True, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001, 'weight_decay': 0.0, 'cuda': False, 'verbose': True, 'train': True, 'save_dir': './vae_model/'}\n",
            "./vae_model/heloc\n",
            "Epoch: 0, ELBO Loss: 75.3547592163086, Test MSELoss: 29.639747619628906\n",
            "Epoch: 0, Best ELBO Loss: 75.3547592163086\n",
            "Epoch: 1, ELBO Loss: 23.322948455810547, Test MSELoss: 17.886213302612305\n",
            "BEST Epoch: 1, Best ELBO Loss: 23.322948455810547\n",
            "Epoch: 2, ELBO Loss: 16.09221076965332, Test MSELoss: 13.991497039794922\n",
            "BEST Epoch: 2, Best ELBO Loss: 16.09221076965332\n",
            "Epoch: 3, ELBO Loss: 12.990450859069824, Test MSELoss: 12.022688865661621\n",
            "BEST Epoch: 3, Best ELBO Loss: 12.990450859069824\n",
            "Epoch: 4, ELBO Loss: 11.65652847290039, Test MSELoss: 10.940305709838867\n",
            "BEST Epoch: 4, Best ELBO Loss: 11.65652847290039\n",
            "Epoch: 5, ELBO Loss: 10.679821968078613, Test MSELoss: 10.120902061462402\n",
            "BEST Epoch: 5, Best ELBO Loss: 10.679821968078613\n",
            "Epoch: 6, ELBO Loss: 9.951045989990234, Test MSELoss: 9.639229774475098\n",
            "BEST Epoch: 6, Best ELBO Loss: 9.951045989990234\n",
            "Epoch: 7, ELBO Loss: 9.535200119018555, Test MSELoss: 9.324432373046875\n",
            "BEST Epoch: 7, Best ELBO Loss: 9.535200119018555\n",
            "Epoch: 8, ELBO Loss: 9.164143562316895, Test MSELoss: 8.806398391723633\n",
            "BEST Epoch: 8, Best ELBO Loss: 9.164143562316895\n",
            "Epoch: 9, ELBO Loss: 8.868876457214355, Test MSELoss: 8.60807991027832\n",
            "BEST Epoch: 9, Best ELBO Loss: 8.868876457214355\n",
            "Epoch: 10, ELBO Loss: 8.564244270324707, Test MSELoss: 8.27381706237793\n",
            "BEST Epoch: 10, Best ELBO Loss: 8.564244270324707\n",
            "Epoch: 11, ELBO Loss: 8.375268936157227, Test MSELoss: 7.909585952758789\n",
            "BEST Epoch: 11, Best ELBO Loss: 8.375268936157227\n",
            "Epoch: 12, ELBO Loss: 8.081864356994629, Test MSELoss: 8.029007911682129\n",
            "BEST Epoch: 12, Best ELBO Loss: 8.081864356994629\n",
            "Epoch: 13, ELBO Loss: 8.023078918457031, Test MSELoss: 7.715576171875\n",
            "BEST Epoch: 13, Best ELBO Loss: 8.023078918457031\n",
            "Epoch: 14, ELBO Loss: 7.829776763916016, Test MSELoss: 7.730334281921387\n",
            "BEST Epoch: 14, Best ELBO Loss: 7.829776763916016\n",
            "Epoch: 15, ELBO Loss: 7.7553391456604, Test MSELoss: 7.586653709411621\n",
            "BEST Epoch: 15, Best ELBO Loss: 7.7553391456604\n",
            "Epoch: 16, ELBO Loss: 7.653234481811523, Test MSELoss: 7.629909515380859\n",
            "BEST Epoch: 16, Best ELBO Loss: 7.653234481811523\n",
            "Epoch: 17, ELBO Loss: 7.565563678741455, Test MSELoss: 7.408627510070801\n",
            "BEST Epoch: 17, Best ELBO Loss: 7.565563678741455\n",
            "Epoch: 18, ELBO Loss: 7.55326509475708, Test MSELoss: 7.388383865356445\n",
            "BEST Epoch: 18, Best ELBO Loss: 7.55326509475708\n",
            "Epoch: 19, ELBO Loss: 7.485442161560059, Test MSELoss: 7.275598526000977\n",
            "BEST Epoch: 19, Best ELBO Loss: 7.485442161560059\n",
            "Figure(1000x500)\n",
            "Figure(1000x500)\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cote\n",
            "\n",
            "\n",
            "    data_name : data_name\n",
            "    n_search_samples : 300\n",
            "    p_norm : 1\n",
            "    step : 0.1\n",
            "    max_iter : 10\n",
            "    clamp : True\n",
            "    binary_cat_features : True\n",
            "    myvae_params : \n",
            "         input_dim : 21\n",
            "         kld_weight : 0.00025\n",
            "         layers : [25, 16]\n",
            "         latent_dim : 12\n",
            "         hidden_activation : relu\n",
            "         dropout : 0.2\n",
            "         batch_norm : True\n",
            "         batch_size : 32\n",
            "         epochs : 10\n",
            "         learning_rate : 0.001\n",
            "         weight_decay : 0.0\n",
            "         cuda : False\n",
            "         verbose : True\n",
            "         train : True\n",
            "         save_dir : ./vae_model/\n",
            "    tree_params : \n",
            "         min_entries_per_label : 900\n",
            "         grid_search_jobs : -1\n",
            "         min_weight_gini : 100\n",
            "         max_search : 100\n",
            "         grid_search : \n",
            "              cv : 1\n",
            "              splitter : ['best']\n",
            "              criterion : ['gini']\n",
            "              max_depth : [3, 4, 5, 6, 7, 8, 9, 10]\n",
            "              min_samples_split : [1.0, 2, 3]\n",
            "              min_samples_leaf : [1, 2, 3]\n",
            "              max_features : [0.4, 0.6, 0.8]\n",
            "{'input_dim': 21, 'kld_weight': 0.00025, 'layers': [25, 16], 'latent_dim': 12, 'hidden_activation': 'relu', 'dropout': 0.2, 'batch_norm': True, 'batch_size': 32, 'epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'cuda': False, 'verbose': True, 'train': True, 'save_dir': './vae_model/'}\n",
            "./vae_model/heloc\n",
            "Epoch: 0, ELBO Loss: 70.68479919433594, Test MSELoss: 29.08002471923828\n",
            "Epoch: 0, Best ELBO Loss: 70.68479919433594\n",
            "Epoch: 1, ELBO Loss: 22.25482940673828, Test MSELoss: 17.478681564331055\n",
            "BEST Epoch: 1, Best ELBO Loss: 22.25482940673828\n",
            "Epoch: 2, ELBO Loss: 15.135198593139648, Test MSELoss: 13.356536865234375\n",
            "BEST Epoch: 2, Best ELBO Loss: 15.135198593139648\n",
            "Epoch: 3, ELBO Loss: 12.768630981445312, Test MSELoss: 11.512604713439941\n",
            "BEST Epoch: 3, Best ELBO Loss: 12.768630981445312\n",
            "Epoch: 4, ELBO Loss: 11.408193588256836, Test MSELoss: 10.759087562561035\n",
            "BEST Epoch: 4, Best ELBO Loss: 11.408193588256836\n",
            "Epoch: 5, ELBO Loss: 10.75246524810791, Test MSELoss: 10.241772651672363\n",
            "BEST Epoch: 5, Best ELBO Loss: 10.75246524810791\n",
            "Epoch: 6, ELBO Loss: 10.157454490661621, Test MSELoss: 9.79447078704834\n",
            "BEST Epoch: 6, Best ELBO Loss: 10.157454490661621\n",
            "Epoch: 7, ELBO Loss: 9.767524719238281, Test MSELoss: 9.391100883483887\n",
            "BEST Epoch: 7, Best ELBO Loss: 9.767524719238281\n",
            "Epoch: 8, ELBO Loss: 9.492973327636719, Test MSELoss: 9.1946439743042\n",
            "BEST Epoch: 8, Best ELBO Loss: 9.492973327636719\n",
            "Epoch: 9, ELBO Loss: 9.147212982177734, Test MSELoss: 8.829331398010254\n",
            "BEST Epoch: 9, Best ELBO Loss: 9.147212982177734\n",
            "DT Warming Up...\n",
            "{'criterion': 'gini', 'max_depth': 6, 'max_features': 0.8, 'min_samples_leaf': 3, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "    data_name : data_name\n",
            "    n_search_samples : 300\n",
            "    p_norm : 1\n",
            "    step : 0.1\n",
            "    max_iter : 10\n",
            "    clamp : True\n",
            "    binary_cat_features : True\n",
            "    myvae_params : \n",
            "         input_dim : 21\n",
            "         kld_weight : 0.00025\n",
            "         layers : [25, 16]\n",
            "         latent_dim : 12\n",
            "         hidden_activation : relu\n",
            "         dropout : 0.2\n",
            "         batch_norm : True\n",
            "         batch_size : 32\n",
            "         epochs : 10\n",
            "         learning_rate : 0.001\n",
            "         weight_decay : 0.0\n",
            "         cuda : False\n",
            "         verbose : True\n",
            "         train : True\n",
            "         save_dir : ./vae_model/\n",
            "    tree_params : \n",
            "         min_entries_per_label : 900\n",
            "         grid_search_jobs : -1\n",
            "         min_weight_gini : 100\n",
            "         max_search : 100\n",
            "         grid_search : \n",
            "              cv : 1\n",
            "              splitter : ['best']\n",
            "              criterion : ['gini']\n",
            "              max_depth : [3, 4, 5, 6, 7, 8, 9, 10]\n",
            "              min_samples_split : [1.0, 2, 3]\n",
            "              min_samples_leaf : [1, 2, 3]\n",
            "              max_features : [0.4, 0.6, 0.8]\n",
            "{'input_dim': 21, 'kld_weight': 0.00025, 'layers': [25, 16], 'latent_dim': 12, 'hidden_activation': 'relu', 'dropout': 0.2, 'batch_norm': True, 'batch_size': 32, 'epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'cuda': False, 'verbose': True, 'train': True, 'save_dir': './vae_model/'}\n",
            "./vae_model/heloc\n",
            "Epoch: 0, ELBO Loss: 65.14067840576172, Test MSELoss: 28.023550033569336\n",
            "Epoch: 0, Best ELBO Loss: 65.14067840576172\n",
            "Epoch: 1, ELBO Loss: 22.376659393310547, Test MSELoss: 17.61761474609375\n",
            "BEST Epoch: 1, Best ELBO Loss: 22.376659393310547\n",
            "Epoch: 2, ELBO Loss: 15.392168998718262, Test MSELoss: 13.112568855285645\n",
            "BEST Epoch: 2, Best ELBO Loss: 15.392168998718262\n",
            "Epoch: 3, ELBO Loss: 12.56283950805664, Test MSELoss: 11.527127265930176\n",
            "BEST Epoch: 3, Best ELBO Loss: 12.56283950805664\n",
            "Epoch: 4, ELBO Loss: 11.230448722839355, Test MSELoss: 10.495970726013184\n",
            "BEST Epoch: 4, Best ELBO Loss: 11.230448722839355\n",
            "Epoch: 5, ELBO Loss: 10.407143592834473, Test MSELoss: 10.129742622375488\n",
            "BEST Epoch: 5, Best ELBO Loss: 10.407143592834473\n",
            "Epoch: 6, ELBO Loss: 9.948077201843262, Test MSELoss: 9.55721664428711\n",
            "BEST Epoch: 6, Best ELBO Loss: 9.948077201843262\n",
            "Epoch: 7, ELBO Loss: 9.381422996520996, Test MSELoss: 9.157381057739258\n",
            "BEST Epoch: 7, Best ELBO Loss: 9.381422996520996\n",
            "Epoch: 8, ELBO Loss: 8.99571704864502, Test MSELoss: 8.908910751342773\n",
            "BEST Epoch: 8, Best ELBO Loss: 8.99571704864502\n",
            "Epoch: 9, ELBO Loss: 8.651434898376465, Test MSELoss: 8.184721946716309\n",
            "BEST Epoch: 9, Best ELBO Loss: 8.651434898376465\n",
            "DT Warming Up...\n",
            "{'criterion': 'gini', 'max_depth': 5, 'max_features': 0.8, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method dice\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method growing_spheres\n",
            "\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method clue\n",
            "\n",
            "\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] \n",
            "Network: [train.py train_VAE]\n",
            "[INFO] \n",
            "Train: [train.py train_VAE]\n",
            "[INFO] init cost variables: [train.py train_VAE]\n",
            "[INFO] it 0/1, vlb -16.424848,  [train.py train_VAE]\n",
            "[INFO] time: 1.578137 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] vlb -12.552903 (-inf)\n",
            " [train.py train_VAE]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_heloc_models/theta_best.dat\n",
            " [utils.py save]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_heloc_models/theta_last.dat\n",
            " [utils.py save]\n",
            "[INFO] average time: 1.742139 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "RESULTS: [train.py train_VAE]\n",
            "[INFO] best_vlb_dev: -12.552903 [train.py train_VAE]\n",
            "[INFO] best_vlb_train: -16.424848 [train.py train_VAE]\n",
            "[INFO] nb_parameters: 1405 (1.37KB)\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] Reading /root/carla/models/autoencoders/clue/fc_VAE_heloc_models/theta_best.dat\n",
            " [utils.py load]\n",
            "[INFO] restoring epoch: 1, lr: 0.001000 [utils.py load]\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] \n",
            "Network: [train.py train_VAE]\n",
            "[INFO] \n",
            "Train: [train.py train_VAE]\n",
            "[INFO] init cost variables: [train.py train_VAE]\n",
            "[INFO] it 0/1, vlb -16.424848,  [train.py train_VAE]\n",
            "[INFO] time: 1.622612 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] vlb -12.552903 (-inf)\n",
            " [train.py train_VAE]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_heloc_models/theta_best.dat\n",
            " [utils.py save]\n",
            "[INFO] Writting /root/carla/models/autoencoders/clue/fc_VAE_heloc_models/theta_last.dat\n",
            " [utils.py save]\n",
            "[INFO] average time: 1.785316 seconds\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "RESULTS: [train.py train_VAE]\n",
            "[INFO] best_vlb_dev: -12.552903 [train.py train_VAE]\n",
            "[INFO] best_vlb_train: -16.424848 [train.py train_VAE]\n",
            "[INFO] nb_parameters: 1405 (1.37KB)\n",
            " [train.py train_VAE]\n",
            "[INFO] \n",
            "Net: [utils.py __init__]\n",
            "[INFO] VAE_gauss_net [fc_gauss_cat.py __init__]\n",
            "[INFO] Total params: 0.00M [fc_gauss_cat.py create_net]\n",
            "[INFO] Reading /root/carla/models/autoencoders/clue/fc_VAE_heloc_models/theta_best.dat\n",
            " [utils.py load]\n",
            "[INFO] restoring epoch: 1, lr: 0.001000 [utils.py load]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method causal_recourse\n",
            "\n",
            "\n",
            "Exception for causal_recourse\n",
            "\n",
            "Exception for causal_recourse\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cchvae\n",
            "\n",
            "\n",
            "[INFO] Start training of Variational Autoencoder... [vae.py fit]\n",
            "[INFO] [Epoch: 0/5] [objective: 35.175] [vae.py fit]\n",
            "[INFO] [ELBO train: 35.175] [vae.py fit]\n",
            "[INFO] [ELBO train: 16.142] [vae.py fit]\n",
            "[INFO] [ELBO train: 15.624] [vae.py fit]\n",
            "[INFO] [ELBO train: 15.033] [vae.py fit]\n",
            "[INFO] [ELBO train: 14.224] [vae.py fit]\n",
            "[INFO] ... finished training of Variational Autoencoder. [vae.py fit]\n",
            "[INFO] Start training of Variational Autoencoder... [vae.py fit]\n",
            "[INFO] [Epoch: 0/5] [objective: 27.387] [vae.py fit]\n",
            "[INFO] [ELBO train: 27.387] [vae.py fit]\n",
            "[INFO] [ELBO train: 15.914] [vae.py fit]\n",
            "[INFO] [ELBO train: 14.604] [vae.py fit]\n",
            "[INFO] [ELBO train: 12.852] [vae.py fit]\n",
            "[INFO] [ELBO train: 11.892] [vae.py fit]\n",
            "[INFO] ... finished training of Variational Autoencoder. [vae.py fit]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cruds\n",
            "\n",
            "\n",
            "[INFO] Start training of CSVAE... [csvae.py fit]\n",
            "  0% 0/5 [00:00<?, ?it/s][INFO] epoch 0: x recon loss: 0.11315858057883951 [csvae.py fit]\n",
            "[INFO] epoch 0: y recon loss: 54.97400492449023 [csvae.py fit]\n",
            " 20% 1/5 [00:09<00:38,  9.74s/it][INFO] epoch 1: x recon loss: 0.07007450414188568 [csvae.py fit]\n",
            "[INFO] epoch 1: y recon loss: 51.92797904647284 [csvae.py fit]\n",
            " 40% 2/5 [00:19<00:29,  9.87s/it][INFO] epoch 2: x recon loss: 0.05558230971843165 [csvae.py fit]\n",
            "[INFO] epoch 2: y recon loss: 49.414403382499884 [csvae.py fit]\n",
            " 60% 3/5 [00:30<00:20, 10.27s/it][INFO] epoch 3: x recon loss: 0.04832292181171453 [csvae.py fit]\n",
            "[INFO] epoch 3: y recon loss: 47.22845421639847 [csvae.py fit]\n",
            " 80% 4/5 [00:40<00:10, 10.36s/it][INFO] epoch 4: x recon loss: 0.043965074723785365 [csvae.py fit]\n",
            "[INFO] epoch 4: y recon loss: 45.304644177878174 [csvae.py fit]\n",
            "100% 5/5 [00:50<00:00, 10.10s/it]\n",
            "[INFO] ... finished training of CSVAE [csvae.py fit]\n",
            "[INFO] Start training of CSVAE... [csvae.py fit]\n",
            "  0% 0/5 [00:00<?, ?it/s][INFO] epoch 0: x recon loss: 0.08326804875411262 [csvae.py fit]\n",
            "[INFO] epoch 0: y recon loss: 46.69907000149724 [csvae.py fit]\n",
            " 20% 1/5 [00:09<00:39,  9.88s/it][INFO] epoch 1: x recon loss: 0.055058408272377304 [csvae.py fit]\n",
            "[INFO] epoch 1: y recon loss: 36.73893559403404 [csvae.py fit]\n",
            " 40% 2/5 [00:19<00:29,  9.76s/it][INFO] epoch 2: x recon loss: 0.04559041246442283 [csvae.py fit]\n",
            "[INFO] epoch 2: y recon loss: 33.38860886459597 [csvae.py fit]\n",
            " 60% 3/5 [00:29<00:19,  9.77s/it][INFO] epoch 3: x recon loss: 0.040844317515076264 [csvae.py fit]\n",
            "[INFO] epoch 3: y recon loss: 31.70767738132415 [csvae.py fit]\n",
            " 80% 4/5 [00:39<00:10, 10.04s/it][INFO] epoch 4: x recon loss: 0.037994148198840685 [csvae.py fit]\n",
            "[INFO] epoch 4: y recon loss: 30.693950255557557 [csvae.py fit]\n",
            "100% 5/5 [00:49<00:00,  9.88s/it]\n",
            "[INFO] ... finished training of CSVAE [csvae.py fit]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method focus\n",
            "\n",
            "\n",
            "Exception for focus\n",
            "ValueError: too many values to unpack (expected 5)\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 207, in __call__\n",
            "    return func(device, token, args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 109, in __call__\n",
            "    ret = self._func(*args)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 195, in f\n",
            "    self._prob_from_input,\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 58, in _filter_hinge_loss\n",
            "    filtered_loss = model_fn(filtered_input, sigma, temperature)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 265, in _prob_from_input\n",
            "    temperature=temperature,\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 127, in get_prob_classification_forest\n",
            "    tree_l = [tree_parser(estimator) for estimator in model.tree_iterator][\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 127, in <listcomp>\n",
            "    tree_l = [tree_parser(estimator) for estimator in model.tree_iterator][\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 120, in tree_parser\n",
            "    return get_prob_classification_tree(tree, feat_columns, feat_input, sigma)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 76, in get_prob_classification_tree\n",
            "    tree, feat_columns, feat_input, split_function\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 28, in _parse_class_tree\n",
            "    children_left, children_right, threshold, feature, scores = parse_booster(tree)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/parse_xgboost.py\", line 81, in parse_booster\n",
            "    ) = _parse_node(node)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/parse_xgboost.py\", line 52, in _parse_node\n",
            "    node_id, threshold, left_child, right_child, _ = numbers\n",
            "\n",
            "ValueError: too many values to unpack (expected 5)\n",
            "\n",
            "\n",
            "\t [[node EagerPyFunc_6 (defined at /content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py:249) ]]\n",
            "\n",
            "Original stack trace for 'EagerPyFunc_6':\n",
            "  File \"becnhmark_experiment.py\", line 323, in <module>\n",
            "    benchmark = Benchmark(model, rcmethod,  data_models.factuals.copy().reset_index(drop=True))\n",
            "  File \"/content/TreeBased_Carla/carla/evaluation/benchmark.py\", line 41, in __init__\n",
            "    self._counterfactuals = recourse_method.get_counterfactuals(factuals).astype(float)\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 249, in get_counterfactuals\n",
            "    pf = tfe.py_func(f, [best_perturb], tf.float32)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 392, in eager_py_func\n",
            "    return _internal_py_func(func=func, inp=inp, Tout=Tout, eager=True, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 281, in _internal_py_func\n",
            "    input=inp, token=token, Tout=Tout, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_script_ops.py\", line 74, in eager_py_func\n",
            "    \"EagerPyFunc\", input=input, token=token, Tout=Tout, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method actionable_recourse\n",
            "\n",
            "\n",
            "Exception for actionable_recourse\n",
            "Recourse method not known  actionable_recourse\n",
            "Exception for actionable_recourse\n",
            "Recourse method not known  actionable_recourse\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method cem\n",
            "\n",
            "\n",
            "Exception for cem\n",
            "Session Methods not supported yet\n",
            "Exception for cem\n",
            "Session Methods not supported yet\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method revisewachter\n",
            "\n",
            "\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method face\n",
            "\n",
            "\n",
            "Exception for face\n",
            "local variable 'immutable_constraint_matrix1' referenced before assignment\n",
            "Exception for face\n",
            "local variable 'immutable_constraint_matrix1' referenced before assignment\n",
            "----------------------------------------\n",
            "Starting experiment for recourse method feature_tweak\n",
            "\n",
            "\n",
            "Exception for feature_tweak\n",
            "ValueError: too many values to unpack (expected 5)\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 207, in __call__\n",
            "    return func(device, token, args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 109, in __call__\n",
            "    ret = self._func(*args)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 195, in f\n",
            "    self._prob_from_input,\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 58, in _filter_hinge_loss\n",
            "    filtered_loss = model_fn(filtered_input, sigma, temperature)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 265, in _prob_from_input\n",
            "    temperature=temperature,\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 127, in get_prob_classification_forest\n",
            "    tree_l = [tree_parser(estimator) for estimator in model.tree_iterator][\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 127, in <listcomp>\n",
            "    tree_l = [tree_parser(estimator) for estimator in model.tree_iterator][\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 120, in tree_parser\n",
            "    return get_prob_classification_tree(tree, feat_columns, feat_input, sigma)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 76, in get_prob_classification_tree\n",
            "    tree, feat_columns, feat_input, split_function\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/trees.py\", line 28, in _parse_class_tree\n",
            "    children_left, children_right, threshold, feature, scores = parse_booster(tree)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/parse_xgboost.py\", line 81, in parse_booster\n",
            "    ) = _parse_node(node)\n",
            "\n",
            "  File \"/content/TreeBased_Carla/carla/models/catalog/parse_xgboost.py\", line 52, in _parse_node\n",
            "    node_id, threshold, left_child, right_child, _ = numbers\n",
            "\n",
            "ValueError: too many values to unpack (expected 5)\n",
            "\n",
            "\n",
            "\t [[node EagerPyFunc_7 (defined at /content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py:249) ]]\n",
            "\n",
            "Original stack trace for 'EagerPyFunc_7':\n",
            "  File \"becnhmark_experiment.py\", line 323, in <module>\n",
            "    benchmark = Benchmark(model, rcmethod,  data_models.factuals.copy().reset_index(drop=True))\n",
            "  File \"/content/TreeBased_Carla/carla/evaluation/benchmark.py\", line 41, in __init__\n",
            "    self._counterfactuals = recourse_method.get_counterfactuals(factuals).astype(float)\n",
            "  File \"/content/TreeBased_Carla/carla/recourse_methods/catalog/focus/model.py\", line 249, in get_counterfactuals\n",
            "    pf = tfe.py_func(f, [best_perturb], tf.float32)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 392, in eager_py_func\n",
            "    return _internal_py_func(func=func, inp=inp, Tout=Tout, eager=True, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 281, in _internal_py_func\n",
            "    input=inp, token=token, Tout=Tout, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_script_ops.py\", line 74, in eager_py_func\n",
            "    \"EagerPyFunc\", input=input, token=token, Tout=Tout, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "\n",
            "\n",
            "FINISHED BENCHMARKING!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced"
      ],
      "metadata": {
        "id": "4_lPGM0Cof6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('outputs')"
      ],
      "metadata": {
        "id": "lZvDio9DLgCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from carla.data.api import data\n",
        "import numpy as np\n",
        "import torch\n",
        "torch.cuda.is_available = lambda : False\n",
        "import yaml\n",
        "from seed_env import seed_my_session\n",
        "from typing import Dict, List\n",
        "from cote.data_specific import DataModels\n",
        "from carla import Benchmark\n",
        "import pandas as pd\n",
        "from carla.recourse_methods import (\n",
        "    CCHVAE,\n",
        "    CEM,\n",
        "    CRUD,\n",
        "    FOCUS,\n",
        "    ActionableRecourse,\n",
        "    CausalRecourse,\n",
        "    Clue,\n",
        "    Dice,\n",
        "    Face,\n",
        "    FeatureTweak,\n",
        "    GrowingSpheres,\n",
        "    Revise,\n",
        "    Wachter,\n",
        ")\n",
        "from carla.recourse_methods.catalog.causal_recourse import constraints, samplers\n",
        "import carla.evaluation.catalog as evaluation_catalog\n",
        "#from cote.TreeResource import TreeBasedContrastiveExplanation\n",
        "from vae_benchmark import VAEBenchmark\n",
        "\n",
        "seed_my_session()\n",
        "data_name = 'heloc'\n",
        "FACTUAL_NUMBER = 20\n",
        "OUT_DIR = './outputs/'\n",
        "if not os.path.exists(OUT_DIR):\n",
        "    os.makedirs(OUT_DIR)\n",
        "OUT_DIR_DATA = os.path.join(OUT_DIR, data_name)\n",
        "if not os.path.exists(OUT_DIR_DATA):\n",
        "    os.makedirs(OUT_DIR_DATA)\n",
        "\n",
        "OUT_DIR_DATA_BENCH_CSVS = os.path.join(OUT_DIR_DATA, 'bench_csvs')\n",
        "if not os.path.exists(OUT_DIR_DATA_BENCH_CSVS):\n",
        "    os.makedirs(OUT_DIR_DATA_BENCH_CSVS)\n",
        "data_models = DataModels(data_name = data_name,\n",
        "                             factuals_length = FACTUAL_NUMBER,\n",
        "                             out_dir = OUT_DIR_DATA)\n",
        "temp_model = data_models.models_zoo['ann']['tensorflow']\n",
        "xxmutables = []\n",
        "for i in range(len(temp_model.feature_input_order)):\n",
        "    xxmutables.append(True)\n",
        "xxmutables = np.array(xxmutables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gba84zgo1Kfu",
        "outputId": "8f48c119-fafe-41eb-9ab6-56a80dde1ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models... --- logs will be saved to ./outputs/heloc/models_logs.txt\n",
            "[WARNING] From /content/TreeBased_Carla/carla/models/catalog/ANN_TF/model_ann.py:10: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            " [deprecation_wrapper.py __getattr__]\n",
            "[WARNING] From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            " [deprecation_wrapper.py __getattr__]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_models.dataset.df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySbMGXzcWfcb",
        "outputId": "aa966ac0-c6c4-4661-aef0-56cfb4412252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9871, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, List, Optional, Tuple, Union\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from matplotlib import pyplot as plt\n",
        "from carla.recourse_methods.processing import  merge_default_parameters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Build the VAE\n",
        "class VariationalAutoencoder(nn.Module):\n",
        "    _DEAFULT_PARAMS = {\n",
        "        'input_dim': 784,\n",
        "        'layers': [512, 128],\n",
        "        'latent_dim': 32,\n",
        "        'hidden_activation': 'relu',\n",
        "        'dropout': 0.2,\n",
        "        'batch_norm': True,\n",
        "        'batch_size': 64,\n",
        "        'epochs': 30,\n",
        "        'learning_rate': 0.001,\n",
        "        'kld_weight': 0.0025,\n",
        "        'weight_decay': 0.0,\n",
        "        'cuda': False,\n",
        "        'verbose': True,\n",
        "        'train': True,\n",
        "        'save_dir': './models',\n",
        "    }\n",
        "    def __init__(self, data_name: str, layers: List, mutable_mask, params = {}):\n",
        "        super(VariationalAutoencoder, self).__init__()\n",
        "        print(params)\n",
        "        self.params = merge_default_parameters(params, self._DEAFULT_PARAMS)\n",
        "        self.params['save_dir'] = os.path.join(self.params['save_dir'], data_name)\n",
        "        print(self.params['save_dir'])\n",
        "        # Define the encoder\n",
        "        self._encoder, self._mu_enc, self._log_var_enc = self.define_encoder()\n",
        "        # Define the decoder\n",
        "        self._mu_dec = self.define_decoder()\n",
        "        # Define the optimizer\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=self.params['learning_rate'],\n",
        "                                    weight_decay=self.params['weight_decay'])\n",
        "        # Define the loss function\n",
        "        self.criterion = nn.MSELoss(reduction='sum')\n",
        "        # Define the cuda\n",
        "        if self.params['cuda']:\n",
        "            self.cuda()\n",
        "        # Check if train is true\n",
        "        if not self.params['train']:\n",
        "            # Load the model from save_dir by searching for the path containing '_epoch_best_model.pth'\n",
        "            # Search for the path containing '_epoch_best_model.pth'\n",
        "            path = glob(os.path.join(self.params['save_dir'], '*_epoch_best_model.pth'))\n",
        "            # Assert if path is empty list\n",
        "            assert len(path) == 1, 'There should be only one file containing the best model, eith no checkpoint or more than one checkpoint'\n",
        "            path = path[0]\n",
        "            # Load the model\n",
        "            self.load_model(path)\n",
        "    \n",
        "    def load_model(self, path):\n",
        "        # Load the model\n",
        "        self.load_state_dict(torch.load(path))\n",
        "        # Print the model\n",
        "        print('Model loaded from {}'.format(path))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encode the input\n",
        "        mu, log_var = self.encode(x)\n",
        "        # Sample from the latent space\n",
        "        z = self.sample(mu, log_var)\n",
        "        # Decode the input\n",
        "        x_hat = self.decode(z)\n",
        "        # Return the mean and the log_var\n",
        "        return x_hat, mu, log_var\n",
        "\n",
        "\n",
        "    # Define plot loss\n",
        "    def plot_loss(self):\n",
        "        #self.loss_list = {'Steps':[],'Loss':[],\n",
        "        #                  'Epoch_Loss':[],'Best_Epoch_Loss':[],\n",
        "        #                  'Epochs':[]}\n",
        "        \n",
        "        # Plot Loss Vs Steps\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.plot(self.loss_list['Steps'], self.loss_list['Loss'], label='Loss', color='red')\n",
        "        # Set the x-axis label\n",
        "        plt.xlabel('Steps')\n",
        "        # Set the y-axis label\n",
        "        plt.ylabel('Loss')\n",
        "        # Set the title\n",
        "        plt.title('Loss Vs Steps')\n",
        "        # Set the legend\n",
        "        plt.legend()\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "        # Plot Epoch Loss and Best Epoch Loss Vs Epochs\n",
        "        plt.figure(figsize=(10,5))\n",
        "        # Plot Epoch Loss in red\n",
        "        plt.plot(self.loss_list['Epochs'], self.loss_list['Epoch_Loss'], label='Loss', color='red')\n",
        "        # Plot Best Epoch Loss in blue\n",
        "        plt.plot(self.loss_list['Epochs'], self.loss_list['Best_Epoch_Loss'], label='Best Loss', color='blue', linestyle='dashdot')\n",
        "        # Plot Best Epoch Loss in blue\n",
        "        plt.plot(self.loss_list['Epochs'], self.loss_list['Epoch_Test_MSE'], label='Test MSE Loss', color='green', linestyle='dashdot')\n",
        "        # Set the x-axis label\n",
        "        plt.xlabel('Epochs')\n",
        "        # Set the y-axis label\n",
        "        plt.ylabel('Loss')\n",
        "        # Set the title\n",
        "        plt.title('Loss Vs Epochs')\n",
        "        # Set the legend\n",
        "        plt.legend()\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "    # Define training function\n",
        "    def fit(self, xtrain: Union[pd.DataFrame, np.ndarray]\n",
        "    ):\n",
        "        # Create save_dir if it doesn't exist\n",
        "        if not os.path.exists(self.params['save_dir']):\n",
        "            os.makedirs(self.params['save_dir'])\n",
        "        # Set the model to train mode\n",
        "        self.train()\n",
        "        # Define loss list for visualization\n",
        "        self.loss_list = {'Steps':[],'Loss':[],\n",
        "                          'Epoch_Loss':[],'Epoch_Test_MSE':[],'Best_Epoch_Loss':[],\n",
        "                          'Epochs':[]}\n",
        "        # Define Best loss param\n",
        "        best_loss = -1\n",
        "        best_checkpoint_path = None\n",
        "        if isinstance(xtrain, pd.DataFrame):\n",
        "            xtrain = xtrain.values\n",
        "        \n",
        "        # Split xtrain to train and test\n",
        "        xtrain, xtest = train_test_split(xtrain, test_size=0.2, random_state=42)\n",
        "\n",
        "        xtrain = torch.from_numpy(xtrain).type(torch.FloatTensor)\n",
        "        xtest = torch.from_numpy(xtest).type(torch.FloatTensor)\n",
        "\n",
        "        # loop on self.params['epochs']\n",
        "        for epoch in range(self.params['epochs']):\n",
        "            train_loader = torch.utils.data.DataLoader(\n",
        "                xtrain, batch_size=self.params['batch_size'], shuffle=True\n",
        "            )\n",
        "            loss_epoch = []\n",
        "            # loop on the batches\n",
        "            for i, (x) in enumerate(train_loader):\n",
        "                if self.params['cuda']:\n",
        "                    x = x.cuda()\n",
        "                # Forward pass\n",
        "                x_hat, mu, log_var = self.forward(x)\n",
        "                # Compute the loss\n",
        "                loss = self.loss_function(x, x_hat, mu, log_var)\n",
        "                # Backward pass\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                loss_val = loss.data.detach().numpy()\n",
        "                self.loss_list['Loss'].append(loss_val)\n",
        "                steps = epoch * len(train_loader) + i\n",
        "                self.loss_list['Steps'].append(steps)\n",
        "                loss_epoch.append(loss_val)\n",
        "            \n",
        "            test_loader = torch.utils.data.DataLoader(\n",
        "                xtest, batch_size=self.params['batch_size'], shuffle=True\n",
        "            )\n",
        "            loss_epoch_test = []\n",
        "            # loop on the batches\n",
        "            for i, (x) in enumerate(test_loader):\n",
        "                if self.params['cuda']:\n",
        "                    x = x.cuda()\n",
        "                # Forward pass\n",
        "                x_hat, mu, log_var = self.forward(x)\n",
        "                # Compute the MSE loss\n",
        "                loss_epoch_test.append(self.criterion(x_hat, x).detach().numpy())\n",
        "            # Compute the mean loss\n",
        "            loss_epoch_test = np.mean(loss_epoch_test)\n",
        "            self.loss_list['Epoch_Test_MSE'].append(loss_epoch_test)\n",
        "\n",
        "            print('Epoch: {}, ELBO Loss: {}, Test MSELoss: {}'.format(epoch, np.mean(loss_epoch), loss_epoch_test))\n",
        "            if epoch == 0:\n",
        "                # Set best_loss to loss_epoch mean\n",
        "                best_loss = np.mean(loss_epoch)\n",
        "                print('Epoch: {}, Best ELBO Loss: {}'.format(epoch, best_loss))\n",
        "                best_checkpoint_path = os.path.join(self.params['save_dir'], '{}_epoch_best_model.pth'.format(epoch))\n",
        "                # Save the model to the epoch_best_model.pth\n",
        "                torch.save(self.state_dict(), best_checkpoint_path)\n",
        "            else:\n",
        "                # If loss_epoch mean is better than best_loss, set best_loss to loss_epoch mean\n",
        "                if np.mean(loss_epoch) < best_loss:\n",
        "                    best_loss = np.mean(loss_epoch)\n",
        "                    print('BEST Epoch: {}, Best ELBO Loss: {}'.format(epoch, best_loss))\n",
        "                    # Remove the previous best_checkpoint_path\n",
        "                    os.remove(best_checkpoint_path)\n",
        "                    # Save the model to the epoch_best_model.pth\n",
        "                    best_checkpoint_path = os.path.join(self.params['save_dir'], '{}_epoch_best_model.pth'.format(epoch))\n",
        "                    torch.save(self.state_dict(), best_checkpoint_path)\n",
        "            self.loss_list['Epoch_Loss'].append(np.mean(loss_epoch))\n",
        "            self.loss_list['Best_Epoch_Loss'].append(best_loss)\n",
        "            self.loss_list['Epochs'].append(epoch)\n",
        "        self.eval()    \n",
        "    \n",
        "    def loss_function(self, x, x_hat, mu, log_var):\n",
        "        # Compute the loss\n",
        "        loss = self.criterion(x_hat, x)\n",
        "        # Add the KL divergence\n",
        "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(),\n",
        "                                               dim = 1), dim = 0)\n",
        "        # Return the loss\n",
        "        loss = loss + self.params['kld_weight'] * kld_loss\n",
        "        return loss\n",
        "\n",
        "    def get_encodings(self, x):\n",
        "        if isinstance(x, pd.DataFrame):\n",
        "            x = x.values\n",
        "        if isinstance(x, list):\n",
        "            x = np.array(x)\n",
        "        x = torch.from_numpy(x).type(torch.FloatTensor)\n",
        "        mu, log_var = self.encode(x)\n",
        "        return self.sample(mu, log_var).detach().numpy()\n",
        "\n",
        "    def sample(self, mu, log_var):\n",
        "        # Sample from the latent space\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self._encoder(x)\n",
        "        # Encode the input\n",
        "        h = self._mu_enc(x)\n",
        "        # Return the mean and the log_var\n",
        "        return h, self._log_var_enc(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        # Decode the input\n",
        "        h = self._mu_dec(z)\n",
        "        # Return the mean and the log_var\n",
        "        return h\n",
        "\n",
        "    def define_decoder(self):\n",
        "        decoder_layers = []\n",
        "        layers = self.params['layers'][::-1]\n",
        "        for i in range(len(layers)):\n",
        "            if i == 0:\n",
        "                decoder_layers.append(nn.Linear(self.params['latent_dim'], layers[i]))\n",
        "            else:\n",
        "                decoder_layers.append(nn.Linear(layers[i-1], layers[i]))\n",
        "            if self.params['batch_norm']:\n",
        "                decoder_layers.append(nn.BatchNorm1d(layers[i]))\n",
        "            # Check if activation name is valid in the torch.nn.functional\n",
        "            if self.params['hidden_activation'].lower() == 'relu':\n",
        "                decoder_layers.append(nn.ReLU())\n",
        "            if self.params['dropout'] > 0:\n",
        "                decoder_layers.append(nn.Dropout(self.params['dropout']))\n",
        "                \n",
        "        # Define the decoder\n",
        "        decoder = nn.Sequential(*decoder_layers)\n",
        "        # Define the mu\n",
        "        mu_dec = nn.Linear(layers[-1], self.params['input_dim'])\n",
        "        mu_dec = nn.Sequential(decoder, mu_dec)\n",
        "        \n",
        "        return mu_dec\n",
        "\n",
        "    def define_encoder(self):\n",
        "        encoder_layers = []\n",
        "        for i in range(len(self.params['layers'])):\n",
        "            if i == 0:\n",
        "                encoder_layers.append(nn.Linear(self.params['input_dim'], self.params['layers'][i]))\n",
        "            else:\n",
        "                encoder_layers.append(nn.Linear(self.params['layers'][i-1], self.params['layers'][i]))\n",
        "            if self.params['batch_norm']:\n",
        "                encoder_layers.append(nn.BatchNorm1d(self.params['layers'][i]))\n",
        "            # Check if activation name is valid in the torch.nn.functional\n",
        "            if self.params['hidden_activation'].lower() == 'relu':\n",
        "                encoder_layers.append(nn.ReLU())\n",
        "            if self.params['dropout'] > 0:\n",
        "                encoder_layers.append(nn.Dropout(self.params['dropout']))\n",
        "        # Define the encoder\n",
        "        encoder = nn.Sequential(*encoder_layers)\n",
        "        # Define the mu\n",
        "        mu_enc = nn.Linear(self.params['layers'][-1], self.params['latent_dim'])\n",
        "        mu_enc = nn.Sequential(mu_enc)\n",
        "        # Define the log_var\n",
        "        log_var_enc = nn.Linear(self.params['layers'][-1], self.params['latent_dim'])\n",
        "        log_var_enc = nn.Sequential(log_var_enc)\n",
        "        return encoder, mu_enc, log_var_enc"
      ],
      "metadata": {
        "id": "KyWz3nTQ6d_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from carla.evaluation.api import Evaluation\n",
        "from carla.recourse_methods.processing import merge_default_parameters\n",
        "from carla.evaluation import remove_nans\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "class VAEBenchmark(Evaluation):\n",
        "    \"\"\"\n",
        "    Computes the euclidean distance between the latent spaces between the counterfactuals and factuals\n",
        "    \"\"\"\n",
        "    _DEFAULT_HYPERPARAMS = {\n",
        "        \"myvae_params\": {\n",
        "            'input_dim': None,\n",
        "            'kld_weight': 0.0025,\n",
        "            'layers': [20, 10],\n",
        "            'latent_dim': 7,\n",
        "            'hidden_activation': 'relu',\n",
        "            'dropout': 0.2,\n",
        "            'batch_norm': True,\n",
        "            'batch_size': 64,\n",
        "            'epochs': 20,\n",
        "            'learning_rate': 0.001,\n",
        "            'weight_decay': 0.0,\n",
        "            'cuda': False,\n",
        "            'verbose': True,\n",
        "            'train': True,\n",
        "            'save_dir': './vae_model/'\n",
        "        }\n",
        "    }\n",
        "    def __init__(self, mlmodel, hyperparameters):\n",
        "        hyperparameters = merge_default_parameters(hyperparameters, self._DEFAULT_HYPERPARAMS)\n",
        "        super().__init__(mlmodel, hyperparameters)\n",
        "        hyperparameters['myvae_params']['input_dim'] = len(mlmodel.feature_input_order)\n",
        "        self.columns = [\"VAE-Euclidean-Distance\"]\n",
        "        self._initialize_vae(vae_params = hyperparameters['myvae_params'])\n",
        "\n",
        "    def _initialize_vae(self, vae_params):\n",
        "        data_name = self.mlmodel.data.name\n",
        "        mutable_list = self.mlmodel.get_mutable_mask() \n",
        "        self.vae = VariationalAutoencoder(\n",
        "            data_name, vae_params[\"layers\"], mutable_list, vae_params\n",
        "        )\n",
        "\n",
        "        self.vae.fit(xtrain=self.mlmodel.data.df[self.mlmodel.feature_input_order])\n",
        "    \n",
        "    def get_minkowski_distance(self, v1s, v2s, p = 2):\n",
        "        '''\n",
        "        Compute the Minkowski distance between two vectors\n",
        "        p should be a positive integer\n",
        "        if p = 1, this is equivalent to the Manhattan distance\n",
        "        if p = 2, this is equivalent to the Euclidean distance\n",
        "        '''\n",
        "        return np.linalg.norm(v1s - v2s, ord=p, axis = 1)\n",
        "\n",
        "    def get_distances(self, arr_f, arr_cf):\n",
        "        '''\n",
        "        Compute the VAE distance between two vectors\n",
        "        '''\n",
        "        vae_distances = self.get_minkowski_distance(arr_f, arr_cf, p = 2)\n",
        "        return vae_distances\n",
        "\n",
        "    def get_evaluation(self, factuals, counterfactuals):\n",
        "        # only keep the rows for which counterfactuals could be found\n",
        "        counterfactuals_without_nans, factuals_without_nans = remove_nans(\n",
        "            counterfactuals, factuals\n",
        "        )\n",
        "\n",
        "        # return empty dataframe if no successful counterfactuals\n",
        "        if counterfactuals_without_nans.empty:\n",
        "            return pd.DataFrame(columns=self.columns)\n",
        "        \n",
        "\n",
        "        arr_f = self.mlmodel.get_ordered_features(factuals_without_nans).to_numpy()\n",
        "        arr_cf = self.mlmodel.get_ordered_features(\n",
        "            counterfactuals_without_nans\n",
        "        ).to_numpy()\n",
        "\n",
        "        # Get the VAE encodings for the factuals and counterfactuals\n",
        "        arr_f = torch.FloatTensor(arr_f)\n",
        "        arr_cf = torch.FloatTensor(arr_cf)\n",
        "\n",
        "        vae_encodings_f = self.vae.encode(arr_f)[0].detach().numpy()\n",
        "        vae_encodings_cf = self.vae.encode(arr_cf)[0].detach().numpy()\n",
        "\n",
        "        # Get the VAE distances between the factuals and counterfactuals\n",
        "        vae_distances = self.get_distances(vae_encodings_f, vae_encodings_cf)\n",
        "        \n",
        "        return pd.DataFrame(vae_distances, columns=self.columns)"
      ],
      "metadata": {
        "id": "tqc_DaJn7P01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae_parms = { \n",
        "    \"myvae_params\": {\n",
        "        'input_dim': len(temp_model.feature_input_order),\n",
        "        'kld_weight': 0.003,\n",
        "        'layers': [20],\n",
        "        'latent_dim': 7,\n",
        "        'hidden_activation': 'relu',\n",
        "        'dropout': 0.2,\n",
        "        'batch_norm': True,\n",
        "        'batch_size': 64,\n",
        "        'epochs': 5,\n",
        "        'learning_rate': 0.001,\n",
        "        'weight_decay': 0.0,\n",
        "        'cuda': False,\n",
        "        'verbose': True,\n",
        "        'train': True,\n",
        "        'save_dir': './vae_model/',\n",
        "    }\n",
        "}\n",
        "print(\"VAEBenchmark dict: \",vae_parms)\n",
        "vae_bench = VAEBenchmark(temp_model, vae_parms)"
      ],
      "metadata": {
        "id": "Qz9JqBH_1gVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae_bench.vae.plot_loss()"
      ],
      "metadata": {
        "id": "ygN_VOVS3NgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/TreeBased_Carla"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8M_kETd26Vr",
        "outputId": "d1766ee2-d8f2-4cd2-9a19-c816db4d1a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TreeBased_Carla\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Images"
      ],
      "metadata": {
        "id": "4Juhd_zajnzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from carla.data.api import data\n",
        "import numpy as np\n",
        "import torch\n",
        "torch.cuda.is_available = lambda : False\n",
        "import yaml\n",
        "from seed_env import seed_my_session\n",
        "from typing import Dict, List\n",
        "from cote.data_specific import DataModels\n",
        "from carla import Benchmark\n",
        "import pandas as pd\n",
        "from carla.recourse_methods import (\n",
        "    CCHVAE,\n",
        "    CEM,\n",
        "    CRUD,\n",
        "    FOCUS,\n",
        "    ActionableRecourse,\n",
        "    CausalRecourse,\n",
        "    Clue,\n",
        "    Dice,\n",
        "    Face,\n",
        "    FeatureTweak,\n",
        "    GrowingSpheres,\n",
        "    Revise,\n",
        "    Wachter,\n",
        ")\n",
        "from carla.recourse_methods.catalog.causal_recourse import constraints, samplers\n",
        "import carla.evaluation.catalog as evaluation_catalog\n",
        "from cote.TreeResource import TreeBasedContrastiveExplanation\n",
        "from vae_benchmark import VAEBenchmark\n",
        "\n",
        "seed_my_session()\n",
        "def load_setup() -> Dict:\n",
        "    with open(\"experimental_setup.yaml\", \"r\") as f:\n",
        "        setup_catalog = yaml.safe_load(f)\n",
        "    return setup_catalog[\"recourse_methods\"]\n",
        "\n",
        "def print_conf(conf, d=4, d_iter=5):\n",
        "    for k, v in conf.items():\n",
        "        if isinstance(v, dict):\n",
        "            print(\"{}{} : \".format(d * \" \", str(k)))\n",
        "            print_conf(v, d + d_iter)\n",
        "        elif isinstance(v, list) and len(v) >= 1 and isinstance(v[0], dict):\n",
        "            print(\"{}{} : \".format(d * \" \", str(k)))\n",
        "            for value in v:\n",
        "                print_conf(value, d + d_iter)\n",
        "        else:\n",
        "            print(\"{}{} : {}\".format(d * \" \", k, v))\n",
        "        \n",
        "def get_resource_supported_backend(recourse_method, supported_backend_dict):\n",
        "    '''\n",
        "    Search in supported_backend for the recourse_method to know what backend is supported\n",
        "    '''\n",
        "    # supported_backend contains 'pytorch', 'tensorflow', 'xgboost', 'sklearn'\n",
        "    # Check what backend contains the recourse_method\n",
        "    suuported_backs = []\n",
        "    for backend in supported_backend_dict:\n",
        "        if recourse_method in supported_backend_dict[backend]:\n",
        "            suuported_backs.append(backend)\n",
        "    # If tensorflow and pytorch are in the list, keep only tensorflow\n",
        "    if \"tensorflow\" in suuported_backs and \"pytorch\" in suuported_backs:\n",
        "        # Remove pytorch from the list\n",
        "        suuported_backs.remove(\"pytorch\")\n",
        "    # Similarly for xgboost and sklearn, keep xgboost\n",
        "    if \"xgboost\" in suuported_backs and \"sklearn\" in suuported_backs:\n",
        "        suuported_backs.remove(\"sklearn\")\n",
        "    #TODO: Keep both, but temp return only first\n",
        "    return suuported_backs[0]\n",
        "\n",
        "def intialialize_recourse_method(method, hyperparams, mlmodel, data_models):\n",
        "    # TODO restrict data to training only\n",
        "    if method == \"cchvae\":\n",
        "        hyperparams[\"data_name\"] = data_name\n",
        "        hyperparams[\"vae_params\"][\"layers\"] = [\n",
        "            len(mlmodel.feature_input_order)\n",
        "        ] + hyperparams[\"vae_params\"][\"layers\"]\n",
        "        return CCHVAE(mlmodel, hyperparams)\n",
        "    elif \"cem\" in method:\n",
        "        hyperparams[\"data_name\"] = data_name\n",
        "        raise ValueError(\"Session Methods not supported yet\")\n",
        "        #return CEM(sess, mlmodel, hyperparams)\n",
        "    elif method == \"clue\":\n",
        "        hyperparams[\"data_name\"] = data_name\n",
        "        return Clue(mlmodel.data, mlmodel, hyperparams)\n",
        "    elif method == \"cruds\":\n",
        "        hyperparams[\"data_name\"] = data_name\n",
        "        # variable input layer dimension is first time here available\n",
        "        hyperparams[\"vae_params\"][\"layers\"] = [\n",
        "            len(mlmodel.feature_input_order)\n",
        "        ] + hyperparams[\"vae_params\"][\"layers\"]\n",
        "        return CRUD(mlmodel, hyperparams)\n",
        "    elif method == \"dice\":\n",
        "        return Dice(mlmodel, hyperparams)\n",
        "    elif \"face\" in method:\n",
        "        return Face(mlmodel, hyperparams)\n",
        "    elif method == \"growing_spheres\":\n",
        "        return GrowingSpheres(mlmodel)\n",
        "    elif method == \"revise\":\n",
        "        hyperparams[\"data_name\"] = data_name\n",
        "        # variable input layer dimension is first time here available\n",
        "        hyperparams[\"vae_params\"][\"layers\"] = [\n",
        "            len(mlmodel.feature_input_order)\n",
        "        ] + hyperparams[\"vae_params\"][\"layers\"]\n",
        "        return Revise(mlmodel, mlmodel.data, hyperparams)\n",
        "    elif \"wachter\" in method:\n",
        "        return Wachter(mlmodel, hyperparams)\n",
        "    elif \"causal_recourse\" in method:\n",
        "        return CausalRecourse(mlmodel, hyperparams)\n",
        "    elif \"focus\" in method:\n",
        "        hyperparams = {'optimizer': 'adam', 'lr': 0.001, 'n_class': 2, 'n_iter': 1000, 'sigma': 1.0, 'temperature': 1.0, 'distance_weight': 0.01, 'distance_func': 'l1'}\n",
        "        return FOCUS(mlmodel, hyperparams)\n",
        "    elif \"feature_tweak\" in method:\n",
        "        return FOCUS(mlmodel, hyperparams)\n",
        "    elif \"cote\" in method:\n",
        "        min_entries_per_label = int(data_models.trainData.df.shape[0]*0.02)\n",
        "        if min_entries_per_label<5000:\n",
        "            min_entries_per_label = 5000\n",
        "        hpr = {\"data_name\": \"data_name\",\"n_search_samples\": 300,\"p_norm\": 1,\"step\": 0.1,\"max_iter\": 10,\"clamp\": True,\n",
        "                \"binary_cat_features\": True,\n",
        "                \"myvae_params\": {\n",
        "                    'input_dim': len(mlmodel.feature_input_order),\n",
        "                    'kld_weight': 0.00025,\n",
        "                    'layers': layers,\n",
        "                    'latent_dim': latent_dim,\n",
        "                    'hidden_activation': 'relu',\n",
        "                    'dropout': 0.2,\n",
        "                    'batch_norm': True,\n",
        "                    'batch_size': 32,\n",
        "                    'epochs': 10,\n",
        "                    'learning_rate': 0.001,\n",
        "                    'weight_decay': 0.0,\n",
        "                    'cuda': False,\n",
        "                    'verbose': True,\n",
        "                    'train': True,\n",
        "                    'save_dir': './vae_model/',\n",
        "                },\n",
        "                \"tree_params\": {\n",
        "                    \"min_entries_per_label\": min_entries_per_label,\n",
        "                    \"grid_search_jobs\": -1,\n",
        "                    \"min_weight_gini\": 10, # set to 0.5 since here both class have same prob,\n",
        "                    \"max_search\" : 100,\n",
        "                    \"grid_search\": {\"cv\": 1,\"splitter\": [\"best\"],\"criterion\": [\"gini\"],\"max_depth\": [60],\n",
        "                                    \"min_samples_split\": [1.0,2,3],\"min_samples_leaf\": [1,2,3],\n",
        "                                    \"max_features\": [0.6],\n",
        "                                    }\n",
        "                }\n",
        "          }\n",
        "        print_conf(hpr)\n",
        "        return TreeBasedContrastiveExplanation(data_models.trainData, mlmodel, hpr, data_catalog= data_models.new_catalog_n)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Recourse method not known  {}\".format(method))\n"
      ],
      "metadata": {
        "id": "uzDeQIMwubrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "169f0385-bf32-4f59-cdde-4e8d02ab819e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n",
            "[INFO] NumExpr defaulting to 2 threads. [utils.py _init_num_threads]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from carla import MLModelCatalog\n",
        "from carla.data.catalog import OnlineCatalog\n",
        "from carla.recourse_methods import GrowingSpheres\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "import contextlib\n",
        "from seed_env import seed_my_session\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from carla.data.api import data, Data\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Seed the environment\n",
        "seed_my_session()\n",
        "\n",
        "def score_acc(model):\n",
        "    dataset = model.data\n",
        "    data = dataset.df\n",
        "    input_cols = model.feature_input_order\n",
        "    target_column = dataset.target\n",
        "    X = data[input_cols]\n",
        "    y = data[target_column]\n",
        "    y_pred = model.predict(X)\n",
        "    y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "class MyData:\n",
        "  def __init__(self, data, target, immutables):\n",
        "    self.df = data\n",
        "    self.target = target\n",
        "    self.immutables = immutables\n",
        "\n",
        "def load_mnist_fashionmnist(data_name):\n",
        "    if data_name == 'fashionmnist':\n",
        "        data = torchvision.datasets.FashionMNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor()\n",
        "                             ]))\n",
        "    elif data_name == 'mnist':\n",
        "        print(data_name)\n",
        "        data = torchvision.datasets.MNIST('/files/', train=True, download=False,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor()\n",
        "                             ]))\n",
        "    else:\n",
        "        raise ValueError('data_name must be either \"mnist\" or \"fashionmnist\"')\n",
        "    # Load data to pandas DataFrame\n",
        "    df_values = []\n",
        "    for i in tqdm(range(len(data))):\n",
        "\n",
        "        # Get the image and the label\n",
        "        image = data[i][0]\n",
        "        # Reshape the image from (28,28) to (784)\n",
        "        image = image.view(28*28)\n",
        "        # Get the label\n",
        "        label = data[i][1]\n",
        "        # Create a list where the first element is 0x0 pixel, second element is the 0x1 pixel, etc. and last element is the label\n",
        "        # Get the pixels liste form image\n",
        "        pixels = image.tolist()\n",
        "        # Create a list where the first element is 0x0 pixel, second element is the 0x1 pixel, etc. and last element is the label\n",
        "        pixels = pixels + [label]\n",
        "        # Append the pixels list to the df_values list\n",
        "        df_values.append(pixels)\n",
        "\n",
        "    # Create a pandas DataFrame from the df_values list\n",
        "    # The columns names will be e.g. [\"0x0\",\"0x1\",....\"label\"]\n",
        "    columns=[]\n",
        "    for i in range(28):\n",
        "        for j in range(28):\n",
        "            columns.append(str(i)+\"x\"+str(j))\n",
        "    columns.append(\"label\")\n",
        "    df_data = pd.DataFrame(df_values, columns=columns)\n",
        "    return df_data\n",
        "\n",
        "class MnistData(Data):\n",
        "    def __init__(self, data_name, labels_needed, n= 28):\n",
        "        # the dataset could be loaded in the constructor\n",
        "        dataset = load_mnist_fashionmnist(data_name)\n",
        "        dataset = dataset[dataset['label'].isin(labels_needed)]\n",
        "        dataset['label'] = dataset['label'].map({labels_needed[0]: 0, labels_needed[1]: 1})\n",
        "        self._dataset = dataset\n",
        "        for coli in self._dataset.columns:\n",
        "            if coli == 'label':\n",
        "                continue\n",
        "            #self._dataset[coli] = self._dataset[coli] / 255.0\n",
        "        self._identity_encoding = True\n",
        "        self.df_train, self.df_test = train_test_split(self._dataset, test_size=0.2)\n",
        "        self.continuous = [str(i)+\"x\"+str(j) for i in range(n) for j in range(n)]#[]\n",
        "        # self.categorical = [\"pixel_\"+str(i)+\"_\"+str(j) for i in range(n) for j in range(n)]\n",
        "        self.categorical = []#[str(i)+\"x\"+str(j) for i in range(n) for j in range(n)]\n",
        "        self.immutables = []\n",
        "        self.target = 'label'\n",
        "        self.name = 'mnist'\n",
        "        self.df = self._dataset #.drop(columns=self.target)\n",
        "        self.catalog = {'categorical': self.categorical,\n",
        "                      'continuous': self.continuous,\n",
        "                      'immutable': self.immutables,\n",
        "                      'target': self.target}\n",
        "    def categorical(self):\n",
        "        # this property contains a list of all categorical features\n",
        "        return self.categorical\n",
        "    def continuous(self):\n",
        "        # this property contains a list of all continuous features\n",
        "        return self.continuous\n",
        "\n",
        "    def immutables(self):\n",
        "        # this property contains a list of features which should not be changed by the recourse method\n",
        "        return self.immutables\n",
        "\n",
        "    def target(self):\n",
        "        # this property contains the feature name of the target column\n",
        "        return self.target\n",
        "\n",
        "    def raw(self):\n",
        "        # this property contains the not encoded and not normalized, raw dataset\n",
        "        return self._dataset\n",
        "\n",
        "    def df(self):\n",
        "        return self._dataset\n",
        "    def df_test(self):\n",
        "        return self.df_test \n",
        "\n",
        "    def df_train(self):\n",
        "        return self.df_train \n",
        "        \n",
        "    def inverse_transform(self):\n",
        "        return self._dataset \n",
        "\n",
        "    def transform(self):\n",
        "        return self._dataset\n",
        "\n",
        "class DataImagesModels:\n",
        "  def __init__(self, data_name, factuals_length = 50, out_dir = '', labels_needed = [3,6]):\n",
        "    logging_file = os.path.join(out_dir, 'models_logs.txt')\n",
        "    self.models_metrics_file = os.path.join(out_dir, 'model_zoo_metrics.csv')\n",
        "    self.data_name = data_name\n",
        "    # Load dataset\n",
        "    self.load_data_modesl(data_name=self.data_name, factuals_length = factuals_length, labels_needed = labels_needed)\n",
        "    # Load models\n",
        "    self.load_models(logging_file = logging_file)\n",
        "    # Get data features\n",
        "    self.get_data_features()\n",
        "\n",
        "  # load a catalog dataset\n",
        "  def load_data_modesl(self, data_name=\"\", factuals_length = 50, labels_needed = [3,6]):\n",
        "    self.dataset = MnistData(data_name=data_name, labels_needed = labels_needed)\n",
        "    # Prepare Training and Test Data\n",
        "    # test_size is the percentages of factuals to be used for testing\n",
        "    factuals_length_percentage = factuals_length/self.dataset.df.shape[0] * 3\n",
        "    self.data_train, self.data_test = train_test_split(self.dataset.df, test_size=factuals_length_percentage)\n",
        "    # Fill immutables with list of True the same length of the dataframe columns\n",
        "    self.immutables = [True] * len(self.data_train.columns)\n",
        "    self.trainData = MyData(self.data_train.copy(), self.dataset.target, self.dataset.immutables)\n",
        "\n",
        "    # load artificial neural network from catalog\n",
        "    self.factuals = self.data_test.sample(factuals_length)\n",
        "\n",
        "  # Load models by training data\n",
        "  def load_models(self, logging_file = 'models_logs.txt'):\n",
        "    dataset = self.dataset\n",
        "    print(\"Loading models... --- logs will be saved to {}\".format(logging_file))\n",
        "    with contextlib.redirect_stdout(open(logging_file, 'w')):\n",
        "      # Define models configs\n",
        "      parms_training = {\"ann\":    {\"learning_rate\": 0.002, \"epochs\": 2, \"batch_size\": 64, \"hidden_size\": [13,4]},\n",
        "                        \"linear\": {\"learning_rate\": 0.002, \"epochs\": 2, \"batch_size\": 64, \"hidden_size\": [13,4]}}\n",
        "      #                  \"forest\": {\"max_depth\": 10, \"n_estimators\": 5}}\n",
        "      # Define models_zoo to store models\n",
        "      self.models_zoo = {\"ann\": {\"tensorflow\": '', \"pytorch\": ''}, \n",
        "                    \"linear\": {\"tensorflow\": '', \"pytorch\": ''}}\n",
        "      #              \"forest\": {\"xgboost\": '', \"sklearn\": ''}}\n",
        "      # Start filling models_zoo\n",
        "      for model_type in self.models_zoo:\n",
        "        for framework in self.models_zoo[model_type]:\n",
        "          # Load model from catalog\n",
        "          model = MLModelCatalog(\n",
        "                      dataset,\n",
        "                      model_type=model_type,\n",
        "                      load_online=False,\n",
        "                      backend=framework)\n",
        "          # Train model\n",
        "          model.train(**parms_training[model_type])\n",
        "          \n",
        "          # Save model\n",
        "          self.models_zoo[model_type][framework] = model\n",
        "    # Save model metrics\n",
        "    frameworks = []\n",
        "    model_types = []\n",
        "    accuracies = []\n",
        "    for model_type in self.models_zoo:\n",
        "      for framework in self.models_zoo[model_type]:\n",
        "        frameworks.append(framework)\n",
        "        model_types.append(model_type)\n",
        "        accuracies.append(score_acc(self.models_zoo[model_type][framework]))\n",
        "    df = pd.DataFrame({\"framework\": frameworks, \"model_type\": model_types, \"accuracy\": accuracies})\n",
        "    df.to_csv(self.models_metrics_file , index=False)\n",
        "        \n",
        "  def get_data_features(self):\n",
        "    # Check our data catalog\n",
        "    col_n = self.dataset.df.columns\n",
        "    catalog_n = self.dataset.catalog\n",
        "    # Initialize new catalog\n",
        "    self.new_catalog_n = {'target': 'income', 'continuous': [], 'categorical': [], 'immutable': []}\n",
        "    # Map continuous values\n",
        "    for col_i in col_n:\n",
        "        # Assuming one hot encoder will map new columns after '_'\n",
        "        col = col_i.split('_')[0]\n",
        "        if col == self.dataset.target:\n",
        "            continue\n",
        "        if col in catalog_n['immutable']:\n",
        "            self.new_catalog_n['immutable'].append(col_i)\n",
        "        if col in catalog_n['continuous']:\n",
        "            self.new_catalog_n['continuous'].append(col_i)\n",
        "        elif col in catalog_n['categorical']:\n",
        "            self.new_catalog_n['categorical'].append(col_i)\n",
        "        else:\n",
        "            # Check if it is contained somewhere\n",
        "            col = col_i\n",
        "            if self.dataset.target in col:\n",
        "                continue\n",
        "            for im_ctn in catalog_n['immutable']:\n",
        "                if im_ctn in col:\n",
        "                    self.new_catalog_n['immutable'].append(col_i)\n",
        "                    break\n",
        "            not_continuous_flag = True\n",
        "            not_categorical_flag = True\n",
        "            for im_ctn in catalog_n['continuous']:\n",
        "                if im_ctn in col:\n",
        "                    self.new_catalog_n['continuous'].append(col_i)\n",
        "                    not_continuous_flag = False\n",
        "                    break\n",
        "            if not_continuous_flag:\n",
        "                for im_ctn in catalog_n['categorical']:\n",
        "                    if im_ctn in col:\n",
        "                        self.new_catalog_n['categorical'].append(col_i)\n",
        "                        not_categorical_flag = False\n",
        "                        break\n",
        "            if not_categorical_flag and not_continuous_flag:\n",
        "                assert False, 'Column not found in catalog {}, original {}\\n{}'.format(col_i, col, catalog_n)\n",
        "\n",
        "    # Assert if self.new_catalog_n is not same shape as catalog_n\n",
        "    assert len(self.new_catalog_n['continuous']) == len(catalog_n['continuous']), 'Continuous values not same shape'\n",
        "    assert len(self.new_catalog_n['categorical']) == len(catalog_n['categorical']), 'Categorical values not same shape'\n",
        "    assert len(self.new_catalog_n['immutable']) == len(catalog_n['immutable']), 'Immutable values not same shape'\n",
        "    # For each continous value get the std, mean, and min/max and plug them in the new catalog['continuous_stats']\n",
        "    self.new_catalog_n['continuous_stats'] = {}\n",
        "    for col_i in self.new_catalog_n['continuous']:\n",
        "        self.new_catalog_n['continuous_stats'][col_i] = {}\n",
        "        self.new_catalog_n['continuous_stats'][col_i]['std'] = self.data_train[col_i].std()\n",
        "        self.new_catalog_n['continuous_stats'][col_i]['mean'] = self.data_train[col_i].mean()\n",
        "        self.new_catalog_n['continuous_stats'][col_i]['min'] = self.data_train[col_i].min()\n",
        "        self.new_catalog_n['continuous_stats'][col_i]['max'] = self.data_train[col_i].max()\n"
      ],
      "metadata": {
        "id": "POfZEqcnjtpC"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shutil.rmtree('/root/carla/models/mnist')"
      ],
      "metadata": {
        "id": "7TK5EUaKrX7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir outputs"
      ],
      "metadata": {
        "id": "_PUJ9iHqH2tE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = DataImagesModels('mnist', labels_needed=[4,9], out_dir = 'outputs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "20a56e4db7144b168b251af410b26916",
            "a97d3d731ae54e5286dece9a4fdcbd2f",
            "98b1667e11414cc59556fc18ecd31e9b",
            "7054be177e7142c7b9d7720dc04956be",
            "bd50dd3065144316aebe7cad9ece3fa5",
            "1dad21ba5e9840dfb9035151318b7624",
            "1e3c962a81334bc18ba7ca2ce039a47c",
            "9ab73af5fff144a6b40c0c94c599f91e",
            "c4d8513da93d4982a6405fb5f18e6583",
            "1016e422f2444a028d8a8f934261a177",
            "c90fab67bd9047a9a67ac0c01f35ae72"
          ]
        },
        "id": "gYswGl9LohhH",
        "outputId": "666055b1-619a-4388-afe4-23bf1752d7bd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mnist\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/60000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20a56e4db7144b168b251af410b26916"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models... --- logs will be saved to outputs/models_logs.txt\n",
            "[WARNING] From /content/TreeBased_Carla/carla/models/catalog/ANN_TF/model_ann.py:10: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            " [deprecation_wrapper.py __getattr__]\n",
            "[WARNING] From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            " [deprecation_wrapper.py __getattr__]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_models = mnist"
      ],
      "metadata": {
        "id": "ziP9c6ORuq0a"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_model = data_models.models_zoo['ann']['tensorflow']"
      ],
      "metadata": {
        "id": "i-ta9qokpBou"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(temp_model.feature_input_order) > 500:\n",
        "    layers = [500, 250]\n",
        "    latent_dim = 32\n",
        "elif len(temp_model.feature_input_order) > 100:\n",
        "    layers = [100, 50]\n",
        "    latent_dim = 24\n",
        "elif len(temp_model.feature_input_order) > 50:\n",
        "    layers = [50, 25]\n",
        "    latent_dim = 16\n",
        "elif len(temp_model.feature_input_order) > 20:\n",
        "    layers = [25, 16]\n",
        "    latent_dim = 12\n",
        "elif len(temp_model.feature_input_order) > 10:\n",
        "    layers = [25]\n",
        "    latent_dim = 8\n",
        "else:\n",
        "    layers = [16]\n",
        "    latent_dim = 7\n",
        "xxmutables = []\n",
        "for i in range(len(temp_model.feature_input_order)):\n",
        "    xxmutables.append(True)\n",
        "xxmutables = np.array(xxmutables)\n",
        "vae_parms = { \n",
        "    \"myvae_params\": {\n",
        "        'input_dim': len(temp_model.feature_input_order),\n",
        "        'kld_weight': 0.00025,\n",
        "        'layers': layers,\n",
        "        'latent_dim': latent_dim,\n",
        "        'hidden_activation': 'relu',\n",
        "        'dropout': 0.2,\n",
        "        'batch_norm': True,\n",
        "        'batch_size': 32,\n",
        "        'epochs': 20,\n",
        "        'learning_rate': 0.001,\n",
        "        'weight_decay': 0.0,\n",
        "        'cuda': False,\n",
        "        'verbose': True,\n",
        "        'train': True,\n",
        "        'save_dir': './vae_model/',\n",
        "    }\n",
        "}\n",
        "print_conf(vae_parms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-JBjsBFjts7",
        "outputId": "13b53fb3-d327-405c-b95e-7622d7f30b7a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    myvae_params : \n",
            "         input_dim : 784\n",
            "         kld_weight : 0.00025\n",
            "         layers : [500, 250]\n",
            "         latent_dim : 32\n",
            "         hidden_activation : relu\n",
            "         dropout : 0.2\n",
            "         batch_norm : True\n",
            "         batch_size : 32\n",
            "         epochs : 20\n",
            "         learning_rate : 0.001\n",
            "         weight_decay : 0.0\n",
            "         cuda : False\n",
            "         verbose : True\n",
            "         train : True\n",
            "         save_dir : ./vae_model/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from carla.evaluation.api import Evaluation\n",
        "from carla.recourse_methods.processing import merge_default_parameters\n",
        "from carla.evaluation import remove_nans\n",
        "from cote.vae import VariationalAutoencoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "class VAEBenchmark(Evaluation):\n",
        "    \"\"\"\n",
        "    Computes the euclidean distance between the latent spaces between the counterfactuals and factuals\n",
        "    \"\"\"\n",
        "    _DEFAULT_HYPERPARAMS = {\n",
        "        \"myvae_params\": {\n",
        "            'input_dim': None,\n",
        "            'kld_weight': 0.0025,\n",
        "            'layers': [20, 10],\n",
        "            'latent_dim': 7,\n",
        "            'hidden_activation': 'relu',\n",
        "            'dropout': 0.2,\n",
        "            'batch_norm': True,\n",
        "            'batch_size': 64,\n",
        "            'epochs': 20,\n",
        "            'learning_rate': 0.001,\n",
        "            'weight_decay': 0.0,\n",
        "            'cuda': False,\n",
        "            'verbose': True,\n",
        "            'train': True,\n",
        "            'save_dir': './vae_model/'\n",
        "        }\n",
        "    }\n",
        "    def __init__(self, mlmodel, hyperparameters):\n",
        "        hyperparameters = merge_default_parameters(hyperparameters, self._DEFAULT_HYPERPARAMS)\n",
        "        super().__init__(mlmodel, hyperparameters)\n",
        "        hyperparameters['myvae_params']['input_dim'] = len(mlmodel.feature_input_order)\n",
        "        self.columns = [\"VAE-Euclidean-Distance\"]\n",
        "        self._initialize_vae(vae_params = hyperparameters['myvae_params'])\n",
        "\n",
        "    def _initialize_vae(self, vae_params):\n",
        "        data_name = self.mlmodel.data.name\n",
        "        mutable_list = [True] * len(self.mlmodel.feature_input_order)\n",
        "        self.vae = VariationalAutoencoder(\n",
        "            data_name, vae_params[\"layers\"], mutable_list, vae_params\n",
        "        )\n",
        "\n",
        "        self.vae.fit(xtrain=self.mlmodel.data.df[self.mlmodel.feature_input_order])\n",
        "    \n",
        "    def get_minkowski_distance(self, v1s, v2s, p = 2):\n",
        "        '''\n",
        "        Compute the Minkowski distance between two vectors\n",
        "        p should be a positive integer\n",
        "        if p = 1, this is equivalent to the Manhattan distance\n",
        "        if p = 2, this is equivalent to the Euclidean distance\n",
        "        '''\n",
        "        return np.linalg.norm(v1s - v2s, ord=p, axis = 1)\n",
        "\n",
        "    def get_distances(self, arr_f, arr_cf):\n",
        "        '''\n",
        "        Compute the VAE distance between two vectors\n",
        "        '''\n",
        "        vae_distances = self.get_minkowski_distance(arr_f, arr_cf, p = 2)\n",
        "        return vae_distances\n",
        "\n",
        "    def get_evaluation(self, factuals, counterfactuals):\n",
        "        # only keep the rows for which counterfactuals could be found\n",
        "        counterfactuals_without_nans, factuals_without_nans = remove_nans(\n",
        "            counterfactuals, factuals\n",
        "        )\n",
        "\n",
        "        # return empty dataframe if no successful counterfactuals\n",
        "        if counterfactuals_without_nans.empty:\n",
        "            return pd.DataFrame(columns=self.columns)\n",
        "        \n",
        "\n",
        "        arr_f = self.mlmodel.get_ordered_features(factuals_without_nans).to_numpy()\n",
        "        arr_cf = self.mlmodel.get_ordered_features(\n",
        "            counterfactuals_without_nans\n",
        "        ).to_numpy()\n",
        "\n",
        "        # Get the VAE encodings for the factuals and counterfactuals\n",
        "        arr_f = torch.FloatTensor(arr_f)\n",
        "        arr_cf = torch.FloatTensor(arr_cf)\n",
        "\n",
        "        vae_encodings_f = self.vae.encode(arr_f)[0].detach().numpy()\n",
        "        vae_encodings_cf = self.vae.encode(arr_cf)[0].detach().numpy()\n",
        "\n",
        "        # Get the VAE distances between the factuals and counterfactuals\n",
        "        vae_distances = self.get_distances(vae_encodings_f, vae_encodings_cf)\n",
        "        \n",
        "        return pd.DataFrame(vae_distances, columns=self.columns)"
      ],
      "metadata": {
        "id": "EMLXWBklvKvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from pynndescent import NNDescent\n",
        "import enum\n",
        "from typing import Dict, List, Tuple, Union\n",
        "import pandas as pd\n",
        "from carla import RecourseMethod\n",
        "from carla.data.api import data, Data\n",
        "from carla.models.api import MLModel\n",
        "from cote.vae import VariationalAutoencoder\n",
        "from carla.recourse_methods.processing import merge_default_parameters\n",
        "from cote.TreeLeaf import TreeLeafs\n",
        "# For Descision Tree implementation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import numpy as np\n",
        "from carla import Benchmark\n",
        "from carla.recourse_methods import Dice, Face\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import deepcopy\n",
        "from carla import MLModelCatalog\n",
        "from carla.data.catalog import OnlineCatalog\n",
        "from carla.recourse_methods import GrowingSpheres\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "tqdm.pandas()\n",
        "\n",
        "class TreeBasedContrastiveExplanation(RecourseMethod):\n",
        "    '''\n",
        "    Decision Tree Based contrastive explanations\n",
        "    '''\n",
        "    _DEFAULT_HYPERPARAMS = {\n",
        "      \"data_name\": None,\n",
        "      \"n_search_samples\": 300,\n",
        "      \"p_norm\": 1,\n",
        "      \"step\": 0.1,\n",
        "      \"max_iter\": 1000,\n",
        "      \"clamp\": True,\n",
        "      \"target_class\": [0, 1],\n",
        "      \"binary_cat_features\": True,\n",
        "      \"myvae_params\": {\n",
        "          'input_dim': 784,\n",
        "          'kld_weight': 0.0025,\n",
        "          'layers': [512, 128],\n",
        "          'latent_dim': 32,\n",
        "          'hidden_activation': 'relu',\n",
        "          'dropout': 0.2,\n",
        "          'batch_norm': True,\n",
        "          'batch_size': 64,\n",
        "          'epochs': 20,\n",
        "          'learning_rate': 0.001,\n",
        "          'weight_decay': 0.0,\n",
        "          'cuda': False,\n",
        "          'verbose': True,\n",
        "          'train': True,\n",
        "          'save_dir': './vae_model/',\n",
        "      },\n",
        "      \"tree_params\": {\n",
        "          \"min_entries_per_label\": 1000,\n",
        "          \"grid_search_jobs\": -1,\n",
        "          \"min_weight_gini\": 100, # set to 0.5 since here both class have same prob\n",
        "          \"max_search\": 500,\n",
        "          \"grid_search\": {\n",
        "                \"splitter\": [\"best\"],\n",
        "                \"criterion\": [\"gini\"],\n",
        "                \"max_depth\": [6],\n",
        "                \"min_samples_split\": [2],\n",
        "                \"min_samples_leaf\": [1],\n",
        "                \"max_features\": [None] #Note changing this will result in removing features that we might want to keep\n",
        "          }\n",
        "      }\n",
        "\n",
        "    }\n",
        "\n",
        "    def __init__(self, dataset:Data, mlmodel: MLModel, hyperparams: Dict, data_catalog: Dict, distance_metric ='euclidean'):\n",
        "        super().__init__(mlmodel)\n",
        "        self.distance_metric = distance_metric\n",
        "        # Construct catalog\n",
        "        self.data_catalog = data_catalog\n",
        "        # Construct mlmodel\n",
        "        self.mlmodel = mlmodel\n",
        "        # Construct the hyperparameters\n",
        "        self.hyperparams = merge_default_parameters(hyperparams, self._DEFAULT_HYPERPARAMS)\n",
        "        # Construct the VAE\n",
        "        self.vae = TEMP_VAE\n",
        "        # self.vae = self.load_vae(dataset, self.hyperparams[\"myvae_params\"], mlmodel, mlmodel.data.name)\n",
        "        # Define feature_input\n",
        "        self.feature_input_order = []\n",
        "        for fin in self.mlmodel.feature_input_order:\n",
        "            if fin in dataset.immutables:\n",
        "                continue\n",
        "            else:\n",
        "                self.feature_input_order.append(fin)\n",
        "        # Construct the dataframe with encodings\n",
        "        self.dataset = dataset.df\n",
        "        self.dataset['VAE_ENCODED'] = self.get_encodeings(self.dataset.copy())\n",
        "        ## These are added to optimize neighbor sampling for DT which used to take ~0.4 seconds and now will be \n",
        "        # NNDescent\n",
        "        self.data_indexes_m = self.dataset.index\n",
        "        self.set_distance_metric_initialize_nn(self.distance_metric)\n",
        "        # Load Grid Parameters\n",
        "        self.hyperparams[\"tree_params\"][\"grid_search\"] = self.optimize_grid(self.hyperparams[\"tree_params\"][\"grid_search\"], self.dataset)\n",
        "        self.tree_scores = {'Train':[], 'Test':[]}\n",
        "\n",
        "    def set_distance_metric_initialize_nn(self, distance_metric):\n",
        "        # TODO : Need to make NNDescent per target class\n",
        "        self.distance_metric = distance_metric\n",
        "        self.nnd = NNDescent(np.array(self.dataset[\"VAE_ENCODED\"].values.tolist()), metric=self.distance_metric,random_state=42)\n",
        "        self.nnd.prepare()\n",
        "        self.nnd_positive = NNDescent(np.array(self.dataset[self.dataset[self._mlmodel.data.target]==1][\"VAE_ENCODED\"].values.tolist()), metric=self.distance_metric,random_state=42)\n",
        "        self.nnd_positive.prepare()\n",
        "        self.nnd_negative = NNDescent(np.array(self.dataset[self.dataset[self._mlmodel.data.target]==0][\"VAE_ENCODED\"].values.tolist()), metric=self.distance_metric,random_state=42)\n",
        "        self.nnd_negative.prepare()\n",
        "\n",
        "    def set_model(self,mlmodel):\n",
        "        self._mlmodel = mlmodel\n",
        "        self.mlmodel = mlmodel\n",
        "    def optimize_grid(self, grid_search, df):\n",
        "        \"\"\"\n",
        "        Optimize the grid search parameters\n",
        "        #@TODO: make it on chunkc of the dataframe and return the top\n",
        "        #@TODO: the chunkcs in order of encodings\n",
        "        \"\"\"\n",
        "        copy_data = df.copy()\n",
        "        print(\"DT Warming Up...\")\n",
        "        # create a frequency count to count how many times a parameter was selected as best_params\n",
        "        best_params_list = []\n",
        "        for i in range(1):\n",
        "            index_factual = df.sample(1).index[0]\n",
        "            factual = df.loc[index_factual]\n",
        "            #index_neighbors_0 = self.nnd.query(np.array([factual[\"VAE_ENCODED\"].tolist()]), k=self.hyperparams[\"tree_params\"][\"min_entries_per_label\"]*2.5)[0][0].tolist()\n",
        "            #datata_index_0 = self.data_indexes_m[index_neighbors_0].tolist()\n",
        "            index_neighbors_0 = self.nnd_negative.query(np.array([factual[\"VAE_ENCODED\"].tolist()]), k=self.hyperparams[\"tree_params\"][\"min_entries_per_label\"])[0][0].tolist()\n",
        "            datata_index_0 = self.data_indexes_m[index_neighbors_0].tolist()\n",
        "            index_neighbors_1 = self.nnd_positive.query(np.array([factual[\"VAE_ENCODED\"].tolist()]), k=self.hyperparams[\"tree_params\"][\"min_entries_per_label\"])[0][0].tolist()\n",
        "            datata_index_1 = self.data_indexes_m[index_neighbors_1].tolist()\n",
        "            datata_index_0.extend(datata_index_1)\n",
        "            nearest_neighbors = copy_data.loc[datata_index_0]\n",
        "            # Define Decision Tree Classifier\n",
        "            dec_tree = DecisionTreeClassifier(random_state=0)\n",
        "            # Define Grid Search\n",
        "            grid_tree = GridSearchCV(dec_tree, grid_search, cv=2, n_jobs=self.hyperparams[\"tree_params\"][\"grid_search_jobs\"])\n",
        "            target_values = nearest_neighbors[self._mlmodel.data.target]\n",
        "            train_features = nearest_neighbors[self.feature_input_order]\n",
        "            # Fit the Grid Search\n",
        "            grid_tree.fit(train_features, target_values)\n",
        "            best_params_list.append(grid_tree.best_params_)\n",
        "        # For each key check the most common value and return that or just return random value\n",
        "        best_params = {}\n",
        "        best_params_listt = pd.DataFrame(best_params_list)\n",
        "        for key in grid_tree.best_params_:\n",
        "            best_params[key] = best_params_listt[key].value_counts().index[0]\n",
        "        # Return the best parameters\n",
        "        print(best_params)\n",
        "        return best_params\n",
        "\n",
        "    def load_vae(\n",
        "        self, data: pd.DataFrame, vae_params: Dict, mlmodel: MLModel, data_name: str\n",
        "    ) -> VariationalAutoencoder:\n",
        "        '''\n",
        "        Load and train the VAE if needed\n",
        "        '''\n",
        "        mutable_list = [True] * len(self.mlmodel.feature_input_order) \n",
        "        # Change all False to True in mutable_list\n",
        "        mutable_list = np.array([True for x in mutable_list])\n",
        "        generative_model = VariationalAutoencoder(\n",
        "            data_name, vae_params[\"layers\"], mutable_list, self.hyperparams['myvae_params']\n",
        "        )\n",
        "        if vae_params[\"train\"]:\n",
        "            generative_model.fit(\n",
        "                xtrain=data.df[mlmodel.feature_input_order]\n",
        "            )\n",
        "        else:\n",
        "            try:\n",
        "                generative_model.load(vae_params[\"layers\"][0])\n",
        "            except FileNotFoundError as exc:\n",
        "                raise FileNotFoundError(\n",
        "                    \"Loading of Autoencoder failed. {}\".format(str(exc))\n",
        "                )\n",
        "\n",
        "        return generative_model\n",
        "\n",
        "    def get_counterfactuals(self, factuals: pd.DataFrame):\n",
        "        '''\n",
        "        this property is responsible to generate and output\n",
        "        encoded and scaled counterfactual examples\n",
        "        as pandas DataFrames\n",
        "        '''\n",
        "        # Get the encoded features of factuals\n",
        "        factuals[\"VAE_ENCODED\"] = self.get_encodeings(factuals)\n",
        "        # Get the counterfactuals\n",
        "        # find counterfactuals\n",
        "        self.tree_scores = {'Train':[], 'Test':[]}\n",
        "        counter_factuals = factuals.apply(\n",
        "            lambda x: self.tree_based_search(x), axis=1, raw=False\n",
        "        )\n",
        "        # counter_factuals = [self.tree_based_search(row) for __,row in factuals.iterrows()]\n",
        "        # Concatenate the counterfactuals to a single dataframe\n",
        "        # counter_factuals is a list of rows\n",
        "        self.counter_factuals = counter_factuals\n",
        "        #counter_factuals = check_counterfactuals(self._mlmodel, counter_factuals)\n",
        "        # Return the counterfactuals\n",
        "        return counter_factuals[self._mlmodel.feature_input_order]\n",
        "\n",
        "    def get_encodeings(self, data: pd.DataFrame):\n",
        "        '''\n",
        "        This method is responsible to append the encoded features\n",
        "        to the dataframe\n",
        "        '''\n",
        "        # Fix DataFrame to be able to feed to the VAE\n",
        "        input_data = data.copy()[self._mlmodel.feature_input_order]\n",
        "        input_data = torch.FloatTensor(input_data.values)\n",
        "        # Get the encoded features\n",
        "        encoded_values = self.vae.encode(input_data)[0].detach().numpy()\n",
        "        encoded_values = [i for i in encoded_values]\n",
        "        return encoded_values\n",
        "\n",
        "    def distance_get(self, x,factuals):\n",
        "        return np.square((x - factuals)).sum()\n",
        "\n",
        "    def get_nearest_neighbors_thershold(self, copy_data, label_threshold):\n",
        "        '''\n",
        "        This method is responsible to get the nearest neighbors of a given threshold\n",
        "        using the VAE and minimum threshold per label\n",
        "        '''\n",
        "        # Find the index of the 100th instance of each class\n",
        "        id_100th_class_0 = copy_data[copy_data[self._mlmodel.data.target] == 0].index[label_threshold-1]\n",
        "        id_100th_class_1 = copy_data[copy_data[self._mlmodel.data.target] == 1].index[label_threshold-1]\n",
        "        # Get the maximum id\n",
        "        max_id = max(id_100th_class_0, id_100th_class_1)\n",
        "        # Return the nearest neighbors of the 100th instance of each class\n",
        "        return copy_data.head(max_id)\n",
        "    \n",
        "    def decision_tree(self, nearest_neighbors):\n",
        "        '''\n",
        "        This method is responsible to create a decision tree\n",
        "        using the nearest neighbors of the 100th instance of each class\n",
        "        '''\n",
        "        target_values = nearest_neighbors[self._mlmodel.data.target]\n",
        "        training_features = nearest_neighbors[self.feature_input_order]\n",
        "        # Split the data into train and test\n",
        "        train_features, test_features, target_values_train, target_values_test = train_test_split(training_features, target_values, \n",
        "                                                                                                test_size=0.1, random_state=42)\n",
        "        # Create the decision tree\n",
        "        clf = DecisionTreeClassifier(random_state=0 , max_depth=self.hyperparams[\"tree_params\"]['grid_search'][\"max_depth\"], \n",
        "                                    min_samples_split=self.hyperparams[\"tree_params\"]['grid_search'][\"min_samples_split\"], \n",
        "                                    min_samples_leaf=self.hyperparams[\"tree_params\"]['grid_search'][\"min_samples_leaf\"], \n",
        "                                    max_features=self.hyperparams[\"tree_params\"]['grid_search'][\"max_features\"])\n",
        "        clf.fit(train_features, target_values_train)\n",
        "        # Predict the test data\n",
        "        predicted__test_values = clf.predict(test_features)\n",
        "        predicted__train_values = clf.predict(train_features)\n",
        "        # Calculate the accuracy\n",
        "        self.tree_scores['Train'].append(accuracy_score(target_values_train, predicted__train_values))\n",
        "        self.tree_scores['Test'].append(accuracy_score(target_values_test, predicted__test_values))\n",
        "        return clf\n",
        "\n",
        "    def tree_based_search(self, factual):\n",
        "        '''\n",
        "        This method is responsible to get the counterfactual of a given targeted_encoding\n",
        "        '''\n",
        "        copy_data = self.dataset.copy()\n",
        "        #index_neighbors_0 = self.nnd.query(np.array([factual[\"VAE_ENCODED\"].tolist()]), k=self.hyperparams[\"tree_params\"][\"min_entries_per_label\"]*2.5)[0][0].tolist()\n",
        "        #datata_index_0 = self.data_indexes_m[index_neighbors_0].tolist()\n",
        "        index_neighbors_0 = self.nnd_negative.query(np.array([factual[\"VAE_ENCODED\"].tolist()]), k=self.hyperparams[\"tree_params\"][\"min_entries_per_label\"])[0][0].tolist()\n",
        "        datata_index_0 = self.data_indexes_m[index_neighbors_0].tolist()\n",
        "        index_neighbors_1 = self.nnd_positive.query(np.array([factual[\"VAE_ENCODED\"].tolist()]), k=self.hyperparams[\"tree_params\"][\"min_entries_per_label\"])[0][0].tolist()\n",
        "        datata_index_1 = self.data_indexes_m[index_neighbors_1].tolist()\n",
        "        datata_index_0.extend(datata_index_1)\n",
        "        nearest_neighbors = copy_data.loc[datata_index_0]\n",
        "        # Get the tree\n",
        "        tree = self.decision_tree(nearest_neighbors)\n",
        "        self.mtree = tree\n",
        "        # Get the leaf nodes\n",
        "        leaf_nodes = TreeLeafs(tree.tree_, self.feature_input_order).leafs_nodes.copy()\n",
        "        # leaf_nodes is list of classes LeafNode\n",
        "        # Get the leaf node where the targeted encoding is located\n",
        "        leaf_node_n_i = -1\n",
        "        for leaf_i in range(len(leaf_nodes)):\n",
        "            if leaf_nodes[leaf_i].check_point(factual):\n",
        "                leaf_node_n_i = leaf_i\n",
        "                break\n",
        "        self.mleaf_node_n_i = leaf_node_n_i\n",
        "        self.mfactual = factual\n",
        "        # assert if the leaf node is not found\n",
        "        assert leaf_node_n_i != -1, \"Leaf node not found\"\n",
        "        # For now change leafnode label to the item label\n",
        "        # #assert if leaf_node_n.label is not the same as the factual label\n",
        "        # assert leaf_node_n.label == factual[self._mlmodel.data.target], \"Leaf node label {} is not the same as the factual label {}\".format(leaf_node_n.label, factual[self._mlmodel.data.target])\n",
        "        if leaf_nodes[leaf_node_n_i].label != factual[self._mlmodel.data.target]:\n",
        "          #print(\"Leaf Node {} flipped node label {} to match the factual entry {}\".format(leaf_node_n_i,\n",
        "          #                                                                          leaf_nodes[leaf_node_n_i].label,\n",
        "          #                                                                          factual[self._mlmodel.data.target]))\n",
        "          leaf_nodes[leaf_node_n_i].label = factual[self._mlmodel.data.target]\n",
        "        leaf_node_n = leaf_nodes[leaf_node_n_i]\n",
        "        # Get all leafnodes with label!= leaf_node_n.label and Sort leaf nodes by distance\n",
        "        leaf_nodes_with_label = [leaf_n for leaf_n in leaf_nodes if leaf_n.label != leaf_node_n.label]\n",
        "        # Check if leaf_nodes_with_label is empty\n",
        "        if len(leaf_nodes_with_label) == 0:\n",
        "            print(\"No leaf node with label {}\".format(leaf_node_n.label))\n",
        "            factual_ret = factual\n",
        "            factual_ret[self._mlmodel.feature_input_order] = np.nan\n",
        "            #print(\"returned\")\n",
        "            return factual_ret[self._mlmodel.feature_input_order]\n",
        "        # Sort leaf nodes by distance\n",
        "        leaf_nodes_with_label = sorted(leaf_nodes_with_label, key=lambda x: len(leaf_node_n.compare_node(x)))\n",
        "        # Get the counterfactual\n",
        "        returned_neighbor = -1\n",
        "        counter_taregt = factual[self._mlmodel.data.target]*-1 +1\n",
        "        #print(\"Searching for Neighbor....\")\n",
        "        # print(\"Start with option A: {}\".format(nearest_leaf_node))\n",
        "        #print(second_nearest_node)\n",
        "        # If len of leaf_nodes_with_label is 1, the all the max_search on the nearest_leaf_node\n",
        "        # If len of leaf_nodes_with_label is 2, the max_search/7 on the nearest_leaf_node and max_search/3 on the second_nearest_node\n",
        "        # If len of leaf_nodes_with_label is 3, the max_search/5 on the nearest_leaf_node and max_search/3 on the second_nearest_node and max_search/2 on the third_nearest_node\n",
        "        print('len(leaf_nodes_with_label):   ', len(leaf_nodes_with_label))\n",
        "        if len(leaf_nodes_with_label) >60:\n",
        "            max_searchs = [self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2]\n",
        "        elif len(leaf_nodes_with_label) >30:\n",
        "            max_searchs = [self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2,\n",
        "                           self.hyperparams[\"tree_params\"][\"max_search\"]*0.2, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2]\n",
        "        elif len(leaf_nodes_with_label) == 1:\n",
        "            max_searchs = [self.hyperparams[\"tree_params\"][\"max_search\"]]\n",
        "        elif len(leaf_nodes_with_label) == 2:\n",
        "            max_searchs = [self.hyperparams[\"tree_params\"][\"max_search\"]*0.8, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2]\n",
        "        else:\n",
        "            max_searchs = [self.hyperparams[\"tree_params\"][\"max_search\"]*0.5, self.hyperparams[\"tree_params\"][\"max_search\"]*0.5]\n",
        "        # map max_search to int values while rounding up to the nearest int\n",
        "        max_searchs = [int(round(x)) for x in max_searchs]\n",
        "        # Loop over max_search\n",
        "        for rank_node, max_search_i in enumerate(max_searchs):\n",
        "            number_searchs = 0\n",
        "            nearest_leaf_node = leaf_nodes_with_label[rank_node]\n",
        "            #print(\"Searching for Neighbor.... {}, {}\".format(rank_node, max_search_i))\n",
        "            while number_searchs < max_search_i and returned_neighbor is -1:\n",
        "                # if number_searchs is 30% of max_search\n",
        "                if number_searchs < max_search_i*0.3:\n",
        "                    sigma = 10\n",
        "                    gamma = 0\n",
        "                # if number_searchs is 80% of max_search\n",
        "                elif number_searchs < max_search_i*0.6:\n",
        "                    sigma = 1\n",
        "                    gamma = 0\n",
        "                # if number_searchs is 80% of max_search\n",
        "                elif number_searchs < max_search_i*0.9:\n",
        "                    sigma = 0.25\n",
        "                    gamma = 0\n",
        "                # if number_searchs is 90% of max_search\n",
        "                else:\n",
        "                    sigma = 0.15\n",
        "                    gamma = 1\n",
        "                neighbor = nearest_leaf_node.generate_point(factual.copy(), data_catalog = self.data_catalog, sigma = sigma, gamma = gamma)\n",
        "                neighb_df = pd.DataFrame([neighbor[self.mlmodel.feature_input_order]])\n",
        "                self.neighb_df = neighb_df\n",
        "                probs_p = self.mlmodel.predict_proba(neighb_df)\n",
        "                if counter_taregt == np.argmax(probs_p):\n",
        "                    returned_neighbor = neighbor\n",
        "                    break\n",
        "                number_searchs += 1\n",
        "            if returned_neighbor is not -1:\n",
        "                break\n",
        "        # If no neighbor is found, return the factual\n",
        "        if returned_neighbor is -1:\n",
        "            #print(\"No neighbor was found\")\n",
        "            factual_ret = factual\n",
        "            factual_ret[self._mlmodel.feature_input_order] = np.nan\n",
        "            #print(\"returned\")\n",
        "            return factual_ret[self._mlmodel.feature_input_order]\n",
        "        return returned_neighbor[self._mlmodel.feature_input_order]\n"
      ],
      "metadata": {
        "id": "xaPqSTC2D61t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Tree Leaf utils\n",
        "\"\"\"\n",
        "\n",
        "# !git clone https://github.com/carla-recourse/CARLA.git\n",
        "\n",
        "\n",
        "import enum\n",
        "from typing import Dict, List, Tuple, Union\n",
        "import pandas as pd\n",
        "from carla import RecourseMethod\n",
        "from carla.data.api import data, Data\n",
        "from carla.models.api import MLModel\n",
        "from carla.recourse_methods.autoencoder import (\n",
        "    VariationalAutoencoder,\n",
        "    train_autoencoder,\n",
        ")\n",
        "from carla.recourse_methods.processing import (\n",
        "    check_counterfactuals,\n",
        "    merge_default_parameters,\n",
        "    reconstruct_encoding_constraints,\n",
        ")\n",
        "# For Descision Tree implementation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import numpy as np\n",
        "from carla import Benchmark\n",
        "from carla.recourse_methods import Dice, Face\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import deepcopy\n",
        "class LeafNode:\n",
        "    def __init__(self, conditions, label, weight):\n",
        "        # Conditions is a list of tuples from the root node to the leaf node\n",
        "        self.conditions = deepcopy(conditions)\n",
        "        # Label is the label of the leaf node\n",
        "        self.label = label\n",
        "        # Wieght Either entropy or gini\n",
        "        self.weight = weight\n",
        "        # Duplicate conditions\n",
        "        self.duplicate_conditions = []\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"\n",
        "        Print the leaf node with conditions and label\n",
        "        \"\"\"\n",
        "        return \"LeafNode(label={}, weight={}, conditions={})\".format(self.label, self.weight, self.conditions)\n",
        "\n",
        "    def compare_node(self, other): #TODO misleading name\n",
        "        \"\"\"\n",
        "        Get the distance between two leaf nodes by returning a set of conditions as follows:\n",
        "        1. Initialize conditions as other conditions\n",
        "        2. Remove conditions that are exactly the same with self\n",
        "        3. Return the remaining conditions\n",
        "\n",
        "        # TODO common feature\n",
        "        \"\"\"\n",
        "        # Initialize conditions as other conditions\n",
        "        conditions = other.conditions\n",
        "        # Remove conditions that are common with self\n",
        "        for condition in self.conditions:\n",
        "            conditions = [c for c in conditions if c != condition]\n",
        "        # Return the remaining conditions\n",
        "        return conditions\n",
        "\n",
        "    def merge_conditions(self):\n",
        "        \"\"\"\n",
        "        If there are two conditions with the same feature and threshold_sign, merge them into one condition\n",
        "        \"\"\"\n",
        "        # Initialize conditions as other conditions\n",
        "        # \n",
        "        conditions = self.conditions\n",
        "        # indexes to be dropped\n",
        "        indexes = []\n",
        "        # Search for conditions with the same feature and threshold_sign\n",
        "        for i in range(len(conditions)):\n",
        "            # if i in the indexes to be dropped, skip\n",
        "            if i in indexes:\n",
        "                continue\n",
        "            for j in range(i + 1, len(conditions)):\n",
        "                # if j in the indexes to be dropped, skip\n",
        "                if j in indexes:\n",
        "                    continue\n",
        "                if conditions[i].feature == conditions[j].feature:\n",
        "                    if conditions[i].threshold_sign == conditions[j].threshold_sign:\n",
        "                        # Merge the two conditions\n",
        "                        if conditions[i].threshold_sign == '<=':\n",
        "                            conditions[i].threshold = min(conditions[i].threshold, conditions[j].threshold)\n",
        "                        else:\n",
        "                            conditions[i].threshold = max(conditions[i].threshold, conditions[j].threshold)\n",
        "                        # Add index to drop\n",
        "                        indexes.append(j)\n",
        "                    else:\n",
        "                        # Add it to duplicate conditions\n",
        "                        if conditions[j].feature not in self.duplicate_conditions:\n",
        "                            self.duplicate_conditions.append(conditions[j].feature)\n",
        "        # Drop indexes from conditions\n",
        "        conditions = [c for i, c in enumerate(conditions) if i not in indexes]\n",
        "        self.conditions = conditions\n",
        "        self.duplicate_conditions = list(set(self.duplicate_conditions))\n",
        "\n",
        "    def check_point(self, point):\n",
        "        \"\"\"\n",
        "        Check if the point satisfies the conditions of the leaf node\n",
        "        \"\"\"\n",
        "        # Check if the point satisfies the conditions of the leaf node\n",
        "        for condition in self.conditions:\n",
        "            if not condition.check_point(point):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def generate_point(self, point, data_catalog = None, sigma =0.5, gamma = 0):\n",
        "        \"\"\"\n",
        "        Generate a point from a point\n",
        "        \"\"\"\n",
        "        # loop through the duplicate conditions\n",
        "        for feature in self.duplicate_conditions:\n",
        "            # get the two conditions with that feature\n",
        "            conditions = [c for c in self.conditions if c.feature == feature]\n",
        "            # data_catalog contains {'categorical':[],'continuous':[],'imutable':[], 'continuous_stats':[]}\n",
        "            if feature in data_catalog['categorical']:\n",
        "                # Assert that there shouldn't be duplicate conditions for a binary feature (categorical here are binaries)\n",
        "                print(\"Skipping Duplicate condition: There shouldn't be duplicate conditions for a binary feature\")\n",
        "                #TODO (general user he can't solve it)\n",
        "                # Thrsh can be continous, then generate a random point between threshold and round the result\n",
        "            elif feature in data_catalog['continuous']:\n",
        "                # using the continuous_stats get the std and mean\n",
        "                std = data_catalog['continuous_stats'][feature]['std']\n",
        "                mean = data_catalog['continuous_stats'][feature]['mean']\n",
        "                minn = data_catalog['continuous_stats'][feature]['min']\n",
        "                maxx = data_catalog['continuous_stats'][feature]['max']\n",
        "                # Using the mean, std, min and max create a bias value\n",
        "                # bias values is std/10 * (max - min)\n",
        "                bias = std / sigma # TOCHECK LATER\n",
        "                bias = min(bias, abs(conditions[0].threshold - conditions[1].threshold))\n",
        "                # Min\n",
        "                if gamma == 0:\n",
        "                    min_bias = 0\n",
        "                else:\n",
        "                    min_bias = std / gamma\n",
        "                # Generate a random value between the two thresholds\n",
        "                bias = random.uniform(min_bias, bias)\n",
        "                # Add the bias to the threshold\n",
        "                if conditions[0].threshold_sign == '<=':\n",
        "                    point[feature] = conditions[0].threshold + bias\n",
        "                else:\n",
        "                    point[feature] = conditions[1].threshold + bias\n",
        "        for condition in self.conditions:\n",
        "            if condition.feature not in self.duplicate_conditions:\n",
        "                if condition.feature in data_catalog['categorical']:\n",
        "                    # Simply flip the value\n",
        "                    # Round the threshold\n",
        "                    point[condition.feature] = not point[condition.feature]\n",
        "                else: # condition.feature in data_catalog['continuous']:\n",
        "                    std = data_catalog['continuous_stats'][condition.feature]['std']\n",
        "                    mean = data_catalog['continuous_stats'][condition.feature]['mean']\n",
        "                    minn = data_catalog['continuous_stats'][condition.feature]['min']\n",
        "                    maxx = data_catalog['continuous_stats'][condition.feature]['max']\n",
        "                    bias = std / sigma\n",
        "                    # Min\n",
        "                    if gamma == 0:\n",
        "                        min_bias = 0\n",
        "                    else:\n",
        "                        min_bias = std / gamma\n",
        "                    # Generate a random value between the two thresholds\n",
        "                    bias = random.uniform(min_bias, bias)\n",
        "                    if condition.threshold_sign == '<=':\n",
        "                        point[condition.feature] = condition.threshold + bias\n",
        "                    else:\n",
        "                        point[condition.feature] = condition.threshold - bias\n",
        "        return point\n",
        "\n",
        "\n",
        "class Condition:\n",
        "    def __init__(self, feature, threshold, threshold_sign):\n",
        "        # Feature is the feature name\n",
        "        self.feature = feature\n",
        "        # Value is the value of the feature\n",
        "        self.threshold = threshold\n",
        "        # <= or > since they are the only two threshold_sign in Decision Tree\n",
        "        self.threshold_sign = threshold_sign\n",
        "    def __repr__(self):\n",
        "        return f'{self.feature} {self.threshold_sign} {self.threshold}'\n",
        "    def check_point(self, point):\n",
        "        \"\"\"\n",
        "        Check if the point satisfies the condition\n",
        "        \"\"\"\n",
        "        # Check if the point satisfies the condition\n",
        "        if self.threshold_sign == '<=':\n",
        "            return point[self.feature] <= self.threshold\n",
        "        else:\n",
        "            return point[self.feature] > self.threshold\n",
        "\n",
        "\n",
        "class TreeLeafs:\n",
        "    def __init__(self, tree, feature_input_order):\n",
        "        self.tree = tree\n",
        "        self.feature_input_order = feature_input_order\n",
        "        self.leafs_nodes = []\n",
        "        self.get_leaf_nodes(tree)\n",
        "        for leaf in self.leafs_nodes:\n",
        "            leaf.merge_conditions()\n",
        "\n",
        "    def get_leaf_nodes(self, tree, node_id=0, conditions=[]):\n",
        "        \"\"\"\n",
        "        This will be a recursion function that will append to leaf_nodes list, their labels and set of conditions\n",
        "        If the node is a leaf node, then it will append a LeafNode object to leaf_nodes\n",
        "        If the node is not a leaf node, then it will return while adding the conditions of the left and right child to the list\n",
        "        \"\"\"\n",
        "        # If the node is a leaf node\n",
        "        if tree.children_left[node_id] == -1 and tree.children_right[node_id] == -1:\n",
        "            # Append the leaf node to the list\n",
        "            self.leafs_nodes.append(LeafNode(conditions, np.argmax(tree.value[node_id]), tree.impurity[node_id]))\n",
        "        # If the node is not a leaf node\n",
        "        else:\n",
        "            # Need to get the feature of the node\n",
        "            feature = self.feature_input_order[tree.feature[node_id]]\n",
        "            # Need to get the threshold of the node\n",
        "            threshold = tree.threshold[node_id]\n",
        "            # For right child if exists, threshold_sign is >\n",
        "            if tree.children_right[node_id] != -1:\n",
        "                conditions_right = conditions.copy()\n",
        "                # Append the condition to the list\n",
        "                conditions_right.append(Condition(feature, threshold, '>'))\n",
        "                # Get the right child\n",
        "                self.get_leaf_nodes(tree, tree.children_right[node_id], conditions_right)\n",
        "            # For left child if exists, threshold_sign is <=\n",
        "            if tree.children_left[node_id] != -1:\n",
        "                conditions_left = conditions.copy()\n",
        "                # Append the condition to the list\n",
        "                conditions_left.append(Condition(feature, threshold, '<='))\n",
        "                # Get the left child\n",
        "                self.get_leaf_nodes(tree, tree.children_left[node_id], conditions_left)\n"
      ],
      "metadata": {
        "id": "So6Ch8KKek23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae_bench = VAEBenchmark(temp_model, vae_parms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1BiUT2Ajtu9",
        "outputId": "c6c5de7e-0b0e-4d8d-b9fa-9858494146ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_dim': 784, 'kld_weight': 0.00025, 'layers': [500, 250], 'latent_dim': 32, 'hidden_activation': 'relu', 'dropout': 0.2, 'batch_norm': True, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001, 'weight_decay': 0.0, 'cuda': False, 'verbose': True, 'train': True, 'save_dir': './vae_model/'}\n",
            "./vae_model/mnist\n",
            "Epoch: 0, ELBO Loss: 1465.2396240234375, Test MSELoss: 840.0263061523438\n",
            "Epoch: 0, Best ELBO Loss: 1465.2396240234375\n",
            "Epoch: 1, ELBO Loss: 749.746826171875, Test MSELoss: 691.7169189453125\n",
            "BEST Epoch: 1, Best ELBO Loss: 749.746826171875\n",
            "Epoch: 2, ELBO Loss: 640.450439453125, Test MSELoss: 606.8975219726562\n",
            "BEST Epoch: 2, Best ELBO Loss: 640.450439453125\n",
            "Epoch: 3, ELBO Loss: 591.3597412109375, Test MSELoss: 574.2608642578125\n",
            "BEST Epoch: 3, Best ELBO Loss: 591.3597412109375\n",
            "Epoch: 4, ELBO Loss: 562.6655883789062, Test MSELoss: 550.5001831054688\n",
            "BEST Epoch: 4, Best ELBO Loss: 562.6655883789062\n",
            "Epoch: 5, ELBO Loss: 541.31591796875, Test MSELoss: 539.8184204101562\n",
            "BEST Epoch: 5, Best ELBO Loss: 541.31591796875\n",
            "Epoch: 6, ELBO Loss: 524.4340209960938, Test MSELoss: 526.288330078125\n",
            "BEST Epoch: 6, Best ELBO Loss: 524.4340209960938\n",
            "Epoch: 7, ELBO Loss: 511.6495666503906, Test MSELoss: 521.9481201171875\n",
            "BEST Epoch: 7, Best ELBO Loss: 511.6495666503906\n",
            "Epoch: 8, ELBO Loss: 503.7828369140625, Test MSELoss: 505.7518005371094\n",
            "BEST Epoch: 8, Best ELBO Loss: 503.7828369140625\n",
            "Epoch: 9, ELBO Loss: 492.8047790527344, Test MSELoss: 502.7868957519531\n",
            "BEST Epoch: 9, Best ELBO Loss: 492.8047790527344\n",
            "Epoch: 10, ELBO Loss: 485.73529052734375, Test MSELoss: 491.68682861328125\n",
            "BEST Epoch: 10, Best ELBO Loss: 485.73529052734375\n",
            "Epoch: 11, ELBO Loss: 477.25970458984375, Test MSELoss: 490.0478210449219\n",
            "BEST Epoch: 11, Best ELBO Loss: 477.25970458984375\n",
            "Epoch: 12, ELBO Loss: 471.6067810058594, Test MSELoss: 471.6278381347656\n",
            "BEST Epoch: 12, Best ELBO Loss: 471.6067810058594\n",
            "Epoch: 13, ELBO Loss: 460.8302001953125, Test MSELoss: 472.1405334472656\n",
            "BEST Epoch: 13, Best ELBO Loss: 460.8302001953125\n",
            "Epoch: 14, ELBO Loss: 457.4516296386719, Test MSELoss: 462.26629638671875\n",
            "BEST Epoch: 14, Best ELBO Loss: 457.4516296386719\n",
            "Epoch: 15, ELBO Loss: 453.5736083984375, Test MSELoss: 457.5675048828125\n",
            "BEST Epoch: 15, Best ELBO Loss: 453.5736083984375\n",
            "Epoch: 16, ELBO Loss: 450.230712890625, Test MSELoss: 454.1837463378906\n",
            "BEST Epoch: 16, Best ELBO Loss: 450.230712890625\n",
            "Epoch: 17, ELBO Loss: 445.6701354980469, Test MSELoss: 449.3349304199219\n",
            "BEST Epoch: 17, Best ELBO Loss: 445.6701354980469\n",
            "Epoch: 18, ELBO Loss: 441.0632019042969, Test MSELoss: 450.5881652832031\n",
            "BEST Epoch: 18, Best ELBO Loss: 441.0632019042969\n",
            "Epoch: 19, ELBO Loss: 440.1619873046875, Test MSELoss: 447.8774719238281\n",
            "BEST Epoch: 19, Best ELBO Loss: 440.1619873046875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vae_bench.vae.plot_loss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "6kxlNArdwvfm",
        "outputId": "b64eb806-ddd0-478d-cee2-c3ec312aea32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAFNCAYAAACwk0NsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgU1d33//dXVuPCOiEIJmAkemNUNKNiMHFBEaMRYqLRmMhjfIImeBtjnl/EaIJr7miiJsa4oKhg4hYTFXe5cTeCgiKCGyOCDCoMO4hsM9/fH+d0umdlprtruqf5vK6rrqo6tZ0uZprPnKpTZe6OiIiIiBSf7QpdARERERFpmIKaiIiISJFSUBMREREpUgpqIiIiIkVKQU1ERESkSCmoiYiIiBQpBTURERGRIqWgJiJFw8wWmNmRrXzMsWb2fAPlPc1sk5l9tYX7O8PM3jGztWa2xMweM7Od4rI7zOzyfNVdREqfgpqIbOv+BnzdzPrXKT8ZeNPd5zR3R2Z2KPA74BR33wn4L+DevNVURLY5CmoiUvTMrJOZ/cnMPorDn8ysU1zW08weMbNVZrbCzF4ws+3isvPNbHFs3XrXzIbW3be7VwJPAz+qs+g0YFLcz+5m9pyZrTazZWbWWPg6AHjZ3V+P+17h7hPdfa2ZjQZOBX5lZuvM7OG4713M7J9mVmVmH5jZORmf+2Izu9/M7o2f4TUz2zdj+VY/n4i0bQpqItIWXAgMBgYB+wIHAhfFZb8EKoEyoBfwa8DNbA/gbOCA2Lp1NLCgkf1PJCOoxW0HAXfFosuAp4BuQF/gL43sZzpwtJldYmZDUmESwN3HA38HrnL3Hd392zFQPgy8AfQBhgLnmtnRGfscAfwD6B7r86CZdWjh5xORNkpBTUTaglOBS919qbtXAZeQDlabgd7Al9x9s7u/4OElxtVAJ2CgmXVw9wXu/n4j+38A6GVmX4/zpwGPx2OljvElYBd33+DuLza0E3d/ATgB2B94FFhuZteYWbtGjnsAUObul7r7JnefD9xCuOyaMtPd73f3zcA1QGdCaG3J5xORNkpBTUTagl2AhRnzC2MZwB+ACuApM5tvZmMB3L0COBe4GFhqZveY2S40wN3XE1qtTjMzIwTDSRmr/Aow4BUzm2tmP26sou7+uLt/m9ACNgL4P8D/bWT1LwG7xMu2q8xsFaFFsFfGOosy9l1DaD3cpSWfT0TaLgU1EWkLPiKEmpQvxjLcfa27/9LddwOOB85L3avl7ne5+yFxWweubOIYE4GTgKOAnQiXJIn7+cTdf+LuuwBnAjeY2e5NVdjda9x9KuH+t1TPUa+z2iLgA3fvmjHs5O7fylhn19REvFTaN+Ozt+TziUgbpKAmIsWmg5l1zhjaA3cDF5lZmZn1BH5L6K2JmR0Xb/Y3YDXhkmCNme1hZkfE+8Q2AJ8BNU0c9wVgFTAeuMfdN6UWmNmJZtY3zq4khKJ6+zKzEWZ2spl1s+BA4FBgWlxlCbBbxiavAGtjp4DtzaydmX3VzA7IWOdrZnZCPA/nAhuBaVl8PhFpgxTURKTYPEYIHanhYuByYAYwG3gTeC2WAQwA/hdYB7wM3ODuzxDu3/o9sAz4BPg8cEFjB433tU0itE5NqrP4AGC6ma0DJgM/j/eT1bUS+AkwD1hDCJN/cPe/x+UTCPeUrTKzB929GjiO0HHhg1jXW4EuGft8CPh+3PePgBPi/Wot+nwi0jZZ+G4SEZFiY2YXA7u7+w8LXRcRKQy1qImIiIgUKQU1ERERkSKlS58iIiIiRUotaiIiIiJFSkFNREREpEi1L3QFktCzZ0/v169foashIiIislUzZ85c5u5lDS0ryaDWr18/ZsyYUehqiIiIiGyVmS1sbFmilz7N7BfxvXhzzOzu+JTx/mY23cwqzOxeM+sY1+0U5yvi8n4Z+7kglr9rZkcnWWcRERGRYpFYUDOzPsA5QLm7fxVoB5xMeBfdte6+O+FJ22fETc4AVsbya+N6mNnAuN1ewHDCO/baJVVvERERkWKRdGeC9sD28R11nwM+Bo4A7o/LJwIj4/SIOE9cPjS+u28E4b17G939A6ACODDheouIiIgUXGL3qLn7YjP7I/Ah4X19TwEzgVXuviWuVgn0idN9gEVx2y1mthroEcunZew6cxsREREpAZs3b6ayspINGzYUuiqJ6dy5M3379qVDhw7N3iaxoGZm3QitYf2BVcA/CJcukzreaGA0wBe/+MWkDiMiIiIJqKysZKeddqJfv36EC2qlxd1Zvnw5lZWV9O/fv9nbJXnp80jgA3evcvfNwL+AIUDXeCkUoC+wOE4vBnYFiMu7AMszyxvY5j/cfby7l7t7eVlZgz1cRUREpEht2LCBHj16lGRIAzAzevTo0eIWwySD2ofAYDP7XLzXbCjwFvAM8L24zijgoTg9Oc4Tlz/t4f1Wk4GTY6/Q/sAA4JUE6y0iIiIFUKohLSWbz5fkPWrTzex+4DVgC/A6MB54FLjHzC6PZRPiJhOAO82sAlhB6OmJu881s/sIIW8LMMbdq5Oqt4iIiGybdtxxR9atW1foatSS6ANv3X0cMK5O8Xwa6LXp7huAExvZzxXAFXmvoIiIiEgR07s+s7FxI4wfD2++WeiaiIiISIJmzZrF4MGD2WefffjOd77DypUrAbjuuusYOHAg++yzDyeffDIAzz33HIMGDWLQoEHst99+rF27NufjK6hl47PP4MwzYerUQtdEREREEnTaaadx5ZVXMnv2bPbee28uueQSAH7/+9/z+uuvM3v2bG666SYA/vjHP/LXv/6VWbNm8cILL7D99tvnfPySfNdnq3EvdA1ERERKz7nnwqxZ+d3noEHwpz+1aJPVq1ezatUqDj30UABGjRrFiSeGu7T22WcfTj31VEaOHMnIkeHZ/UOGDOG8887j1FNP5YQTTqBv3745V1statko8V4pIiIi0rRHH32UMWPG8Nprr3HAAQewZcsWxo4dy6233spnn33GkCFDeOedd3I+jlrUcqEWNRERkfxrYctXUrp06UK3bt144YUX+MY3vsGdd97JoYceSk1NDYsWLeLwww/nkEMO4Z577mHdunUsX76cvffem7333ptXX32Vd955hz333DOnOiioZSPVoqagJiIiUjLWr19f63Lleeedx8SJEznrrLNYv349u+22G7fffjvV1dX88Ic/ZPXq1bg755xzDl27duU3v/kNzzzzDNtttx177bUXxxxzTM51UlDLhi59ioiIlJyampoGy6dNm1av7MUXX6xX9pe//CXvddI9arlQi5qIiIgkSEEtG2pRExERkVagoJYLtaiJiIhIghTUsqEWNRERkbzzEm8AyebzKajlosR/oERERFpL586dWb58ecmGNXdn+fLldO7cuUXbqddnNtSiJiIikld9+/alsrKSqqqqQlclMZ07d27x2woU1HJRoqlfRESktXXo0IH+/fsXuhpFR5c+s6EH3oqIiEgrUFDLhi59ioiISCtQUMuFWtREREQkQQpq2VCLmoiIiLQCBbVcqEVNREREEqSglg21qImIiEgrUFDLhVrUREREJEEKatnQ4zlERESkFSioZUOXPkVERKQVKKjlQi1qIiIikqDEgpqZ7WFmszKGNWZ2rpl1N7MpZjYvjrvF9c3MrjOzCjObbWb7Z+xrVFx/npmNSqrOzaYWNREREWkFiQU1d3/X3Qe5+yDga8B64AFgLDDV3QcAU+M8wDHAgDiMBm4EMLPuwDjgIOBAYFwq3BWcWtREREQkQa116XMo8L67LwRGABNj+URgZJweAUzyYBrQ1cx6A0cDU9x9hbuvBKYAw1up3g1Ti5qIiIi0gtYKaicDd8fpXu7+cZz+BOgVp/sAizK2qYxljZUXnlrUREREJEGJBzUz6wgcD/yj7jJ3dyAvacfMRpvZDDObUVVVlY9dNnWwZPcvIiIiQuu0qB0DvObuS+L8knhJkzheGssXA7tmbNc3ljVWXou7j3f3cncvLysry/NHaIRa1ERERCRBrRHUTiF92RNgMpDquTkKeCij/LTY+3MwsDpeIn0SGGZm3WIngmGxrHD0wFsRERFpBe2T3LmZ7QAcBZyZUfx74D4zOwNYCJwUyx8DvgVUEHqIng7g7ivM7DLg1bjepe6+Isl6i4iIiBSDRIOau38K9KhTtpzQC7Tuug6MaWQ/twG3JVHHnKhFTURERBKkNxNkSx0KREREJGEKarlQi5qIiIgkSEEtW2pRExERkYQpqOVCLWoiIiKSIAW1bJkpqImIiEiiFNSypUufIiIikjAFtVyoRU1EREQSpKCWLbWoiYiISMIU1HKhFjURERFJkIJattSiJiIiIglTUMuFWtREREQkQQpq2VKLmoiIiCRMQS0XalETERGRBCmoZUsPvBUREZGEKahlS5c+RUREJGEKarlQi5qIiIgkSEEtW2pRExERkYQpqOVCLWoiIiKSIAW1bKlFTURERBKmoJYLtaiJiIhIghTUsqXHc4iIiEjCFNSypUufIiIikjAFtVyoRU1EREQSpKCWLbWoiYiISMISDWpm1tXM7jezd8zsbTM72My6m9kUM5sXx93iumZm15lZhZnNNrP9M/YzKq4/z8xGJVnnFlGLmoiIiCQo6Ra1PwNPuPuewL7A28BYYKq7DwCmxnmAY4ABcRgN3AhgZt2BccBBwIHAuFS4Kyi1qImIiEjCEgtqZtYF+CYwAcDdN7n7KmAEMDGuNhEYGadHAJM8mAZ0NbPewNHAFHdf4e4rgSnA8KTq3SJqURMREZEEJdmi1h+oAm43s9fN7FYz2wHo5e4fx3U+AXrF6T7AooztK2NZY+WFpcdziIiISMKSDGrtgf2BG919P+BT0pc5AXB3B/KSdsxstJnNMLMZVVVV+djl1g6Y/DFERERkm5ZkUKsEKt19epy/nxDclsRLmsTx0rh8MbBrxvZ9Y1lj5bW4+3h3L3f38rKysrx+kEapRU1EREQSlFhQc/dPgEVmtkcsGgq8BUwGUj03RwEPxenJwGmx9+dgYHW8RPokMMzMusVOBMNiWWGpRU1EREQS1j7h/f838Hcz6wjMB04nhMP7zOwMYCFwUlz3MeBbQAWwPq6Lu68ws8uAV+N6l7r7ioTr3TxqURMREZEEJRrU3H0WUN7AoqENrOvAmEb2cxtwW35rlyO1qImIiEjC9GaCXKhFTURERBKkoJYttaiJiIhIwhTUcqEWNREREUmQglq29MBbERERSZiCWrZ06VNEREQSpqCWC7WoiYiISIIU1LKlFjURERFJmIJaLtSiJiIiIglSUMuWWtREREQkYQpquVCLmoiIiCRIQS1bejyHiIiIJExBLVu69CkiIiIJU1DLhVrUREREJEEKatlq1w5qagpdCxERESlhCmrZatcOtmwpdC1ERESkhCmoZatdO6iuLnQtREREpIQpqGWrfXu1qImIiEiiFNSypRY1ERERSZiCWrbat1dQExERkUQpqGVLnQlEREQkYQpq2dKlTxEREUmYglq2dOlTREREEqagli1d+hQREZGEKahlS5c+RUREJGGJBjUzW2Bmb5rZLDObEcu6m9kUM5sXx91iuZnZdWZWYWazzWz/jP2MiuvPM7NRSda52fQcNREREUlYa7SoHe7ug9y9PM6PBaa6+wBgapwHOAYYEIfRwI0Qgh0wDjgIOBAYlwp3BaUWNREREUlYIS59jgAmxumJwMiM8kkeTAO6mllv4GhgiruvcPeVwBRgeGtXup6OHWHz5kLXQkREREpY0kHNgafMbKaZjY5lvdz94zj9CdArTvcBFmVsWxnLGisvrI4dYePGQtdCRERESlj7hPd/iLsvNrPPA1PM7J3Mhe7uZub5OFAMgqMBvvjFL+Zjl03r2BE2bUr+OCIiIrLNSrRFzd0Xx/FS4AHCPWZL4iVN4nhpXH0xsGvG5n1jWWPldY813t3L3b28rKws3x+lvk6dFNREREQkUYkFNTPbwcx2Sk0Dw4A5wGQg1XNzFPBQnJ4MnBZ7fw4GVsdLpE8Cw8ysW+xEMCyWFZZa1ERERCRhSV767AU8YGap49zl7k+Y2avAfWZ2BrAQOCmu/xjwLaACWA+cDuDuK8zsMuDVuN6l7r4iwXo3j4KaiIiIJCyxoObu84F9GyhfDgxtoNyBMY3s6zbgtnzXMSfqTCAiIiIJ05sJsqV71ERERCRhCmrZSl369Lx0WhURERGpR0EtWx07hpCmtxOIiIhIQhTUstWxYxjrPjURERFJiIJatjp1CmPdpyYiIiIJUVDLVqpFTUFNREREEqKgli0FNREREUmYglq2dI+aiIiIJExBLVu6R01EREQSpqCWLV36FBERkYQpqGWrQ4cwVlATERGRhCioZatduzCuqSlsPURERKRkKahla7t46hTUREREJCEKatlKBTW9QkpEREQSoqCWLV36FBERkYQpqGVLlz5FREQkYQpq2dKlTxEREUlYs4Kame1gZtvF6a+Y2fFm1iHZqhU5XfoUERGRhDW3Re15oLOZ9QGeAn4E3JFUpdoEtaiJiIhIwpob1Mzd1wMnADe4+4nAXslVqw2orAzjW24pbD1ERESkZDU7qJnZwcCpwKOxrF0yVWoj9t03jAcMKGw9REREpGQ1N6idC1wAPODuc81sN+CZ5KrVBpSVhXHv3oWth4iIiJSs9s1Zyd2fA54DiJ0Klrn7OUlWrOh16hTGGzYUth4iIiJSsprb6/MuM9vZzHYA5gBvmdn/l2zVilyq16c6E4iIiEhCmnvpc6C7rwFGAo8D/Qk9P7fKzNqZ2etm9kic729m082swszuNbOOsbxTnK+Iy/tl7OOCWP6umR3dgs+XHD2eQ0RERBLW3KDWIT43bSQw2d03A97MbX8OvJ0xfyVwrbvvDqwEzojlZwArY/m1cT3MbCBwMqGX6XDgBjMrfEcGPZ5DREREEtbcoHYzsADYAXjezL4ErNnaRmbWFzgWuDXOG3AEcH9cZSIh/AGMiPPE5UPj+iOAe9x9o7t/AFQABzaz3skxC4OCmoiIiCSkWUHN3a9z9z7u/i0PFgKHN2PTPwG/AlLXB3sAq9x9S5yvBPrE6T7Aoni8LcDquP5/yhvYprDatdOlTxEREUlMczsTdDGza8xsRhyuJrSuNbXNccBSd5+Zj4o2o46jU/WrqqpqjUOGoKYWNREREUlIcy993gasBU6Kwxrg9q1sMwQ43swWAPcQLnn+GehqZqnHgvQFFsfpxcCuAHF5F2B5ZnkD2/yHu49393J3Ly9LPeMsadttp6AmIiIiiWluUPuyu49z9/lxuATYrakN3P0Cd+/r7v0InQGedvdTCQ/K/V5cbRTwUJyeHOeJy592d4/lJ8deof2BAcArzax3snTpU0RERBLU3KD2mZkdkpoxsyHAZ1ke83zgPDOrINyDNiGWTwB6xPLzgLEA7j4XuA94C3gCGOPuxdGMpUufIiIikqBmvZkAOAuYZGZd4vxK0q1fW+XuzwLPxun5NNBr0903ACc2sv0VwBXNPV6r0aVPERERSVBzXyH1BrCvme0c59eY2bnA7CQrV/R06VNEREQS1NxLn0AIaPENBRAuT27bdOlTREREEtSioFaH5a0WbdXSpfDxx4WuhYiIiJSoXIJac18hVbrcYfLkQtdCRERESlST96iZ2VoaDmQGbJ9IjUREREQE2EpQc/edWqsiIiIiIlJbLpc+RURERCRBCmr54LpdT0RERPJPQS0f9Cw1ERERSYCCWj7oWWoiIiKSAAW1fHjzzULXQEREREqQglo+vPdeoWsgIiIiJUhBLR/UmUBEREQSoKCWDwpqIiIikgAFtXwwvfZURERE8k9BLRfjx4dxv34FrYaIiIiUJgW1XPTvH8Z6PIeIiIgkQEEtF+3ahbGCmoiIiCRAQS0X7eM77RXUREREJAEKarlItaht2VLYeoiIiEhJUlDLhS59ioiISIIU1HKhS58iIiKSIAW1XOjSp4iIiCRIQS0XqRY1BTURERFJQGJBzcw6m9krZvaGmc01s0tieX8zm25mFWZ2r5l1jOWd4nxFXN4vY18XxPJ3zezopOrcYjvsEMbz5xe2HiIiIlKSkmxR2wgc4e77AoOA4WY2GLgSuNbddwdWAmfE9c8AVsbya+N6mNlA4GRgL2A4cIOZtUuw3s3XpUsYjx1b2HqIiIhISUosqHmwLs52iIMDRwD3x/KJwMg4PSLOE5cPNTOL5fe4+0Z3/wCoAA5Mqt4tsvPOha6BiIiIlLBE71Ezs3ZmNgtYCkwB3gdWuXvqpq5KoE+c7gMsAojLVwM9Mssb2KawUveoHXlkYeshIiIiJSnRoObu1e4+COhLaAXbM6ljmdloM5thZjOqqqqSOkx9++6bvldNREREJI9apdenu68CngEOBrqaWWyKoi+wOE4vBnYFiMu7AMszyxvYJvMY49293N3Ly8rKEvkcDercGT77rPWOJyIiItuMJHt9lplZ1zi9PXAU8DYhsH0vrjYKeChOT47zxOVPu7vH8pNjr9D+wADglaTq3WKdO8OyZdCzJ0yZUujaiIiISAlpv/VVstYbmBh7aG4H3Ofuj5jZW8A9ZnY58DowIa4/AbjTzCqAFYSenrj7XDO7D3gL2AKMcffieRVA+/Ywe3Z4ltqFF8JRRxW6RiIiIlIiEgtq7j4b2K+B8vk00GvT3TcAJzayryuAK/Jdx7xo1w5qagpdCxERESlBejNBrrbbLh3U3AtbFxERESkpCmq52k6nUERERJKhlJGrdsXxkgQREREpPQpqucpsUdOlTxEREckjBbVcPfRQelpBTURERPJIQU1ERESkSCmo5ZNa1ERERCSPFNRy9ctfFroGIiIiUqIU1HI1YEB6Wi1qIiIikkcKarnq2DE9raAmIiIieaSglqvFiwtdAxERESlRCmq5evDBQtdARERESpSCWq5+9KP0tC59ioiISB4pqOXquOPS0wpqIiIikkcKarnSuz5FREQkIQpqucoMampRExERkTxSUMuVWaFrICIiIiVKQS1XmUFNLWoiIiKSRwpq+bR6daFrICIiIiVEQS2fKisLXQMREREpIQpqIiIiIkVKQS1XX/hCoWsgIiIiJUpBLVd6jpqIiIgkREFNREREpEglFtTMbFcze8bM3jKzuWb281je3cymmNm8OO4Wy83MrjOzCjObbWb7Z+xrVFx/npmNSqrOIiIiIsUkyRa1LcAv3X0gMBgYY2YDgbHAVHcfAEyN8wDHAAPiMBq4EUKwA8YBBwEHAuNS4U5ERESklCUW1Nz9Y3d/LU6vBd4G+gAjgIlxtYnAyDg9ApjkwTSgq5n1Bo4Gprj7CndfCUwBhidV75yMGVPoGoiIiEgJaZV71MysH7AfMB3o5e4fx0WfAL3idB9gUcZmlbGssfLiccIJYdypU2HrISIiIiUl8aBmZjsC/wTOdfc1mcvc3YG8vHfJzEab2Qwzm1FVVZWPXTbfP/8ZQtqaNVtfV0RERKSZEg1qZtaBENL+7u7/isVL4iVN4nhpLF8M7Jqxed9Y1lh5Le4+3t3L3b28rKwsvx+kOTZuhFtvbf3jioiISMlKstenAROAt939moxFk4FUz81RwEMZ5afF3p+DgdXxEumTwDAz6xY7EQyLZSIiIiIlrX2C+x4C/Ah408xmxbJfA78H7jOzM4CFwElx2WPAt4AKYD1wOoC7rzCzy4BX43qXuvuKBOstIiIiUhQs3CZWWsrLy33GjBmte1CzMC7B8ykiIiLJMbOZ7l7e0DK9mSBffvObML755sLWQ0REREqGglq+bBdP5VlnFbYeIiIiUjIU1PLlppsKXQMREREpMQpq+bJ+faFrICIiIiVGQS1ffvvbQtdARERESoyCWr784AeFroGIiIiUGAW1fNlll0LXQEREREqMglo+nX++XswuIiIieaOglk8dOoR3fq5eXeiaiIiISAlQUMuntWvD+NhjC1sPERERKQkKavl0441h/NJLepWUiIiI5ExBLZ82bUpPV1YWrh4iIiJSEhTUkjJ4cKFrICIiIm2cglpSPvoIpkwpdC1ERESkDVNQy6eJE2vPDxtWmHqIiIhISVBQy6fTTit0DURERKSEKKgl7e23C10DERERaaMU1PLtxBNrzw8cWJh6iIiISJunoJZvf/5zoWsgIiIiJUJBLd969y50DURERKREKKgl4dJLa8+bpV8vJSIiItJMCmpJ+M1v6pftvDN89autXxcRERFpsxTUWtPcufCvf8H69YWuiYiIiLQBCmpJWbmy4fLvfhfOPrt16yIiIiJtUmJBzcxuM7OlZjYno6y7mU0xs3lx3C2Wm5ldZ2YVZjbbzPbP2GZUXH+emY1Kqr5517UrjB/f8LLbb4f58+GnP4UVK7a+r29/O9znJiIiItuUJFvU7gCG1ykbC0x19wHA1DgPcAwwIA6jgRshBDtgHHAQcCAwLhXu2oTvfKfxZV/+Mtx0E4wdC+5QUwOrVkF1NTz0UChLeeSR5OsqIiIiRad9Ujt29+fNrF+d4hHAYXF6IvAscH4sn+TuDkwzs65m1juuO8XdVwCY2RRC+Ls7qXrnVc+eW1/nllugrCy0mF1xBfz2t6HX6N/+FspOOin5eoqIiEhRSiyoNaKXu38cpz8BesXpPsCijPUqY1lj5aXld79LT6ce7XHttTBzJixcmF42YAA8/TTsumvr1k9EREQKomCdCWLrmW91xWYys9FmNsPMZlRVVeVrt7l7+WU48MCWbzdvXhh/8EG6rKIC7rij/rr//ndofXv33ayqKCIiIsWptYPaknhJkzheGssXA5nNRH1jWWPl9bj7eHcvd/fysrKyvFc8a4MHw+TJsNtuLdtuzZowvuWW2uVm8NlnsGFDuuzueCX4ySezr6eIiIgUndYOapOBVM/NUcBDGeWnxd6fg4HV8RLpk8AwM+sWOxEMi2VtS69eoTXsz3+G00/PbV9r14YepZ//PPzwh/DAA9CuXVhWXZ17XUVERKRomHverj7W3rHZ3YTOAD2BJYTemw8C9wFfBBYCJ7n7CjMz4HpCR4H1wOnuPiPu58fAr+Nur3D327d27PLycp8xY0Z+P1A+5ftRG+edB9dcE6bfey/cy9vdvg8AABeOSURBVAawbh106ACzZsEuu6TvbXv8cZg+HS6+OL/1EBERkRYzs5nuXt7gsqSCWiEVfVB78EG4+mp48cX87G/EiPBID4A//hF++cswXTcQusPo0enLqe6hx+luu4Xgli/LlsFTT8EPfpC/fYqIiJQoBbVi9pWvpDsO5EPPnrBkCWy3Xf2gNnUqDB2ant+wATp3DtPN/Tl48slwj9zIkY2v881vwgsvQGVlqE+nTi37DCIiItuQpoKaXiFVaNOnwwUX5G9/y5aFe9YauryaGdIAzjknPV1Tk37t1Zw58Nxz4Z43M7j88vR6w4c3/CDfDRvSYe/998P41ltDEPzww+w/T2NeeinUrbIy//sWEREpEgpqhdatW3iO2vbbp8vWrGl+C1cuMl9xdcQR0L079OsHe+8Nhx2WDkGXXRZC15tvNryfKVNC/U85JVx2/eijUH7//WF8ww1w3HEhDLbUTTfBs8+GtzZkuuGGMH7uuXC8xQ12Bg4efjj/jy6pqWn8fIiIiOSJglqxqKgIoe3aa2GnnWovmzs3+eM/91wYZz5g9+WXw3jTJvjJT2CffdLLPvggtGiZwbBhoezee9OdGiC0zAFceSU8+mjosQohhPboEbatqKhfl9tvhx//OHSG+OlP4fDDYdCghuvtDn36QN++jX+244+HPfesXVZZGY7/4IONb5eyenU4B5muvjqcj63d2zdrVuuEbhERKUkKasVil13CC9rPPbf+soEDw3/2Tz3VunU65ZTGl7X0uXAAmzeHy6tTp6ZfRn/sseFy7ZQp4f2nO+8cQtrtt8MXvpDeduHC0HL2yithvbvuCuWZIahHDzj44BAIq6vDfXILFjRcl1Rr2I03br3eXbumw2hK6h7Ixvb/8cdwzDGw336hNTLlgQdCQEw9Jy9fPv00jKurk7nULCIiBaGg1pYcdVR4uO2dd6bLxoyBX/yicHVqibKycHn1qKPSZe+9F8qHDYP589OtbpAOHyl9+sBBB4X1Uk47LT29YgVMmxbCWp8+oVND//7p5U88EVrGPvwQli8PZZ99FsYnnghnn9143VMtjosWhfvjGgpoF10UXvEF8P3vh+MBvPZaGA8cCCecEKYbakmcOjWEuE8+qV2W2epXU1O/he6992DHHcNbK8aOhS99KX35uTGPP1679bQtevTR8Jq1YvPee/ntINSaxo1Lt6TL1r30Epx/fqFrIaXO3Utu+NrXvuYlIfyX3PCyqir3uXPdt2wJw9Sp7mVl7jNnprcD91NOSU+feKL7pZfWXq6h9vDd77rfcEM4j+7ud96ZXnbLLfXXv/vu+mWPPVZ7/owzav97gnu/funpF15w/8tf0vP/+lf99TN/Jnbc0X3evHTZAw+E8iFD3L/61TD9xhu1f17eecd92bL6P1u33up+ySWhrKbG/eKL3Ssr3Rcvzv7ntinLlrm//XbLtnn/ffeFC+uX1z03c+a4d+nivmhR4/sC93POadnxW6qp39ti15brXgjZnK+VK92rq5OpTz5t2hT+b5FWAczwRjJNo2GnLQ8lE9R+8hP3//f/Wr7dPff4f4LZpk1hWL06vXz06MIFoW11uPnmlq3vXnt+48b6ZcuWue+xR+2yHXcM4+99L/3vvWBBKOvTJ8xv2FD/eI895v7Xv9YuGzeu9s/VsmWhfODAdJ02bnQfO9Z96dLa677yivtLL9Uuywy9ixe7P/tsKK+pCeF082b3Tz91P/989/Xrw7L//d/0Nps3u48Z415R4f7UU7XP1aZNYRm4n3VWGE+fXv93I7XN/PnN+lVyd/d162r/h1Vd7T5pUu2w3NAx1qwJ9cq3OXPCft97LwTtUaMaDrJr1oTzvG5d7ZDelMxzmtrHmjUtr+Ozz7r/7W9bX++++8IfEbmYPr3p8P/cc+F3oCX+/W/3hx7a+nqZP5vNsWZNWP+Xv2xZfQoB3AcNKnQtthkKatuimTPDf4CNWbjQ/brr6v+H3alTGO+5Z/ahREPrDL16Nb384IPdf//73I9zzjkNl++4o/tOO6Xnr77a/Ygj6q83cGC61a+pYeRI98suC9NXXVV/+V57Nbzd5z8fxsceW3+Zu/ubbzZ+zKuucj/11LDek0+6P/xwCA533OF+6KHhD5zUuh99FNa79tp02QMPhFB68cXuU6aE5XXrtmxZCKA33xx+5/7+97DsxBNDID33XPfLL2/697mmJmyz227pfbdvX/tY11xT+3e+f/9Q/uUvh/E997h/+9shdKZacJcsSa+fGX4//ND9s8/cO3YM86kgMmqUe+/e7tdf7/7JJ+nvklmz0vXMDPwvveS+alXjnyu1XnV17fCc+iOgro8+cn/rrVDv1PEz/62bOkbKhRe6P/98CLupY7z1lvuNN7p//LH700+nt7nllnC14tVXQ3iDcO7q7vvTT8P8ddeFfTTm44/D+mVlja+T8thjoXW/pib97/rww+7vvrv1bfNha+c1pbLS/cADa3/uBQvcly8P08uXh9+Rlti8OfyeVFe733VX/VbwTZua/v+tpaqr3f/nf0JrZ4EoqEnj/uu/wo/B5z7nftRR4Qf1uuvSvwRduqR/Yb/73fAFd+SR7r/+dbp8yJDwBfrss43/h6hBQykMX/ua+z77NL78619v2f5GjkxPb9yYnu7YMYSDww8Pl7NTraLNGc4+O4SYxpb37Nm8/XzlK1tf56WX0tPuIXw2tF6XLu4XXZT+3qmudv/DH9LL/+d/wvjxx90ffTRdftVV4fPcfXdooau7X/f09MMPu//whyGYu4dL4Jm3K6Sk5nv3Duc5s6w5w157hdC7/fa1y488MoxTf0BNnBjqX1PjftBBoYU6FdS6dKn9Pfzpp6H187nn6tczNaxcWf+zPPBA7aslKVOmpNd9+WX3GTNC+caN6ds6UqZNc//Vr9It0nWP7x5uPxgzJtRz5sxwDh58MCwbOzasN2hQ+MPjlVfCfPfuYfn++4f5hoLVxo3uL74YpseNc//5z8P01VeHbe64o3Y97rjD/TvfCfP//d/hitPzz9fe57vvhiBXt5UzdVvQ4YeH/+9Sl58//DD9ByKE/9uOOqp+XROmoCaNe+yx8Ndd6i/Cug4/PPyYNHR54ne/cx8+vHbZU0+FFodbb3Xfb7/6Xzann56eTv1lmrn8rrvcr7yyZV+cGjRoKPyQj9bblg4779yy9RtqHX7ttWTrOG1a48suvTRcys8s+81v3H/xi6brvmZNCEap+W9+M7Sgzp0bvlM7dGi6Tu+8437bbaF1te6yN9+s/YfB5Zc3/F3+uc+5/+xnTR/n9dfT0336hD/oX3sttC6vX+9+3HFh2YABtbcZPLj+vtavb/pY69fXDnYQwv2qVSGo1l0/1TrZ2P7cQ9hLtQwmTEFNsrdkSWh+z8Wrr4YftVRz/5w57rNnp5cvXVr7l6OmJlwuOvvsdPmhh4a/TrdsCX81jxwZ/vr8xjfchw51P/PM+r9oJ5zQ+C9hr17hl7CiIgTGn/0sfNZBg2p/uZx0UvovQg0aNGjQsO0NDd3vmmdNBTW961OSt2RJeCba5z8fplvCHf79b/j61xt+LVam1PLMn+kXXoCOHcNjPSA88mPFCth118b3U10N7duHNzJcdFHtZWedBTffHKaHDIHrrw/PSoPw9oSuXcP0OeeE58O9/z706gUXXhjesHDggWGd/fYLr+I68kjo3Tu8O/Uf/wiP71i/Hrp0SR+zvDw8SqOqqn5djzkmPJKjd+/wSI7DDmv6HDVl+PBQZ/3uiIjUlnBWaupdnw2mt7Y+qEWtyKR6Cyb977JkifsHHyR7jAkTwmcZPz7do6+yMgzuofl9w4bcj3P00e63356+z2LJknA/inu4B2TLlobvTXnmmdBauW6d+yOPhL8E//nPUL/UPTQQ9l33r8aUTZvS99msXRvud5oyJdxAvmZNqNMzz4QbyM88M32f4/nnh5bOSy4JlxseeaT+Me6/Pz39+uvheFVV9de7774wLi93Nwv3+GQuX7kyXOaYMSNcfk+Vjx8fxied1PRfyGvXpi+TDB1af3n37o1ve9hhLftr/Lbbtr7ORx+1bJ8aNGho3SFh6NKnFNxdd6V7abVlNTXhxtq2KNWD8Z//DPPduiX/BXT99eEYP/1p7XrcdVfD669fH3oRpsLbrbfWXr58eQihmaqrG/8yXbky3De5YEH9Hl01NeEZdjU1IZzecYf7IYeE/cydG8pXrw5DTU04b2ecEY63YUMIrJk98j77LDxmBMIl9MzAfvfdIcjWfX7Wt78d1t+8OYTxJ56o/Z/DGWekb3SeNCncfH3zzeFy/W23hbD8/PNh+ahR4Xxlbj9pUniMx+bNtXtfppan6jhhQrg5/JvfTC8bNy7cu/q3v9UOpy++mJ7+/vfT04MHh2M01cM3dcM61O61vLUezKkerJB+PExjQ79+4Ub+k04K/yZ1H2FTqCHzM+y+e+Hrk88h8365Uhya00s3RwpqIlLfRx8lf+9F6lENZ52V7HGeeCLdsy0XNTWhF1hrWb8+3CeZMn16OF/l5bXXa+hRFY2ZNy88fy71yIyGpP4DaomHHkp3KnrjjXSL6IIFIYBl+uST9D2mqRvcU1asCJ9ny5bQ6prZG/CTT0IwnT493GP6/vvp5XXr/OijtTseuYcg3FDvwsrKcFP/2rUhtF5xRbpFeunS2q3T69aF+2AvuiiE3MrK+sfOPMbGjelzPX++e9++4f7Zp58OfwhkqqkJ4THTH/7gfsAB6edbfuc74d8/9ViX738/nMPXXw9lixbVDhFnnhlCeqq3q3v63B98cJhfuDD02ofw2TK379EjHOOee0LYfuON8Lm/+tVQl7feCq3mf/pT2NegQaETR6oX5UknhfIPPwydICZOTO/7jjvCv+FFF4WrBBMnun/hC2HZySfXD0SXXx7+KLj88tA6fv314fxnPsj9gANCb92//z38202dmr6v+MQTw89Nz57hXGf+gTFvXv3j3XJL+t8lVZbZK3rIkDA+4YT6P1N51lRQ0z1qIpKchQuhX7/wqqf99y90bYrf+vWw994wYUJu9xtuTUP3c+ZbTU24R3PAgPzsr7o67LNDh9rl7qG8Xbv8HKch990Hc+bApZcmd4x16+C3v4UrroDtt2963YULw6u+NmyAU0+tf06aY/Fi6NkTOnXKrr4Aq1fDDjuEe3ozzZwZ3t88dmzT26d+/szCv+F2TbzVctKkcH/v8cc3vHzZsvCu6I4da5evWRP2u+OO4efx5Zfhu98Nrw/s3j293oQJcMghsMcetbffb79wT/PkyU1/lhw1dY+agpqIyLZm9erwn2Sq84uINOyAA8L7qB97LNHDNBXU2jdUKCIiJSyzV7GINO7OO7NrscwjBTURERGRhuy5Z6FrQBMXhEVERESkkBTURERERIqUgpqIiIhIkVJQExERESlSbSaomdlwM3vXzCrMbCsPZxERERFp+9pEUDOzdsBfgWOAgcApZjawsLUSERERSVabCGrAgUCFu893903APcCIAtdJREREJFFtJaj1ARZlzFfGMhEREZGS1VaC2laZ2Wgzm2FmM6qqqgpdHREREZGctZWgthjYNWO+byz7D3cf7+7l7l5eVlbWqpUTERERSUKbeCm7mbUH3gOGEgLaq8AP3H1uI+tXAQtboWo9gWWtcJxtjc5rMnRek6Hzmgyd12TovCYj1/P6JXdvsJWpTbzr0923mNnZwJNAO+C2xkJaXL9VmtTMbEZjb7uX7Om8JkPnNRk6r8nQeU2GzmsykjyvbSKoAbj7Y8Bjha6HiIiISGtpK/eoiYiIiGxzFNRyM77QFShROq/J0HlNhs5rMnRek6HzmozEzmub6EwgIiIisi1Si5qIiIhIkVJQy4JeEN8yZnabmS01szkZZd3NbIqZzYvjbrHczOy6eG5nm9n+GduMiuvPM7NRhfgsxcTMdjWzZ8zsLTOba2Y/j+U6tzkws85m9oqZvRHP6yWxvL+ZTY/n714z6xjLO8X5iri8X8a+Lojl75rZ0YX5RMXFzNqZ2etm9kic13nNkZktMLM3zWyWmc2IZfoeyJGZdTWz+83sHTN728wOLsh5dXcNLRgIjwd5H9gN6Ai8AQwsdL2KeQC+CewPzMkouwoYG6fHAlfG6W8BjwMGDAamx/LuwPw47hanuxX6sxX4vPYG9o/TOxGeNThQ5zbn82rAjnG6AzA9nq/7gJNj+U3AT+P0z4Cb4vTJwL1xemD8fugE9I/fG+0K/fkKPQDnAXcBj8R5ndfcz+kCoGedMn0P5H5eJwL/N053BLoW4ryqRa3l9IL4FnL354EVdYpHEH4JiOORGeWTPJgGdDWz3sDRwBR3X+HuK4EpwPDka1+83P1jd38tTq8F3ia8A1fnNgfx/KyLsx3i4MARwP2xvO55TZ3v+4GhZmax/B533+juHwAVhO+PbZaZ9QWOBW6N84bOa1L0PZADM+tCaGSYAODum9x9FQU4rwpqLacXxOdHL3f/OE5/AvSK042dX533JsTLQvsRWn90bnMUL8/NApYSvljfB1a5+5a4SuY5+s/5i8tXAz3QeW3In4BfATVxvgc6r/ngwFNmNtPMRscyfQ/kpj9QBdweL9XfamY7UIDzqqAmBeehfVjdj7NkZjsC/wTOdfc1mct0brPj7tXuPojwXuEDgT0LXKU2z8yOA5a6+8xC16UEHeLu+wPHAGPM7JuZC/U9kJX2hFt2bnT3/YBPCZc6/6O1zquCWstt9QXx0ixLYrMwcbw0ljd2fnXeG2BmHQgh7e/u/q9YrHObJ/FSxzPAwYRLGam3uWSeo/+cv7i8C7Acnde6hgDHm9kCwi0jRwB/Ruc1Z+6+OI6XAg8Q/rjQ90BuKoFKd58e5+8nBLdWP68Kai33KjAg9lTqSLjJdXKB69QWTQZSvV9GAQ9llJ8We9AMBlbHZuYngWFm1i32shkWy7ZZ8X6dCcDb7n5NxiKd2xyYWZmZdY3T2wNHEe7/ewb4Xlyt7nlNne/vAU/Hv7QnAyfH3ov9gQHAK63zKYqPu1/g7n3dvR/he/Npdz8VndecmNkOZrZTaprw+zsHfQ/kxN0/ARaZ2R6xaCjwFoU4r63Zg6JUBkLvjvcI961cWOj6FPsA3A18DGwm/JVyBuFek6nAPOB/ge5xXQP+Gs/tm0B5xn5+TLhxuAI4vdCfq9ADcAih2X02MCsO39K5zfm87gO8Hs/rHOC3sXw3QiCoAP4BdIrlneN8RVy+W8a+Lozn+13gmEJ/tmIZgMNI9/rUec3tXO5G6AX7BjA39X+Svgfycm4HATPid8GDhF6brX5e9WYCERERkSKlS58iIiIiRUpBTURERKRIKaiJiIiIFCkFNREREZEipaAmIiIiUqQU1ERkm2VmF5rZXDObbWazzOwgMzvXzD5X6LqJiAB6PIeIbJvM7GDgGuAwd99oZj2BjsC/Cc9AWlbQCoqIoBY1Edl29QaWuftGgBjMvgfsAjxjZs8AmNkwM3vZzF4zs3/Ed6tiZgvM7Coze9PMXjGz3WP5iWY2x8zeMLPnC/PRRKRUqEVNRLZJMXC9CHyO8ITxe939ufguynJ3XxZb2f5FePr9p2Z2PuHJ+ZfG9W5x9yvM7DTgJHc/zszeBIa7+2Iz6+rhfaEiIllRi5qIbJPcfR3wNWA0UAXca2b/p85qg4GBwEtmNovwbr8vZSy/O2N8cJx+CbjDzH4CtEum9iKyrWhf6AqIiBSKu1cDzwLPxpawUXVWMWCKu5/S2C7qTrv7WWZ2EHAsMNPMvubuy/NbcxHZVqhFTUS2SWa2h5kNyCgaBCwE1gI7xbJpwJCM+892MLOvZGzz/Yzxy3GdL7v7dHf/LaGlbtcEP4aIlDi1qInItmpH4C9m1hXYAlQQLoOeAjxhZh+5++HxcujdZtYpbncR8F6c7mZms4GNcTuAP8QAaMBU4I1W+TQiUpLUmUBEJAuZnQ4KXRcRKV269CkiIiJSpNSiJiIiIlKk1KImIiIiUqQU1ERERESKlIKaiIiISJFSUBMREREpUgpqIiIiIkVKQU1ERESkSP3/U6MQlqXfwXMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rcmethod = intialialize_recourse_method('growing_spheres', {}, temp_model, data_models)"
      ],
      "metadata": {
        "id": "1Nzio4oPw3j9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_models.dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f-692EQI5Dy",
        "outputId": "681358b7-4992-4145-fb20-cd9057baf9c8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<carla.data.catalog.online_catalog.OnlineCatalog at 0x7f3a57622650>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CEM"
      ],
      "metadata": {
        "id": "fSgHxu8K9hNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try while making the pixels as continous"
      ],
      "metadata": {
        "id": "BauyTAFx-OOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_models = DataImagesModels('mnist', labels_needed=[4,9], out_dir = 'outputs')\n",
        "print(data_models.dataset.catalog)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "3ff840674aad4742be61a6caccd138a4",
            "e149c530397649f886bdc33b4aa179aa",
            "af57ce72a1164f80ac1f216d032b1f0c",
            "5af6624ac2ae454991fb6259a560a87a",
            "d65cb059e67141aba0b20f2627dbd6e3",
            "4f5fbc52b7bd478bad14bd3fdf77a810",
            "ba6471dd3f074005abc50db015ad40dd",
            "e1b78be17cdd42d9bd47577ce69a785f",
            "5d0bbdbcf29c404ba3629a86c34ad4e4",
            "6ac3fb337d7548428767be7af9931402",
            "c2ee438ce1084467972d5541cea44ecf"
          ]
        },
        "id": "AUGGnodw-Cai",
        "outputId": "ed86eae2-344e-41e5-c4ea-7e0801d1a45c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mnist\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/60000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ff840674aad4742be61a6caccd138a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models... --- logs will be saved to outputs/models_logs.txt\n",
            "{'categorical': [], 'continuous': ['0x0', '0x1', '0x2', '0x3', '0x4', '0x5', '0x6', '0x7', '0x8', '0x9', '0x10', '0x11', '0x12', '0x13', '0x14', '0x15', '0x16', '0x17', '0x18', '0x19', '0x20', '0x21', '0x22', '0x23', '0x24', '0x25', '0x26', '0x27', '1x0', '1x1', '1x2', '1x3', '1x4', '1x5', '1x6', '1x7', '1x8', '1x9', '1x10', '1x11', '1x12', '1x13', '1x14', '1x15', '1x16', '1x17', '1x18', '1x19', '1x20', '1x21', '1x22', '1x23', '1x24', '1x25', '1x26', '1x27', '2x0', '2x1', '2x2', '2x3', '2x4', '2x5', '2x6', '2x7', '2x8', '2x9', '2x10', '2x11', '2x12', '2x13', '2x14', '2x15', '2x16', '2x17', '2x18', '2x19', '2x20', '2x21', '2x22', '2x23', '2x24', '2x25', '2x26', '2x27', '3x0', '3x1', '3x2', '3x3', '3x4', '3x5', '3x6', '3x7', '3x8', '3x9', '3x10', '3x11', '3x12', '3x13', '3x14', '3x15', '3x16', '3x17', '3x18', '3x19', '3x20', '3x21', '3x22', '3x23', '3x24', '3x25', '3x26', '3x27', '4x0', '4x1', '4x2', '4x3', '4x4', '4x5', '4x6', '4x7', '4x8', '4x9', '4x10', '4x11', '4x12', '4x13', '4x14', '4x15', '4x16', '4x17', '4x18', '4x19', '4x20', '4x21', '4x22', '4x23', '4x24', '4x25', '4x26', '4x27', '5x0', '5x1', '5x2', '5x3', '5x4', '5x5', '5x6', '5x7', '5x8', '5x9', '5x10', '5x11', '5x12', '5x13', '5x14', '5x15', '5x16', '5x17', '5x18', '5x19', '5x20', '5x21', '5x22', '5x23', '5x24', '5x25', '5x26', '5x27', '6x0', '6x1', '6x2', '6x3', '6x4', '6x5', '6x6', '6x7', '6x8', '6x9', '6x10', '6x11', '6x12', '6x13', '6x14', '6x15', '6x16', '6x17', '6x18', '6x19', '6x20', '6x21', '6x22', '6x23', '6x24', '6x25', '6x26', '6x27', '7x0', '7x1', '7x2', '7x3', '7x4', '7x5', '7x6', '7x7', '7x8', '7x9', '7x10', '7x11', '7x12', '7x13', '7x14', '7x15', '7x16', '7x17', '7x18', '7x19', '7x20', '7x21', '7x22', '7x23', '7x24', '7x25', '7x26', '7x27', '8x0', '8x1', '8x2', '8x3', '8x4', '8x5', '8x6', '8x7', '8x8', '8x9', '8x10', '8x11', '8x12', '8x13', '8x14', '8x15', '8x16', '8x17', '8x18', '8x19', '8x20', '8x21', '8x22', '8x23', '8x24', '8x25', '8x26', '8x27', '9x0', '9x1', '9x2', '9x3', '9x4', '9x5', '9x6', '9x7', '9x8', '9x9', '9x10', '9x11', '9x12', '9x13', '9x14', '9x15', '9x16', '9x17', '9x18', '9x19', '9x20', '9x21', '9x22', '9x23', '9x24', '9x25', '9x26', '9x27', '10x0', '10x1', '10x2', '10x3', '10x4', '10x5', '10x6', '10x7', '10x8', '10x9', '10x10', '10x11', '10x12', '10x13', '10x14', '10x15', '10x16', '10x17', '10x18', '10x19', '10x20', '10x21', '10x22', '10x23', '10x24', '10x25', '10x26', '10x27', '11x0', '11x1', '11x2', '11x3', '11x4', '11x5', '11x6', '11x7', '11x8', '11x9', '11x10', '11x11', '11x12', '11x13', '11x14', '11x15', '11x16', '11x17', '11x18', '11x19', '11x20', '11x21', '11x22', '11x23', '11x24', '11x25', '11x26', '11x27', '12x0', '12x1', '12x2', '12x3', '12x4', '12x5', '12x6', '12x7', '12x8', '12x9', '12x10', '12x11', '12x12', '12x13', '12x14', '12x15', '12x16', '12x17', '12x18', '12x19', '12x20', '12x21', '12x22', '12x23', '12x24', '12x25', '12x26', '12x27', '13x0', '13x1', '13x2', '13x3', '13x4', '13x5', '13x6', '13x7', '13x8', '13x9', '13x10', '13x11', '13x12', '13x13', '13x14', '13x15', '13x16', '13x17', '13x18', '13x19', '13x20', '13x21', '13x22', '13x23', '13x24', '13x25', '13x26', '13x27', '14x0', '14x1', '14x2', '14x3', '14x4', '14x5', '14x6', '14x7', '14x8', '14x9', '14x10', '14x11', '14x12', '14x13', '14x14', '14x15', '14x16', '14x17', '14x18', '14x19', '14x20', '14x21', '14x22', '14x23', '14x24', '14x25', '14x26', '14x27', '15x0', '15x1', '15x2', '15x3', '15x4', '15x5', '15x6', '15x7', '15x8', '15x9', '15x10', '15x11', '15x12', '15x13', '15x14', '15x15', '15x16', '15x17', '15x18', '15x19', '15x20', '15x21', '15x22', '15x23', '15x24', '15x25', '15x26', '15x27', '16x0', '16x1', '16x2', '16x3', '16x4', '16x5', '16x6', '16x7', '16x8', '16x9', '16x10', '16x11', '16x12', '16x13', '16x14', '16x15', '16x16', '16x17', '16x18', '16x19', '16x20', '16x21', '16x22', '16x23', '16x24', '16x25', '16x26', '16x27', '17x0', '17x1', '17x2', '17x3', '17x4', '17x5', '17x6', '17x7', '17x8', '17x9', '17x10', '17x11', '17x12', '17x13', '17x14', '17x15', '17x16', '17x17', '17x18', '17x19', '17x20', '17x21', '17x22', '17x23', '17x24', '17x25', '17x26', '17x27', '18x0', '18x1', '18x2', '18x3', '18x4', '18x5', '18x6', '18x7', '18x8', '18x9', '18x10', '18x11', '18x12', '18x13', '18x14', '18x15', '18x16', '18x17', '18x18', '18x19', '18x20', '18x21', '18x22', '18x23', '18x24', '18x25', '18x26', '18x27', '19x0', '19x1', '19x2', '19x3', '19x4', '19x5', '19x6', '19x7', '19x8', '19x9', '19x10', '19x11', '19x12', '19x13', '19x14', '19x15', '19x16', '19x17', '19x18', '19x19', '19x20', '19x21', '19x22', '19x23', '19x24', '19x25', '19x26', '19x27', '20x0', '20x1', '20x2', '20x3', '20x4', '20x5', '20x6', '20x7', '20x8', '20x9', '20x10', '20x11', '20x12', '20x13', '20x14', '20x15', '20x16', '20x17', '20x18', '20x19', '20x20', '20x21', '20x22', '20x23', '20x24', '20x25', '20x26', '20x27', '21x0', '21x1', '21x2', '21x3', '21x4', '21x5', '21x6', '21x7', '21x8', '21x9', '21x10', '21x11', '21x12', '21x13', '21x14', '21x15', '21x16', '21x17', '21x18', '21x19', '21x20', '21x21', '21x22', '21x23', '21x24', '21x25', '21x26', '21x27', '22x0', '22x1', '22x2', '22x3', '22x4', '22x5', '22x6', '22x7', '22x8', '22x9', '22x10', '22x11', '22x12', '22x13', '22x14', '22x15', '22x16', '22x17', '22x18', '22x19', '22x20', '22x21', '22x22', '22x23', '22x24', '22x25', '22x26', '22x27', '23x0', '23x1', '23x2', '23x3', '23x4', '23x5', '23x6', '23x7', '23x8', '23x9', '23x10', '23x11', '23x12', '23x13', '23x14', '23x15', '23x16', '23x17', '23x18', '23x19', '23x20', '23x21', '23x22', '23x23', '23x24', '23x25', '23x26', '23x27', '24x0', '24x1', '24x2', '24x3', '24x4', '24x5', '24x6', '24x7', '24x8', '24x9', '24x10', '24x11', '24x12', '24x13', '24x14', '24x15', '24x16', '24x17', '24x18', '24x19', '24x20', '24x21', '24x22', '24x23', '24x24', '24x25', '24x26', '24x27', '25x0', '25x1', '25x2', '25x3', '25x4', '25x5', '25x6', '25x7', '25x8', '25x9', '25x10', '25x11', '25x12', '25x13', '25x14', '25x15', '25x16', '25x17', '25x18', '25x19', '25x20', '25x21', '25x22', '25x23', '25x24', '25x25', '25x26', '25x27', '26x0', '26x1', '26x2', '26x3', '26x4', '26x5', '26x6', '26x7', '26x8', '26x9', '26x10', '26x11', '26x12', '26x13', '26x14', '26x15', '26x16', '26x17', '26x18', '26x19', '26x20', '26x21', '26x22', '26x23', '26x24', '26x25', '26x26', '26x27', '27x0', '27x1', '27x2', '27x3', '27x4', '27x5', '27x6', '27x7', '27x8', '27x9', '27x10', '27x11', '27x12', '27x13', '27x14', '27x15', '27x16', '27x17', '27x18', '27x19', '27x20', '27x21', '27x22', '27x23', '27x24', '27x25', '27x26', '27x27'], 'immutable': [], 'target': 'label'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytest\n",
        "from tensorflow import Graph, Session\n",
        "\n",
        "from carla.data.catalog import OnlineCatalog\n",
        "from carla.models.catalog import MLModelCatalog\n",
        "from carla.models.negative_instances import predict_negative_instances\n",
        "from carla.recourse_methods.catalog.actionable_recourse import ActionableRecourse\n",
        "from carla.recourse_methods.catalog.cchvae import CCHVAE\n",
        "from carla.recourse_methods.catalog.cem import CEM\n",
        "from carla.recourse_methods.catalog.clue import Clue\n",
        "from carla.recourse_methods.catalog.crud import CRUD\n",
        "from carla.recourse_methods.catalog.dice import Dice\n",
        "from carla.recourse_methods.catalog.face import Face\n",
        "from carla.recourse_methods.catalog.feature_tweak import FeatureTweak\n",
        "from carla.recourse_methods.catalog.focus import FOCUS\n",
        "from carla.recourse_methods.catalog.growing_spheres.model import GrowingSpheres\n",
        "from carla.recourse_methods.catalog.revise import Revise\n",
        "from carla.recourse_methods.catalog.wachter import Wachter\n",
        "\n",
        "\n",
        "hyperparams_cem = {\n",
        "    \"data_name\": data_name,\n",
        "}\n",
        "\n",
        "graph = Graph()\n",
        "with graph.as_default():\n",
        "    ann_sess = Session()\n",
        "    with ann_sess.as_default():\n",
        "        \n",
        "        model_ann = MLModelCatalog(\n",
        "                    data=data_models.dataset,\n",
        "                    model_type='ann',\n",
        "                    load_online=False,\n",
        "                    backend=\"tensorflow\",\n",
        "                )\n",
        "        model_ann.train(learning_rate=0.002, epochs=2, batch_size=64, hidden_size =[13,4])\n",
        "        test_factuals = data_models.dataset.df.iloc[:5]\n",
        "\n",
        "        recourse = CEM(\n",
        "            sess=ann_sess,\n",
        "            mlmodel=model_ann,\n",
        "            hyperparams=hyperparams_cem,\n",
        "        )\n",
        "\n",
        "        counterfactuals_df = recourse.get_counterfactuals(factuals=test_factuals)\n",
        "count = 0\n",
        "max_count = 5\n",
        "fig, axs = plt.subplots(3, max_count, figsize=(20,6))\n",
        "\n",
        "df_sample = test_factuals\n",
        "factual = test_factuals.copy()\n",
        "adada=0\n",
        "for idx, row in df_sample.iterrows():\n",
        "  if True:\n",
        "    colss = factual.drop('label', axis = 1).columns\n",
        "    fcc =  factual[factual.index==idx].astype(float)\n",
        "    cf = counterfactuals_df.copy()\n",
        "    cf_np = cf[colss].values[adada].reshape(28,28).astype(float)\n",
        "    f_np = factual.loc[idx].drop('label').values.reshape(28,28).astype(float)\n",
        "    adada = adada +1\n",
        "    cf_rgb = np.zeros((f_np.shape[0],f_np.shape[1],3))\n",
        "    cf_rgb_fm = np.zeros((f_np.shape[0],f_np.shape[1],3))\n",
        "\n",
        "    for i in range(3):\n",
        "      cf_rgb[:,:,i] = f_np \n",
        "\n",
        "    for i in range(cf_rgb.shape[0]):\n",
        "      for j in range(cf_rgb.shape[1]):\n",
        "        if f_np[i,j] > cf_np[i,j]:\n",
        "          cf_rgb[i,j,0] = 255\n",
        "          cf_rgb[i,j,1] = 0\n",
        "          cf_rgb[i,j,2] = 0\n",
        "\n",
        "        elif f_np[i,j] < cf_np[i,j]:\n",
        "          cf_rgb[i,j,0] = 0\n",
        "          cf_rgb[i,j,1] = 255\n",
        "          cf_rgb[i,j,2] = 0\n",
        "\n",
        "\n",
        "    axs[0, count].set_title(str(idx))\n",
        "    axs[0, count].imshow(f_np, cmap='gray')\n",
        "    axs[1, count].imshow(cf_np, cmap='gray')\n",
        "    axs[2, count].imshow(cf_rgb, )\n",
        "    count += 1\n",
        "    if count == max_count:\n",
        "      break\n",
        "  else:\n",
        "    print(\"exception\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "v8J5c0Io95Qj",
        "outputId": "96072384-04cd-4f30-a332-e1692673cb58"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from /root/carla/models/mnist/ann_layers_13_4.h5\n",
            "test accuracy for model: 0.9690546841882154\n",
            "Train on 8253 samples, validate on 3538 samples\n",
            "Epoch 1/5\n",
            "8253/8253 [==============================] - 1s 68us/step - loss: 0.0763 - val_loss: 0.0520\n",
            "Epoch 2/5\n",
            "8253/8253 [==============================] - 0s 55us/step - loss: 0.0470 - val_loss: 0.0443\n",
            "Epoch 3/5\n",
            "8253/8253 [==============================] - 0s 52us/step - loss: 0.0430 - val_loss: 0.0418\n",
            "Epoch 4/5\n",
            "8253/8253 [==============================] - 1s 78us/step - loss: 0.0410 - val_loss: 0.0401\n",
            "Epoch 5/5\n",
            "8253/8253 [==============================] - 2s 233us/step - loss: 0.0390 - val_loss: 0.0375\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x432 with 15 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try while making the pixels as categorical binary"
      ],
      "metadata": {
        "id": "XlEq6NvI-TZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_models.dataset.catalog)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg8cEHW-9-Zy",
        "outputId": "e51e80b6-dd3e-4e6c-ca3a-b87cbf287539"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'categorical': ['0x0', '0x1', '0x2', '0x3', '0x4', '0x5', '0x6', '0x7', '0x8', '0x9', '0x10', '0x11', '0x12', '0x13', '0x14', '0x15', '0x16', '0x17', '0x18', '0x19', '0x20', '0x21', '0x22', '0x23', '0x24', '0x25', '0x26', '0x27', '1x0', '1x1', '1x2', '1x3', '1x4', '1x5', '1x6', '1x7', '1x8', '1x9', '1x10', '1x11', '1x12', '1x13', '1x14', '1x15', '1x16', '1x17', '1x18', '1x19', '1x20', '1x21', '1x22', '1x23', '1x24', '1x25', '1x26', '1x27', '2x0', '2x1', '2x2', '2x3', '2x4', '2x5', '2x6', '2x7', '2x8', '2x9', '2x10', '2x11', '2x12', '2x13', '2x14', '2x15', '2x16', '2x17', '2x18', '2x19', '2x20', '2x21', '2x22', '2x23', '2x24', '2x25', '2x26', '2x27', '3x0', '3x1', '3x2', '3x3', '3x4', '3x5', '3x6', '3x7', '3x8', '3x9', '3x10', '3x11', '3x12', '3x13', '3x14', '3x15', '3x16', '3x17', '3x18', '3x19', '3x20', '3x21', '3x22', '3x23', '3x24', '3x25', '3x26', '3x27', '4x0', '4x1', '4x2', '4x3', '4x4', '4x5', '4x6', '4x7', '4x8', '4x9', '4x10', '4x11', '4x12', '4x13', '4x14', '4x15', '4x16', '4x17', '4x18', '4x19', '4x20', '4x21', '4x22', '4x23', '4x24', '4x25', '4x26', '4x27', '5x0', '5x1', '5x2', '5x3', '5x4', '5x5', '5x6', '5x7', '5x8', '5x9', '5x10', '5x11', '5x12', '5x13', '5x14', '5x15', '5x16', '5x17', '5x18', '5x19', '5x20', '5x21', '5x22', '5x23', '5x24', '5x25', '5x26', '5x27', '6x0', '6x1', '6x2', '6x3', '6x4', '6x5', '6x6', '6x7', '6x8', '6x9', '6x10', '6x11', '6x12', '6x13', '6x14', '6x15', '6x16', '6x17', '6x18', '6x19', '6x20', '6x21', '6x22', '6x23', '6x24', '6x25', '6x26', '6x27', '7x0', '7x1', '7x2', '7x3', '7x4', '7x5', '7x6', '7x7', '7x8', '7x9', '7x10', '7x11', '7x12', '7x13', '7x14', '7x15', '7x16', '7x17', '7x18', '7x19', '7x20', '7x21', '7x22', '7x23', '7x24', '7x25', '7x26', '7x27', '8x0', '8x1', '8x2', '8x3', '8x4', '8x5', '8x6', '8x7', '8x8', '8x9', '8x10', '8x11', '8x12', '8x13', '8x14', '8x15', '8x16', '8x17', '8x18', '8x19', '8x20', '8x21', '8x22', '8x23', '8x24', '8x25', '8x26', '8x27', '9x0', '9x1', '9x2', '9x3', '9x4', '9x5', '9x6', '9x7', '9x8', '9x9', '9x10', '9x11', '9x12', '9x13', '9x14', '9x15', '9x16', '9x17', '9x18', '9x19', '9x20', '9x21', '9x22', '9x23', '9x24', '9x25', '9x26', '9x27', '10x0', '10x1', '10x2', '10x3', '10x4', '10x5', '10x6', '10x7', '10x8', '10x9', '10x10', '10x11', '10x12', '10x13', '10x14', '10x15', '10x16', '10x17', '10x18', '10x19', '10x20', '10x21', '10x22', '10x23', '10x24', '10x25', '10x26', '10x27', '11x0', '11x1', '11x2', '11x3', '11x4', '11x5', '11x6', '11x7', '11x8', '11x9', '11x10', '11x11', '11x12', '11x13', '11x14', '11x15', '11x16', '11x17', '11x18', '11x19', '11x20', '11x21', '11x22', '11x23', '11x24', '11x25', '11x26', '11x27', '12x0', '12x1', '12x2', '12x3', '12x4', '12x5', '12x6', '12x7', '12x8', '12x9', '12x10', '12x11', '12x12', '12x13', '12x14', '12x15', '12x16', '12x17', '12x18', '12x19', '12x20', '12x21', '12x22', '12x23', '12x24', '12x25', '12x26', '12x27', '13x0', '13x1', '13x2', '13x3', '13x4', '13x5', '13x6', '13x7', '13x8', '13x9', '13x10', '13x11', '13x12', '13x13', '13x14', '13x15', '13x16', '13x17', '13x18', '13x19', '13x20', '13x21', '13x22', '13x23', '13x24', '13x25', '13x26', '13x27', '14x0', '14x1', '14x2', '14x3', '14x4', '14x5', '14x6', '14x7', '14x8', '14x9', '14x10', '14x11', '14x12', '14x13', '14x14', '14x15', '14x16', '14x17', '14x18', '14x19', '14x20', '14x21', '14x22', '14x23', '14x24', '14x25', '14x26', '14x27', '15x0', '15x1', '15x2', '15x3', '15x4', '15x5', '15x6', '15x7', '15x8', '15x9', '15x10', '15x11', '15x12', '15x13', '15x14', '15x15', '15x16', '15x17', '15x18', '15x19', '15x20', '15x21', '15x22', '15x23', '15x24', '15x25', '15x26', '15x27', '16x0', '16x1', '16x2', '16x3', '16x4', '16x5', '16x6', '16x7', '16x8', '16x9', '16x10', '16x11', '16x12', '16x13', '16x14', '16x15', '16x16', '16x17', '16x18', '16x19', '16x20', '16x21', '16x22', '16x23', '16x24', '16x25', '16x26', '16x27', '17x0', '17x1', '17x2', '17x3', '17x4', '17x5', '17x6', '17x7', '17x8', '17x9', '17x10', '17x11', '17x12', '17x13', '17x14', '17x15', '17x16', '17x17', '17x18', '17x19', '17x20', '17x21', '17x22', '17x23', '17x24', '17x25', '17x26', '17x27', '18x0', '18x1', '18x2', '18x3', '18x4', '18x5', '18x6', '18x7', '18x8', '18x9', '18x10', '18x11', '18x12', '18x13', '18x14', '18x15', '18x16', '18x17', '18x18', '18x19', '18x20', '18x21', '18x22', '18x23', '18x24', '18x25', '18x26', '18x27', '19x0', '19x1', '19x2', '19x3', '19x4', '19x5', '19x6', '19x7', '19x8', '19x9', '19x10', '19x11', '19x12', '19x13', '19x14', '19x15', '19x16', '19x17', '19x18', '19x19', '19x20', '19x21', '19x22', '19x23', '19x24', '19x25', '19x26', '19x27', '20x0', '20x1', '20x2', '20x3', '20x4', '20x5', '20x6', '20x7', '20x8', '20x9', '20x10', '20x11', '20x12', '20x13', '20x14', '20x15', '20x16', '20x17', '20x18', '20x19', '20x20', '20x21', '20x22', '20x23', '20x24', '20x25', '20x26', '20x27', '21x0', '21x1', '21x2', '21x3', '21x4', '21x5', '21x6', '21x7', '21x8', '21x9', '21x10', '21x11', '21x12', '21x13', '21x14', '21x15', '21x16', '21x17', '21x18', '21x19', '21x20', '21x21', '21x22', '21x23', '21x24', '21x25', '21x26', '21x27', '22x0', '22x1', '22x2', '22x3', '22x4', '22x5', '22x6', '22x7', '22x8', '22x9', '22x10', '22x11', '22x12', '22x13', '22x14', '22x15', '22x16', '22x17', '22x18', '22x19', '22x20', '22x21', '22x22', '22x23', '22x24', '22x25', '22x26', '22x27', '23x0', '23x1', '23x2', '23x3', '23x4', '23x5', '23x6', '23x7', '23x8', '23x9', '23x10', '23x11', '23x12', '23x13', '23x14', '23x15', '23x16', '23x17', '23x18', '23x19', '23x20', '23x21', '23x22', '23x23', '23x24', '23x25', '23x26', '23x27', '24x0', '24x1', '24x2', '24x3', '24x4', '24x5', '24x6', '24x7', '24x8', '24x9', '24x10', '24x11', '24x12', '24x13', '24x14', '24x15', '24x16', '24x17', '24x18', '24x19', '24x20', '24x21', '24x22', '24x23', '24x24', '24x25', '24x26', '24x27', '25x0', '25x1', '25x2', '25x3', '25x4', '25x5', '25x6', '25x7', '25x8', '25x9', '25x10', '25x11', '25x12', '25x13', '25x14', '25x15', '25x16', '25x17', '25x18', '25x19', '25x20', '25x21', '25x22', '25x23', '25x24', '25x25', '25x26', '25x27', '26x0', '26x1', '26x2', '26x3', '26x4', '26x5', '26x6', '26x7', '26x8', '26x9', '26x10', '26x11', '26x12', '26x13', '26x14', '26x15', '26x16', '26x17', '26x18', '26x19', '26x20', '26x21', '26x22', '26x23', '26x24', '26x25', '26x26', '26x27', '27x0', '27x1', '27x2', '27x3', '27x4', '27x5', '27x6', '27x7', '27x8', '27x9', '27x10', '27x11', '27x12', '27x13', '27x14', '27x15', '27x16', '27x17', '27x18', '27x19', '27x20', '27x21', '27x22', '27x23', '27x24', '27x25', '27x26', '27x27'], 'continuous': [], 'immutable': [], 'target': 'label'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytest\n",
        "from tensorflow import Graph, Session\n",
        "\n",
        "from carla.data.catalog import OnlineCatalog\n",
        "from carla.models.catalog import MLModelCatalog\n",
        "from carla.models.negative_instances import predict_negative_instances\n",
        "from carla.recourse_methods.catalog.actionable_recourse import ActionableRecourse\n",
        "from carla.recourse_methods.catalog.cchvae import CCHVAE\n",
        "from carla.recourse_methods.catalog.cem import CEM\n",
        "from carla.recourse_methods.catalog.clue import Clue\n",
        "from carla.recourse_methods.catalog.crud import CRUD\n",
        "from carla.recourse_methods.catalog.dice import Dice\n",
        "from carla.recourse_methods.catalog.face import Face\n",
        "from carla.recourse_methods.catalog.feature_tweak import FeatureTweak\n",
        "from carla.recourse_methods.catalog.focus import FOCUS\n",
        "from carla.recourse_methods.catalog.growing_spheres.model import GrowingSpheres\n",
        "from carla.recourse_methods.catalog.revise import Revise\n",
        "from carla.recourse_methods.catalog.wachter import Wachter\n",
        "\n",
        "\n",
        "hyperparams_cem = {\n",
        "    \"data_name\": data_name,\n",
        "}\n",
        "\n",
        "graph = Graph()\n",
        "with graph.as_default():\n",
        "    ann_sess = Session()\n",
        "    with ann_sess.as_default():\n",
        "        \n",
        "        model_ann = MLModelCatalog(\n",
        "                    data=data_models.dataset,\n",
        "                    model_type='ann',\n",
        "                    load_online=False,\n",
        "                    backend=\"tensorflow\",\n",
        "                )\n",
        "        model_ann.train(learning_rate=0.002, epochs=2, batch_size=64, hidden_size =[13,4])\n",
        "        test_factuals = data_models.dataset.df.iloc[:5]\n",
        "\n",
        "        recourse = CEM(\n",
        "            sess=ann_sess,\n",
        "            mlmodel=model_ann,\n",
        "            hyperparams=hyperparams_cem,\n",
        "        )\n",
        "\n",
        "        counterfactuals_df = recourse.get_counterfactuals(factuals=test_factuals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiWawKpsIscF",
        "outputId": "109c9d8d-012d-4406-ead2-1d3658a839d6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from /root/carla/models/mnist/ann_layers_13_4.h5\n",
            "test accuracy for model: 0.9690546841882154\n",
            "Train on 8253 samples, validate on 3538 samples\n",
            "Epoch 1/5\n",
            "8253/8253 [==============================] - 1s 181us/step - loss: 0.0806 - val_loss: 0.0525\n",
            "Epoch 2/5\n",
            "8253/8253 [==============================] - 1s 116us/step - loss: 0.0474 - val_loss: 0.0425\n",
            "Epoch 3/5\n",
            "8253/8253 [==============================] - 1s 126us/step - loss: 0.0407 - val_loss: 0.0395\n",
            "Epoch 4/5\n",
            "8253/8253 [==============================] - 1s 137us/step - loss: 0.0393 - val_loss: 0.0390\n",
            "Epoch 5/5\n",
            "8253/8253 [==============================] - 1s 106us/step - loss: 0.0387 - val_loss: 0.0383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "math.sqrt(3918)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF1MDBEL8-eS",
        "outputId": "2de938c2-b623-466e-8851-7ac513f4c287"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62.5939294181153"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf[colss].values[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1YJC0Kr9Gzw",
        "outputId": "112e224b-9686-48a8-d99b-c6c6f2b7af92"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "max_count = 5\n",
        "fig, axs = plt.subplots(3, max_count, figsize=(20,6))\n",
        "\n",
        "df_sample = test_factuals\n",
        "factual = test_factuals.copy()\n",
        "adada=0\n",
        "for idx, row in df_sample.iterrows():\n",
        "  if True:\n",
        "    colss = factual.drop('label', axis = 1).columns\n",
        "    fcc =  factual[factual.index==idx].astype(float)\n",
        "    cf = counterfactuals_df.copy()\n",
        "    cf_np = cf[colss].values[adada].reshape(28,28).astype(float)\n",
        "    f_np = factual.loc[idx].drop('label').values.reshape(28,28).astype(float)\n",
        "    adada = adada +1\n",
        "    cf_rgb = np.zeros((f_np.shape[0],f_np.shape[1],3))\n",
        "    cf_rgb_fm = np.zeros((f_np.shape[0],f_np.shape[1],3))\n",
        "\n",
        "    for i in range(3):\n",
        "      cf_rgb[:,:,i] = f_np \n",
        "\n",
        "    for i in range(cf_rgb.shape[0]):\n",
        "      for j in range(cf_rgb.shape[1]):\n",
        "        if f_np[i,j] > cf_np[i,j]:\n",
        "          cf_rgb[i,j,0] = 255\n",
        "          cf_rgb[i,j,1] = 0\n",
        "          cf_rgb[i,j,2] = 0\n",
        "\n",
        "        elif f_np[i,j] < cf_np[i,j]:\n",
        "          cf_rgb[i,j,0] = 0\n",
        "          cf_rgb[i,j,1] = 255\n",
        "          cf_rgb[i,j,2] = 0\n",
        "\n",
        "\n",
        "    axs[0, count].set_title(str(idx))\n",
        "    axs[0, count].imshow(f_np, cmap='gray')\n",
        "    axs[1, count].imshow(cf_np, cmap='gray')\n",
        "    axs[2, count].imshow(cf_rgb, )\n",
        "    count += 1\n",
        "    if count == max_count:\n",
        "      break\n",
        "  else:\n",
        "    print(\"exception\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "ii5obdN58rln",
        "outputId": "59b6f564-76b7-44db-8085-fb9da75430f1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x432 with 15 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### End of CEM"
      ],
      "metadata": {
        "id": "gORUyJ9X9joX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnnmodel = temp_model"
      ],
      "metadata": {
        "id": "UMy8rHzq7CY5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "factuals = data_models.dataset.df.copy()\n",
        "factual = factuals.copy()\n",
        "from scipy import signal \n",
        "def gkern(kernlen = 21, std=3):\n",
        "  gkern1d = signal.gaussian(kernlen, std=std).reshape(kernlen,1)\n",
        "  gkern2d = np.outer(gkern1d, gkern1d )\n",
        "  return gkern2d\n",
        "k = 2\n",
        "kernel = gkern(kernlen=2*k+1, std=2)*255\n",
        "plt.imshow(kernel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "kVkn80ld6t6e",
        "outputId": "5e3f7a8f-d820-48e2-a4d4-1c3308dea359"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3a4bb964d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_models.trainData.df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrI7u04AY9BG",
        "outputId": "abfe3dbf-af9f-45fd-871a-b5d55f1566aa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5877\n",
              "0    5764\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "max_count = 5\n",
        "fig, axs = plt.subplots(3, max_count, figsize=(20,6))\n",
        "\n",
        "df_sample = factual.sample(max_count*3)\n",
        "for idx, row in df_sample.iterrows():\n",
        "  if True:\n",
        "    colss = factual.drop('label', axis = 1).columns\n",
        "    fcc =  factual[factual.index==idx].astype(float)\n",
        "    cf = rcmethod.get_counterfactuals(fcc)\n",
        "    cf_np = cf[colss].values.reshape(28,28).astype(float)\n",
        "    f_np = factual.loc[idx].drop('label').values.reshape(28,28).astype(float)\n",
        "\n",
        "    cf_rgb = np.zeros((f_np.shape[0],f_np.shape[1],3))\n",
        "    cf_rgb_fm = np.zeros((f_np.shape[0],f_np.shape[1],3))\n",
        "\n",
        "    for i in range(3):\n",
        "      cf_rgb[:,:,i] = f_np \n",
        "\n",
        "    for i in range(cf_rgb.shape[0]):\n",
        "      for j in range(cf_rgb.shape[1]):\n",
        "        if f_np[i,j] > cf_np[i,j]:\n",
        "          cf_rgb[i,j,0] = 255\n",
        "          cf_rgb[i,j,1] = 0\n",
        "          cf_rgb[i,j,2] = 0\n",
        "\n",
        "        elif f_np[i,j] < cf_np[i,j]:\n",
        "          cf_rgb[i,j,0] = 0\n",
        "          cf_rgb[i,j,1] = 255\n",
        "          cf_rgb[i,j,2] = 0\n",
        "\n",
        "\n",
        "    axs[0, count].set_title(str(idx))\n",
        "    axs[0, count].imshow(f_np, cmap='gray')\n",
        "    axs[1, count].imshow(cf_np, cmap='gray')\n",
        "    axs[2, count].imshow(cf_rgb, )\n",
        "    count += 1\n",
        "    if count == max_count:\n",
        "      break\n",
        "  else:\n",
        "    print(\"exception\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "8lPnm8rr6hD0",
        "outputId": "f7964e61-1dc6-4e9c-e9c9-686e8762b4d1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x432 with 15 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rcmethod = intialialize_recourse_method('cem', {}, temp_model, data_models)\n",
        "count = 0\n",
        "max_count = 20\n",
        "fig, axs = plt.subplots(3, max_count, figsize=(20,6))\n",
        "\n",
        "df_sample = factual.sample(max_count*3)\n",
        "for idx, row in df_sample.iterrows():\n",
        "  if True:\n",
        "    colss = factual.drop('label', axis = 1).columns\n",
        "    fcc =  factual[factual.index==idx].astype(float)\n",
        "    cf = rcmethod.get_counterfactuals(fcc)\n",
        "    cf_np = cf[colss].values.reshape(28,28).astype(float)\n",
        "    f_np = factual.loc[idx].drop('label').values.reshape(28,28).astype(float)\n",
        "\n",
        "    cf_rgb = np.zeros((f_np.shape[0],f_np.shape[1],3))\n",
        "    cf_rgb_fm = np.zeros((f_np.shape[0],f_np.shape[1],3))\n",
        "\n",
        "    for i in range(3):\n",
        "      cf_rgb[:,:,i] = f_np \n",
        "\n",
        "    for i in range(cf_rgb.shape[0]):\n",
        "      for j in range(cf_rgb.shape[1]):\n",
        "        if f_np[i,j] > cf_np[i,j]:\n",
        "          cf_rgb[i,j,0] = 255\n",
        "          cf_rgb[i,j,1] = 0\n",
        "          cf_rgb[i,j,2] = 0\n",
        "\n",
        "        elif f_np[i,j] < cf_np[i,j]:\n",
        "          cf_rgb[i,j,0] = 0\n",
        "          cf_rgb[i,j,1] = 255\n",
        "          cf_rgb[i,j,2] = 0\n",
        "\n",
        "\n",
        "    axs[0, count].set_title(str(idx))\n",
        "    axs[0, count].imshow(f_np, cmap='gray')\n",
        "    axs[1, count].imshow(cf_np, cmap='gray')\n",
        "    axs[2, count].imshow(cf_rgb, )\n",
        "    count += 1\n",
        "    if count == max_count:\n",
        "      break\n",
        "  else:\n",
        "    print(\"exception\")"
      ],
      "metadata": {
        "id": "jiD6krXujt2E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}