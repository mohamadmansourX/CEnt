{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Carla_Wrapper.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LeafNode ---> merge_conditions\n",
        "\n",
        "if both has '<=' we sould choose the min value but its not working unless we choose max??? same to '>'"
      ],
      "metadata": {
        "id": "XDzs2eomsMFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/carla-recourse/CARLA.git\n",
        "%cd CARLA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCeHsIfWeGFH",
        "outputId": "cee7e033-639f-4407-8496-5008e9f21be8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CARLA'...\n",
            "remote: Enumerating objects: 2252, done.\u001b[K\n",
            "remote: Counting objects: 100% (1054/1054), done.\u001b[K\n",
            "remote: Compressing objects: 100% (605/605), done.\u001b[K\n",
            "remote: Total 2252 (delta 698), reused 531 (delta 449), pack-reused 1198\u001b[K\n",
            "Receiving objects: 100% (2252/2252), 1.81 MiB | 18.34 MiB/s, done.\n",
            "Resolving deltas: 100% (1294/1294), done.\n",
            "/content/CARLA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "echo \"\"\"pip install -U pip setuptools wheel\n",
        "pip install -e .\n",
        "pip install -r requirements-dev.txt\n",
        "pre-commit install\n",
        "pip install -r requirements-dev.txt\n",
        "\"\"\" > mm_bash_setup.sh"
      ],
      "metadata": {
        "id": "B6XGsT61XmOx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash mm_bash_setup.sh"
      ],
      "metadata": {
        "id": "KRyWxBcgX_wM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0672f137-2c34-4575-b7ad-5de54efa1472"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.1.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 24.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-62.3.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 54.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed pip-22.1.2 setuptools-62.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/CARLA\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lime==0.2.0.1\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mip==1.12.0\n",
            "  Downloading mip-1.12.0-py3-none-any.whl (47.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.19.4\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /packages/a5/bb/87d668b353848b93baab0a64cddf6408c40717f099539668c3d26fe39f7e/numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.1.4\n",
            "  Downloading pandas-1.1.4-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting recourse==1.0.0\n",
            "  Downloading recourse-1.0.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==1.14.0\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.3/109.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.7.0\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.7/776.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.8.1\n",
            "  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dice-ml==0.5\n",
            "  Downloading dice_ml-0.5-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.0/224.0 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from carla-recourse==0.0.4) (5.5.0)\n",
            "Collecting keras==2.3.0\n",
            "  Downloading Keras-2.3.0-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.6/377.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost==1.4.2\n",
            "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting causalgraphicalmodels==0.0.4\n",
            "  Downloading causalgraphicalmodels-0.0.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from causalgraphicalmodels==0.0.4->carla-recourse==0.0.4) (2.6.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from causalgraphicalmodels==0.0.4->carla-recourse==0.0.4) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->carla-recourse==0.0.4) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0->carla-recourse==0.0.4) (3.13)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0->carla-recourse==0.0.4) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.0->carla-recourse==0.0.4) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.1->carla-recourse==0.0.4) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.1->carla-recourse==0.0.4) (4.64.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.1->carla-recourse==0.0.4) (0.18.3)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from mip==1.12.0->carla-recourse==0.0.4) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.4->carla-recourse==0.0.4) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.4->carla-recourse==0.0.4) (2.8.2)\n",
            "Requirement already satisfied: jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from recourse==1.0.0->carla-recourse==0.0.4) (2.11.3)\n",
            "Collecting pytest>=4.3.0\n",
            "  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.0/297.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from recourse==1.0.0->carla-recourse==0.0.4) (0.11.2)\n",
            "Collecting ipython\n",
            "  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from recourse==1.0.0->carla-recourse==0.0.4) (5.1.1)\n",
            "Collecting cplex>=12.8\n",
            "  Downloading cplex-22.1.0.0-cp37-cp37m-manylinux1_x86_64.whl (43.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prettytable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from recourse==1.0.0->carla-recourse==0.0.4) (3.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->carla-recourse==0.0.4) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->carla-recourse==0.0.4) (3.1.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.5/488.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->carla-recourse==0.0.4) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->carla-recourse==0.0.4) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->carla-recourse==0.0.4) (1.0.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->carla-recourse==0.0.4) (1.46.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->carla-recourse==0.0.4) (0.5.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->carla-recourse==0.0.4) (0.37.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->carla-recourse==0.0.4) (1.14.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->carla-recourse==0.0.4) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0->carla-recourse==0.0.4) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->carla-recourse==0.0.4) (4.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->carla-recourse==0.0.4) (0.16.0)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1->carla-recourse==0.0.4) (7.1.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->carla-recourse==0.0.4) (0.7.5)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython->carla-recourse==0.0.4) (0.1.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->carla-recourse==0.0.4) (2.6.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython->carla-recourse==0.0.4) (4.8.0)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.29-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.5/381.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->carla-recourse==0.0.4) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython->carla-recourse==0.0.4) (0.18.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->carla-recourse==0.0.4) (62.3.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->carla-recourse==0.0.4) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython->carla-recourse==0.0.4) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10.1->recourse==1.0.0->carla-recourse==0.0.4) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.2.0.1->carla-recourse==0.0.4) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.2.0.1->carla-recourse==0.0.4) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.2.0.1->carla-recourse==0.0.4) (1.4.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython->carla-recourse==0.0.4) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable>=0.7.2->recourse==1.0.0->carla-recourse==0.0.4) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable>=0.7.2->recourse==1.0.0->carla-recourse==0.0.4) (4.11.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=4.3.0->recourse==1.0.0->carla-recourse==0.0.4) (21.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest>=4.3.0->recourse==1.0.0->carla-recourse==0.0.4) (21.3)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest>=4.3.0->recourse==1.0.0->carla-recourse==0.0.4) (1.11.0)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest>=4.3.0->recourse==1.0.0->carla-recourse==0.0.4) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=4.3.0->recourse==1.0.0->carla-recourse==0.0.4) (2.0.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.1->carla-recourse==0.0.4) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.1->carla-recourse==0.0.4) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.1->carla-recourse==0.0.4) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->carla-recourse==0.0.4) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->carla-recourse==0.0.4) (1.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->mip==1.12.0->carla-recourse==0.0.4) (2.21)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable>=0.7.2->recourse==1.0.0->carla-recourse==0.0.4) (3.8.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283839 sha256=bdf3ee33278bb4b4a689e2642cd91addd885179ebbe96088e01bad13c3377f61\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/cb/e5/ac701e12d365a08917bf4c6171c0961bc880a8181359c66aa7\n",
            "Successfully built lime\n",
            "Installing collected packages: tensorflow-estimator, dataclasses, cplex, prompt-toolkit, numpy, torch, pluggy, pandas, mip, ipython, h5py, xgboost, torchvision, tensorboard, scikit-learn, pytest, keras-applications, causalgraphicalmodels, tensorflow, recourse, lime, keras, dice-ml, carla-recourse\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Running setup.py develop for carla-recourse\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.4 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed carla-recourse causalgraphicalmodels-0.0.4 cplex-22.1.0.0 dataclasses-0.6 dice-ml-0.5 h5py-2.10.0 ipython-7.34.0 keras-2.3.0 keras-applications-1.0.8 lime-0.2.0.1 mip-1.12.0 numpy-1.19.4 pandas-1.1.4 pluggy-1.0.0 prompt-toolkit-3.0.29 pytest-7.1.2 recourse-1.0.0 scikit-learn-0.23.2 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 torch-1.7.0 torchvision-0.8.1 xgboost-1.4.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pre-commit==2.9.2\n",
            "  Downloading pre_commit-2.9.2-py2.py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.8/184.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest==6.1.2\n",
            "  Downloading pytest-6.1.2-py3-none-any.whl (272 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.4/272.4 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx==4.0.2\n",
            "  Downloading Sphinx-4.0.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx-rtd-theme==0.5.2\n",
            "  Downloading sphinx_rtd_theme-0.5.2-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx_autodoc_typehints==1.12.0\n",
            "  Downloading sphinx_autodoc_typehints-1.12.0-py3-none-any.whl (9.4 kB)\n",
            "Collecting numpydoc==1.1.0\n",
            "  Downloading numpydoc-1.1.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imageio==2.9.0\n",
            "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython==7.22.0\n",
            "  Downloading ipython-7.22.0-py3-none-any.whl (785 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.0/785.0 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2==2.11.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 9)) (2.11.3)\n",
            "Collecting networkx==2.5.1\n",
            "  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.6.2\n",
            "  Downloading scipy-1.6.2-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.4/27.4 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markupsafe==2.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 12)) (2.0.1)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading identify-2.5.1-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (4.11.3)\n",
            "Collecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest==6.1.2->-r requirements-dev.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest==6.1.2->-r requirements-dev.txt (line 2)) (1.11.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest==6.1.2->-r requirements-dev.txt (line 2)) (21.4.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest==6.1.2->-r requirements-dev.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (62.3.2)\n",
            "Collecting sphinxcontrib-htmlhelp\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.5/100.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2.10.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (0.7.12)\n",
            "Requirement already satisfied: docutils<0.18,>=0.14 in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (0.17.1)\n",
            "Collecting sphinxcontrib-jsmath\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting sphinxcontrib-devhelp\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-applehelp\n",
            "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2.6.1)\n",
            "Collecting sphinxcontrib-qthelp\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (1.1.5)\n",
            "Collecting docutils<0.18,>=0.14\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.9.0->-r requirements-dev.txt (line 7)) (1.19.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.9.0->-r requirements-dev.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (0.18.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (0.7.5)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (3.0.29)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (5.1.1)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel>=1.3->sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2022.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython==7.22.0->-r requirements-dev.txt (line 8)) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython==7.22.0->-r requirements-dev.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.22.0->-r requirements-dev.txt (line 8)) (0.2.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx==4.0.2->-r requirements-dev.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx==4.0.2->-r requirements-dev.txt (line 3)) (1.24.3)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (1.15.0)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m461.2/461.2 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytest==6.1.2->-r requirements-dev.txt (line 2)) (3.0.9)\n",
            "Installing collected packages: nodeenv, distlib, toml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, scipy, pyyaml, platformdirs, networkx, imageio, identify, docutils, cfgv, virtualenv, sphinx, pluggy, ipython, sphinx-rtd-theme, sphinx_autodoc_typehints, pytest, pre-commit, numpydoc\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 2.6.3\n",
            "    Uninstalling networkx-2.6.3:\n",
            "      Successfully uninstalled networkx-2.6.3\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 1.8.6\n",
            "    Uninstalling Sphinx-1.8.6:\n",
            "      Successfully uninstalled Sphinx-1.8.6\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 1.0.0\n",
            "    Uninstalling pluggy-1.0.0:\n",
            "      Successfully uninstalled pluggy-1.0.0\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.1.2\n",
            "    Uninstalling pytest-7.1.2:\n",
            "      Successfully uninstalled pytest-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.4 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.22.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cfgv-3.3.1 distlib-0.3.4 docutils-0.16 identify-2.5.1 imageio-2.9.0 ipython-7.22.0 networkx-2.5.1 nodeenv-1.6.0 numpydoc-1.1.0 platformdirs-2.5.2 pluggy-0.13.1 pre-commit-2.9.2 pytest-6.1.2 pyyaml-6.0 scipy-1.6.2 sphinx-4.0.2 sphinx-rtd-theme-0.5.2 sphinx_autodoc_typehints-1.12.0 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 toml-0.10.2 virtualenv-20.14.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mpre-commit installed at .git/hooks/pre-commit\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pre-commit==2.9.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 1)) (2.9.2)\n",
            "Requirement already satisfied: pytest==6.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 2)) (6.1.2)\n",
            "Requirement already satisfied: sphinx==4.0.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 3)) (4.0.2)\n",
            "Requirement already satisfied: sphinx-rtd-theme==0.5.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 4)) (0.5.2)\n",
            "Requirement already satisfied: sphinx_autodoc_typehints==1.12.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 5)) (1.12.0)\n",
            "Requirement already satisfied: numpydoc==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: imageio==2.9.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 7)) (2.9.0)\n",
            "Requirement already satisfied: ipython==7.22.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 8)) (7.22.0)\n",
            "Requirement already satisfied: jinja2==2.11.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 9)) (2.11.3)\n",
            "Requirement already satisfied: networkx==2.5.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 10)) (2.5.1)\n",
            "Requirement already satisfied: scipy==1.6.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 11)) (1.6.2)\n",
            "Requirement already satisfied: markupsafe==2.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements-dev.txt (line 12)) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (4.11.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (0.10.2)\n",
            "Requirement already satisfied: virtualenv>=20.0.8 in /usr/local/lib/python3.7/dist-packages (from pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (20.14.1)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (2.5.1)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (3.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest==6.1.2->-r requirements-dev.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest==6.1.2->-r requirements-dev.txt (line 2)) (1.11.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest==6.1.2->-r requirements-dev.txt (line 2)) (21.4.0)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest==6.1.2->-r requirements-dev.txt (line 2)) (0.13.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest==6.1.2->-r requirements-dev.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (1.0.2)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2.2.0)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (0.7.12)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (1.1.5)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: docutils<0.18,>=0.14 in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (0.16)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (1.0.2)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (62.3.2)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (1.0.3)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.7/dist-packages (from sphinx==4.0.2->-r requirements-dev.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.9.0->-r requirements-dev.txt (line 7)) (1.19.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.9.0->-r requirements-dev.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (3.0.29)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (0.18.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (5.1.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.22.0->-r requirements-dev.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel>=1.3->sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2022.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython==7.22.0->-r requirements-dev.txt (line 8)) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython==7.22.0->-r requirements-dev.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.22.0->-r requirements-dev.txt (line 8)) (0.2.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx==4.0.2->-r requirements-dev.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx==4.0.2->-r requirements-dev.txt (line 3)) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx==4.0.2->-r requirements-dev.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (2.5.2)\n",
            "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (3.7.0)\n",
            "Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit==2.9.2->-r requirements-dev.txt (line 1)) (0.3.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytest==6.1.2->-r requirements-dev.txt (line 2)) (3.0.9)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall pandas -y\n",
        "!pip install pandas==1.3.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhnmWheUdCOu",
        "outputId": "87687d1b-469f-46ee-a165-5f04c9468337"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pandas 1.1.4\n",
            "Uninstalling pandas-1.1.4:\n",
            "  Successfully uninstalled pandas-1.1.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas==1.3.5\n",
            "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.5) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.5) (1.19.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.5) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.5) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.4 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.3.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing the Model"
      ],
      "metadata": {
        "id": "FeLj5teOseo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CARLA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBfbSJQhYfZJ",
        "outputId": "2464fa52-d5f8-4570-8a5d-26602a0b7514"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CARLA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Tuple, Union\n",
        "import pandas as pd\n",
        "from carla import RecourseMethod\n",
        "from carla.data.api import data, Data\n",
        "from carla.models.api import MLModel\n",
        "from carla.recourse_methods.autoencoder import (\n",
        "    VAEDataset,\n",
        "    VariationalAutoencoder,\n",
        "    train_variational_autoencoder,\n",
        ")\n",
        "from carla.recourse_methods.processing import (\n",
        "    check_counterfactuals,\n",
        "    merge_default_parameters,\n",
        "    reconstruct_encoding_constraints,\n",
        ")\n",
        "# For Descision Tree implementation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import numpy as np\n",
        "from carla import Benchmark\n",
        "from carla.recourse_methods import Dice, Face\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "metadata": {
        "id": "fXLi06EAPbyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b1ff18-5f70-4d9d-bb1d-04693d1775d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "def load_setup() -> Dict:\n",
        "    with open(\"experimental_setup.yaml\", \"r\") as f:\n",
        "        setup_catalog = yaml.safe_load(f)\n",
        "    return setup_catalog[\"recourse_methods\"]\n",
        "setup = load_setup()"
      ],
      "metadata": {
        "id": "JR6mT9Y8Hi7R"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Tree Leaf utils\n",
        "\"\"\"\n",
        "\n",
        "# !git clone https://github.com/carla-recourse/CARLA.git\n",
        "\n",
        "\n",
        "import enum\n",
        "from typing import Dict, List, Tuple, Union\n",
        "import pandas as pd\n",
        "from carla import RecourseMethod\n",
        "from carla.data.api import data, Data\n",
        "from carla.models.api import MLModel\n",
        "from carla.recourse_methods.autoencoder import (\n",
        "    VAEDataset,\n",
        "    VariationalAutoencoder,\n",
        "    train_variational_autoencoder,\n",
        ")\n",
        "from carla.recourse_methods.processing import (\n",
        "    check_counterfactuals,\n",
        "    merge_default_parameters,\n",
        "    reconstruct_encoding_constraints,\n",
        ")\n",
        "# For Descision Tree implementation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import numpy as np\n",
        "from carla import Benchmark\n",
        "from carla.recourse_methods import Dice, Face\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import deepcopy\n",
        "class LeafNode:\n",
        "    def __init__(self, conditions, label, weight):\n",
        "        # Conditions is a list of tuples from the root node to the leaf node\n",
        "        self.conditions = deepcopy(conditions)\n",
        "        # Label is the label of the leaf node\n",
        "        self.label = label\n",
        "        # Wieght Either entropy or gini\n",
        "        self.weight = weight\n",
        "        # Duplicate conditions\n",
        "        self.duplicate_conditions = []\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"\n",
        "        Print the leaf node with conditions and label\n",
        "        \"\"\"\n",
        "        return \"LeafNode(label={}, weight={}, conditions={})\".format(self.label, self.weight, self.conditions)\n",
        "\n",
        "    def compare_node(self, other): #TODO misleading name\n",
        "        \"\"\"\n",
        "        Get the distance between two leaf nodes by returning a set of conditions as follows:\n",
        "        1. Initialize conditions as other conditions\n",
        "        2. Remove conditions that are exactly the same with self\n",
        "        3. Return the remaining conditions\n",
        "\n",
        "        # TODO common feature\n",
        "        \"\"\"\n",
        "        # Initialize conditions as other conditions\n",
        "        conditions = other.conditions\n",
        "        # Remove conditions that are common with self\n",
        "        for condition in self.conditions:\n",
        "            conditions = [c for c in conditions if c != condition]\n",
        "        # Return the remaining conditions\n",
        "        return conditions\n",
        "\n",
        "    def merge_conditions(self):\n",
        "        \"\"\"\n",
        "        If there are two conditions with the same feature and threshold_sign, merge them into one condition\n",
        "        \"\"\"\n",
        "        # Initialize conditions as other conditions\n",
        "        # \n",
        "        conditions = self.conditions\n",
        "        # indexes to be dropped\n",
        "        indexes = []\n",
        "        # Search for conditions with the same feature and threshold_sign\n",
        "        for i in range(len(conditions)):\n",
        "            # if i in the indexes to be dropped, skip\n",
        "            if i in indexes:\n",
        "                continue\n",
        "            for j in range(i + 1, len(conditions)):\n",
        "                # if j in the indexes to be dropped, skip\n",
        "                if j in indexes:\n",
        "                    continue\n",
        "                if conditions[i].feature == conditions[j].feature:\n",
        "                    if conditions[i].threshold_sign == conditions[j].threshold_sign:\n",
        "                        # Merge the two conditions\n",
        "                        if conditions[i].threshold_sign == '<=':\n",
        "                            conditions[i].threshold = min(conditions[i].threshold, conditions[j].threshold)\n",
        "                        else:\n",
        "                            conditions[i].threshold = max(conditions[i].threshold, conditions[j].threshold)\n",
        "                        # Add index to drop\n",
        "                        indexes.append(j)\n",
        "                    else:\n",
        "                        # Add it to duplicate conditions\n",
        "                        if conditions[j].feature not in self.duplicate_conditions:\n",
        "                            self.duplicate_conditions.append(conditions[j].feature)\n",
        "        # Drop indexes from conditions\n",
        "        conditions = [c for i, c in enumerate(conditions) if i not in indexes]\n",
        "        self.conditions = conditions\n",
        "        self.duplicate_conditions = list(set(self.duplicate_conditions))\n",
        "\n",
        "    def check_point(self, point):\n",
        "        \"\"\"\n",
        "        Check if the point satisfies the conditions of the leaf node\n",
        "        \"\"\"\n",
        "        # Check if the point satisfies the conditions of the leaf node\n",
        "        for condition in self.conditions:\n",
        "            if not condition.check_point(point):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def generate_point(self, point, data_catalog = None, sigma =0.5, gamma = 0):\n",
        "        \"\"\"\n",
        "        Generate a point from a point\n",
        "        \"\"\"\n",
        "        # loop through the duplicate conditions\n",
        "        for feature in self.duplicate_conditions:\n",
        "            # get the two conditions with that feature\n",
        "            conditions = [c for c in self.conditions if c.feature == feature]\n",
        "            # data_catalog contains {'categorical':[],'continuous':[],'imutable':[], 'continuous_stats':[]}\n",
        "            if feature in data_catalog['categorical']:\n",
        "                # Assert that there shouldn't be duplicate conditions for a binary feature (categorical here are binaries)\n",
        "                assert False, \"There shouldn't be duplicate conditions for a binary feature\"\n",
        "                #TODO (general user he can't solve it)\n",
        "                # Thrsh can be continous, then generate a random point between threshold and round the result\n",
        "            elif feature in data_catalog['continuous']:\n",
        "                # using the continuous_stats get the std and mean\n",
        "                std = data_catalog['continuous_stats'][feature]['std']\n",
        "                mean = data_catalog['continuous_stats'][feature]['mean']\n",
        "                minn = data_catalog['continuous_stats'][feature]['min']\n",
        "                maxx = data_catalog['continuous_stats'][feature]['max']\n",
        "                # Using the mean, std, min and max create a bias value\n",
        "                # bias values is std/10 * (max - min)\n",
        "                bias = std / sigma # TOCHECK LATER\n",
        "                bias = min(bias, abs(conditions[0].threshold - conditions[1].threshold))\n",
        "                # Min\n",
        "                if gamma == 0:\n",
        "                    min_bias = 0\n",
        "                else:\n",
        "                    min_bias = std / gamma\n",
        "                # Generate a random value between the two thresholds\n",
        "                bias = random.uniform(min_bias, bias)\n",
        "                # Add the bias to the threshold\n",
        "                if conditions[0].threshold_sign == '<=':\n",
        "                    point[feature] = conditions[0].threshold + bias\n",
        "                else:\n",
        "                    point[feature] = conditions[1].threshold + bias\n",
        "        for condition in self.conditions:\n",
        "            if condition.feature not in self.duplicate_conditions:\n",
        "                if condition.feature in data_catalog['categorical']:\n",
        "                    # Simply flip the value\n",
        "                    # Round the threshold\n",
        "                    point[condition.feature] = not point[condition.feature]\n",
        "                else: # condition.feature in data_catalog['continuous']:\n",
        "                    std = data_catalog['continuous_stats'][condition.feature]['std']\n",
        "                    mean = data_catalog['continuous_stats'][condition.feature]['mean']\n",
        "                    minn = data_catalog['continuous_stats'][condition.feature]['min']\n",
        "                    maxx = data_catalog['continuous_stats'][condition.feature]['max']\n",
        "                    bias = std / sigma\n",
        "                    # Min\n",
        "                    if gamma == 0:\n",
        "                        min_bias = 0\n",
        "                    else:\n",
        "                        min_bias = std / gamma\n",
        "                    # Generate a random value between the two thresholds\n",
        "                    bias = random.uniform(min_bias, bias)\n",
        "                    if condition.threshold_sign == '<=':\n",
        "                        point[condition.feature] = condition.threshold + bias\n",
        "                    else:\n",
        "                        point[condition.feature] = condition.threshold - bias\n",
        "        return point\n",
        "\n",
        "\n",
        "class Condition:\n",
        "    def __init__(self, feature, threshold, threshold_sign):\n",
        "        # Feature is the feature name\n",
        "        self.feature = feature\n",
        "        # Value is the value of the feature\n",
        "        self.threshold = threshold\n",
        "        # <= or > since they are the only two threshold_sign in Decision Tree\n",
        "        self.threshold_sign = threshold_sign\n",
        "    def __repr__(self):\n",
        "        return f'{self.feature} {self.threshold_sign} {self.threshold}'\n",
        "    def check_point(self, point):\n",
        "        \"\"\"\n",
        "        Check if the point satisfies the condition\n",
        "        \"\"\"\n",
        "        # Check if the point satisfies the condition\n",
        "        if self.threshold_sign == '<=':\n",
        "            return point[self.feature] <= self.threshold\n",
        "        else:\n",
        "            return point[self.feature] > self.threshold\n",
        "\n",
        "\n",
        "class TreeLeafs:\n",
        "    def __init__(self, tree, feature_input_order):\n",
        "        self.tree = tree\n",
        "        self.feature_input_order = feature_input_order\n",
        "        self.leafs_nodes = []\n",
        "        self.get_leaf_nodes(tree)\n",
        "        for leaf in self.leafs_nodes:\n",
        "            leaf.merge_conditions()\n",
        "\n",
        "    def get_leaf_nodes(self, tree, node_id=0, conditions=[]):\n",
        "        \"\"\"\n",
        "        This will be a recursion function that will append to leaf_nodes list, their labels and set of conditions\n",
        "        If the node is a leaf node, then it will append a LeafNode object to leaf_nodes\n",
        "        If the node is not a leaf node, then it will return while adding the conditions of the left and right child to the list\n",
        "        \"\"\"\n",
        "        # If the node is a leaf node\n",
        "        if tree.children_left[node_id] == -1 and tree.children_right[node_id] == -1:\n",
        "            # Append the leaf node to the list\n",
        "            self.leafs_nodes.append(LeafNode(conditions, np.argmax(tree.value[node_id]), tree.impurity[node_id]))\n",
        "        # If the node is not a leaf node\n",
        "        else:\n",
        "            # Need to get the feature of the node\n",
        "            feature = self.feature_input_order[tree.feature[node_id]]\n",
        "            # Need to get the threshold of the node\n",
        "            threshold = tree.threshold[node_id]\n",
        "            # For right child if exists, threshold_sign is >\n",
        "            if tree.children_right[node_id] != -1:\n",
        "                conditions_right = conditions.copy()\n",
        "                # Append the condition to the list\n",
        "                conditions_right.append(Condition(feature, threshold, '>'))\n",
        "                # Get the right child\n",
        "                self.get_leaf_nodes(tree, tree.children_right[node_id], conditions_right)\n",
        "            # For left child if exists, threshold_sign is <=\n",
        "            if tree.children_left[node_id] != -1:\n",
        "                conditions_left = conditions.copy()\n",
        "                # Append the condition to the list\n",
        "                conditions_left.append(Condition(feature, threshold, '<='))\n",
        "                # Get the left child\n",
        "                self.get_leaf_nodes(tree, tree.children_left[node_id], conditions_left)\n"
      ],
      "metadata": {
        "id": "3pz8zIRCkF9U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "\n",
        "class TreeBasedContrastiveExplanation(RecourseMethod):\n",
        "    '''\n",
        "    Decision Tree Based contrastive explanations\n",
        "    '''\n",
        "    _DEFAULT_HYPERPARAMS = {\n",
        "      \"data_name\": None,\n",
        "      \"n_search_samples\": 300,\n",
        "      \"p_norm\": 1,\n",
        "      \"step\": 0.1,\n",
        "      \"max_iter\": 1000,\n",
        "      \"clamp\": True,\n",
        "      \"target_class\": [0, 1],\n",
        "      \"binary_cat_features\": True,\n",
        "      \"vae_params\": {\n",
        "          \"layers\": None,\n",
        "          \"train\": True,\n",
        "          \"lambda_reg\": 1e-6,\n",
        "          \"epochs\": 5,\n",
        "          \"lr\": 1e-3,\n",
        "          \"batch_size\": 32,\n",
        "      },\n",
        "      \"tree_params\": {\n",
        "          \"min_entries_per_label\": 1000,\n",
        "          \"grid_search_jobs\": -1,\n",
        "          \"min_weight_gini\": 100, # set to 0.5 since here both class have same prob\n",
        "          \"max_search\": 500,\n",
        "          \"grid_search\": {\n",
        "                \"splitter\": [\"best\"],\n",
        "                \"criterion\": [\"gini\"],\n",
        "                \"max_depth\": [6],\n",
        "                \"min_samples_split\": [2],\n",
        "                \"min_samples_leaf\": [1],\n",
        "                \"max_features\": [None] #Note changing this will result in removing features that we might want to keep\n",
        "          }\n",
        "      }\n",
        "\n",
        "    }\n",
        "\n",
        "    def __init__(self, dataset:Data, mlmodel: MLModel, hyperparams: Dict, data_catalog: Dict):\n",
        "        super().__init__(mlmodel)\n",
        "        # Construct catalog\n",
        "        self.data_catalog = data_catalog\n",
        "        # Construct mlmodel\n",
        "        self.mlmodel = mlmodel\n",
        "        # Construct the hyperparameters\n",
        "        self.hyperparams = merge_default_parameters(hyperparams, self._DEFAULT_HYPERPARAMS)\n",
        "        # Construct the VAE\n",
        "        self.vae = TEMP_VAE\n",
        "        # self.vae = self.load_vae(dataset, self.hyperparams[\"vae_params\"], mlmodel, mlmodel.data.name)\n",
        "        # Construct the dataframe with encodings\n",
        "        self.dataset = dataset.df\n",
        "        self.dataset['VAE_ENCODED'] = self.get_encodeings(self.dataset)\n",
        "        \n",
        "\n",
        "\n",
        "    def load_vae(self, data: pd.DataFrame, vae_params: Dict, mlmodel: MLModel, data_name: str) -> VariationalAutoencoder:\n",
        "        '''\n",
        "        Load and train the VAE if needed\n",
        "        '''\n",
        "        generative_model = VariationalAutoencoder(data_name, vae_params['layers'])\n",
        "        # if train is True, train the VAE\n",
        "        if vae_params['train']:\n",
        "            generative_model = train_variational_autoencoder(\n",
        "                generative_model,\n",
        "                data,\n",
        "                mlmodel.feature_input_order,\n",
        "                lambda_reg=vae_params[\"lambda_reg\"],\n",
        "                epochs=vae_params[\"epochs\"],\n",
        "                lr=vae_params[\"lr\"],\n",
        "                batch_size=vae_params[\"batch_size\"],\n",
        "            )\n",
        "        else:\n",
        "            try:\n",
        "                # CHeck if the generative_model can load our data\n",
        "                generative_model.load(data.shape[1] - 1)\n",
        "            except FileNotFoundError as exc:\n",
        "                raise FileNotFoundError(\n",
        "                    \"Loading of Autoencoder failed. {}\".format(str(exc))\n",
        "                )\n",
        "        \n",
        "        return generative_model\n",
        "    \n",
        "    def get_counterfactuals(self, factuals: pd.DataFrame):\n",
        "        '''\n",
        "        this property is responsible to generate and output\n",
        "        encoded and scaled counterfactual examples\n",
        "        as pandas DataFrames\n",
        "        '''\n",
        "        # Get the encoded features of factuals\n",
        "        factuals[\"VAE_ENCODED\"] = self.get_encodeings(factuals)\n",
        "        # Get the counterfactuals\n",
        "        # find counterfactuals\n",
        "        counter_factuals = factuals.apply(\n",
        "            lambda x: self.tree_based_search(x), axis=1, raw=False\n",
        "        )\n",
        "        # counter_factuals = [self.tree_based_search(row) for __,row in factuals.iterrows()]\n",
        "        # Concatenate the counterfactuals to a single dataframe\n",
        "        # counter_factuals is a list of rows\n",
        "        self.counter_factuals = counter_factuals\n",
        "        #counter_factuals = check_counterfactuals(self._mlmodel, counter_factuals)\n",
        "        # Return the counterfactuals\n",
        "        return counter_factuals[self._mlmodel.feature_input_order]\n",
        "\n",
        "    def get_encodeings(self, data: pd.DataFrame):\n",
        "        '''\n",
        "        This method is responsible to append the encoded features\n",
        "        to the dataframe\n",
        "        '''\n",
        "        # Fix DataFrame to be able to feed to the VAE\n",
        "        input_data = data.copy()[self._mlmodel.feature_input_order]\n",
        "        input_data = torch.FloatTensor(input_data.values)\n",
        "        # Get the encoded features\n",
        "        encoded_values = self.vae.encode(input_data)[0].detach().numpy()\n",
        "        encoded_values = [i for i in encoded_values]\n",
        "        return encoded_values\n",
        "\n",
        "    def distance_get(self, x,factuals):\n",
        "        return np.square((x - factuals)).sum()\n",
        "\n",
        "    def get_nearest_neighbors_thershold(self, copy_data, label_threshold):\n",
        "        '''\n",
        "        This method is responsible to get the nearest neighbors of a given threshold\n",
        "        using the VAE and minimum threshold per label\n",
        "        '''\n",
        "        # Find the index of the 100th instance of each class\n",
        "        id_100th_class_0 = copy_data[copy_data[self._mlmodel.data.target] == 0].index[label_threshold-1]\n",
        "        id_100th_class_1 = copy_data[copy_data[self._mlmodel.data.target] == 1].index[label_threshold-1]\n",
        "        # Get the maximum id\n",
        "        max_id = max(id_100th_class_0, id_100th_class_1)\n",
        "        # Return the nearest neighbors of the 100th instance of each class\n",
        "        return copy_data.head(max_id)\n",
        "    \n",
        "    def decision_tree(self, nearest_neighbors):\n",
        "        '''\n",
        "        This method is responsible to create a decision tree\n",
        "        using the nearest neighbors of the 100th instance of each class\n",
        "        '''\n",
        "        target_values = nearest_neighbors[self._mlmodel.data.target]\n",
        "        train_features = nearest_neighbors[self._mlmodel.feature_input_order]\n",
        "        # Create the decision tree\n",
        "        clf = DecisionTreeClassifier(random_state=0 , max_depth=self.hyperparams[\"tree_params\"]['grid_search'][\"max_depth\"][0], \n",
        "                                    min_samples_split=self.hyperparams[\"tree_params\"]['grid_search'][\"min_samples_split\"][0], \n",
        "                                    min_samples_leaf=self.hyperparams[\"tree_params\"]['grid_search'][\"min_samples_leaf\"][0], \n",
        "                                    max_features=self.hyperparams[\"tree_params\"]['grid_search'][\"max_features\"][0])\n",
        "        # Define the grid search\n",
        "        #grid_search = GridSearchCV(clf, self.hyperparams[\"tree_params\"][\"grid_search\"], cv=5, verbose=0, refit=True, n_jobs=self.hyperparams[\"tree_params\"][\"grid_search_jobs\"])\n",
        "        # Fit the grid search evaluate on X_test and y_test then refit best model on the whole dataset\n",
        "        #grid_search.fit(train_features, target_values)\n",
        "        # Return the best model\n",
        "        #return grid_search.best_estimator_\n",
        "        clf.fit(train_features, target_values)\n",
        "        return clf\n",
        "\n",
        "\n",
        "    def tree_based_search(self, factual):\n",
        "        '''\n",
        "        This method is responsible to get the counterfactual of a given targeted_encoding\n",
        "        '''\n",
        "        copy_data = self.dataset.copy()\n",
        "        # Get distances from data to this encoding\n",
        "        copy_data[\"distance\"] = copy_data[\"VAE_ENCODED\"].apply(lambda x: self.distance_get(x, factual[\"VAE_ENCODED\"]))\n",
        "        # Sort the dataframe by distance\n",
        "        copy_data = copy_data.sort_values(by=\"distance\")\n",
        "        # Reset the index\n",
        "        copy_data = copy_data.reset_index(drop=True)\n",
        "        # Get the nearest neighbors of the targeted encoding\n",
        "        nearest_neighbors = self.get_nearest_neighbors_thershold(copy_data, label_threshold=self.hyperparams[\"tree_params\"][\"min_entries_per_label\"])\n",
        "        # Get the tree\n",
        "        tree = self.decision_tree(nearest_neighbors)\n",
        "        self.mtree = tree\n",
        "        # Get the leaf nodes\n",
        "        leaf_nodes = TreeLeafs(tree.tree_, self._mlmodel.feature_input_order).leafs_nodes.copy()\n",
        "        # leaf_nodes is list of classes LeafNode\n",
        "        # Get the leaf node where the targeted encoding is located\n",
        "        leaf_node_n_i = -1\n",
        "        for leaf_i in range(len(leaf_nodes)):\n",
        "            if leaf_nodes[leaf_i].check_point(factual):\n",
        "                leaf_node_n_i = leaf_i\n",
        "                break\n",
        "        self.mleaf_node_n_i = leaf_node_n_i\n",
        "        self.mfactual = factual\n",
        "        # assert if the leaf node is not found\n",
        "        assert leaf_node_n_i != -1, \"Leaf node not found\"\n",
        "        # For now change leafnode label to the item label\n",
        "        # #assert if leaf_node_n.label is not the same as the factual label\n",
        "        # assert leaf_node_n.label == factual[self._mlmodel.data.target], \"Leaf node label {} is not the same as the factual label {}\".format(leaf_node_n.label, factual[self._mlmodel.data.target])\n",
        "        if leaf_nodes[leaf_node_n_i].label != factual[self._mlmodel.data.target]:\n",
        "          #print(\"Leaf Node {} flipped node label {} to match the factual entry {}\".format(leaf_node_n_i,\n",
        "          #                                                                          leaf_nodes[leaf_node_n_i].label,\n",
        "          #                                                                          factual[self._mlmodel.data.target]))\n",
        "          leaf_nodes[leaf_node_n_i].label = factual[self._mlmodel.data.target]\n",
        "        leaf_node_n = leaf_nodes[leaf_node_n_i]\n",
        "        # Get all leafnodes with label!= leaf_node_n.label and Sort leaf nodes by distance\n",
        "        leaf_nodes_with_label = [leaf_n for leaf_n in leaf_nodes if leaf_n.label != leaf_node_n.label]\n",
        "        # Check if leaf_nodes_with_label is empty\n",
        "        if len(leaf_nodes_with_label) == 0:\n",
        "            print(\"No leaf node with label {}\".format(leaf_node_n.label))\n",
        "            factual_ret = factual\n",
        "            factual_ret[self._mlmodel.feature_input_order] = np.nan\n",
        "            #print(\"returned\")\n",
        "            return factual_ret[self._mlmodel.feature_input_order]\n",
        "        # Sort leaf nodes by distance\n",
        "        leaf_nodes_with_label = sorted(leaf_nodes_with_label, key=lambda x: len(leaf_node_n.compare_node(x)))\n",
        "        # Get the counterfactual\n",
        "        returned_neighbor = -1\n",
        "        counter_taregt = factual[self._mlmodel.data.target]*-1 +1\n",
        "        #print(\"Searching for Neighbor....\")\n",
        "        # print(\"Start with option A: {}\".format(nearest_leaf_node))\n",
        "        #print(second_nearest_node)\n",
        "        # If len of leaf_nodes_with_label is 1, the all the max_search on the nearest_leaf_node\n",
        "        # If len of leaf_nodes_with_label is 2, the max_search/7 on the nearest_leaf_node and max_search/3 on the second_nearest_node\n",
        "        # If len of leaf_nodes_with_label is 3, the max_search/5 on the nearest_leaf_node and max_search/3 on the second_nearest_node and max_search/2 on the third_nearest_node\n",
        "        if len(leaf_nodes_with_label) == 1:\n",
        "            max_searchs = [self.hyperparams[\"tree_params\"][\"max_search\"]]\n",
        "        else: #elif len(leaf_nodes_with_label) == 2:\n",
        "            max_searchs = [self.hyperparams[\"tree_params\"][\"max_search\"]*0.7, self.hyperparams[\"tree_params\"][\"max_search\"]*0.3]\n",
        "        #else:\n",
        "        #    max_searchs = [self.hyperparams[\"tree_params\"][\"max_search\"]*0.5, self.hyperparams[\"tree_params\"][\"max_search\"]*0.3, self.hyperparams[\"tree_params\"][\"max_search\"]*0.2]\n",
        "        # map max_search to int values while rounding up to the nearest int\n",
        "        max_searchs = [int(round(x)) for x in max_searchs]\n",
        "        # Loop over max_search\n",
        "        for rank_node, max_search_i in enumerate(max_searchs):\n",
        "            number_searchs = 0\n",
        "            nearest_leaf_node = leaf_nodes_with_label[rank_node]\n",
        "            #print(\"Searching for Neighbor.... {}, {}\".format(rank_node, max_search_i))\n",
        "            while number_searchs < max_search_i and returned_neighbor is -1:\n",
        "                # if number_searchs is 30% of max_search\n",
        "                if number_searchs < max_search_i*0.3:\n",
        "                    sigma = 20\n",
        "                    gamma = 0\n",
        "                # if number_searchs is 60% of max_search\n",
        "                elif number_searchs < max_search_i*0.6:\n",
        "                    sigma = 10\n",
        "                    gamma = 20\n",
        "                # if number_searchs is 80% of max_search\n",
        "                elif number_searchs < max_search_i*0.8:\n",
        "                    sigma = 1\n",
        "                    gamma = 10\n",
        "                # if number_searchs is 80% of max_search\n",
        "                elif number_searchs < max_search_i*0.9:\n",
        "                    sigma = 0.2\n",
        "                    gamma = 1\n",
        "                # if number_searchs is 90% of max_search\n",
        "                else:\n",
        "                    sigma = 1\n",
        "                    gamma = 0\n",
        "\n",
        "                neighbor = nearest_leaf_node.generate_point(factual.copy(), data_catalog = self.data_catalog, sigma = sigma, gamma = gamma)\n",
        "                if counter_taregt == np.argmax(self.mlmodel.predict_proba(pd.DataFrame([neighbor[self.mlmodel.feature_input_order]]))):\n",
        "                    returned_neighbor = neighbor\n",
        "                    break\n",
        "                number_searchs += 1\n",
        "            if returned_neighbor is not -1:\n",
        "                break\n",
        "        # If no neighbor is found, return the factual\n",
        "        if returned_neighbor is -1:\n",
        "            #print(\"No neighbor was found\")\n",
        "            factual_ret = factual\n",
        "            factual_ret[self._mlmodel.feature_input_order] = np.nan\n",
        "            #print(\"returned\")\n",
        "            return factual_ret[self._mlmodel.feature_input_order]\n",
        "        return returned_neighbor[self._mlmodel.feature_input_order]\n"
      ],
      "metadata": {
        "id": "ImMBjT2iQPWk"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEMP_VAE = tbtest.vae"
      ],
      "metadata": {
        "id": "LIL1UsLWUr3L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from carla import MLModelCatalog\n",
        "from carla.data.catalog import OnlineCatalog\n",
        "from carla.recourse_methods import GrowingSpheres\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "# load a catalog dataset\n",
        "data_name = \"adult\"\n",
        "dataset = OnlineCatalog(data_name)\n",
        "data_train, data_test = train_test_split(dataset.df, test_size=0.2)\n",
        "\n",
        "class MyData:\n",
        "  def __init__(self, data, target):\n",
        "    self.df = data\n",
        "    self.target = target\n",
        "trainData = MyData(data_train.copy(), dataset.target)\n",
        "\n",
        "# load artificial neural network from catalog\n",
        "model = MLModelCatalog(dataset, 'ann')\n",
        "factuals = data_test.head(50)"
      ],
      "metadata": {
        "id": "V4WllcD0t3t6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47425635-d4b6-4eb4-bd3e-f1dcb273bd25"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARNING] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor [deprecation.py new_func]\n",
            "[WARNING] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor [deprecation.py new_func]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check our data catalog\n",
        "col_n = dataset.df.columns\n",
        "catalog_n = dataset.catalog\n",
        "# Initialize new catalog\n",
        "new_catalog_n = {'target': 'income', 'continuous': [], 'categorical': [], 'immutable': []}\n",
        "# Map continuous values\n",
        "for col_i in col_n:\n",
        "    col = col_i.split('_')[0]\n",
        "    if col == dataset.target:\n",
        "        continue\n",
        "    if col in catalog_n['immutable']:\n",
        "        new_catalog_n['immutable'].append(col_i)\n",
        "    if col in catalog_n['continuous']:\n",
        "        new_catalog_n['continuous'].append(col_i)\n",
        "    elif col in catalog_n['categorical']:\n",
        "        new_catalog_n['categorical'].append(col_i)\n",
        "    else:\n",
        "        assert False, 'Column not found in catalog {}'.format(col_i)\n",
        "\n",
        "# Assert if new_catalog_n is not same shape as catalog_n\n",
        "assert len(new_catalog_n['continuous']) == len(catalog_n['continuous']), 'Continuous values not same shape'\n",
        "assert len(new_catalog_n['categorical']) == len(catalog_n['categorical']), 'Categorical values not same shape'\n",
        "assert len(new_catalog_n['immutable']) == len(catalog_n['immutable']), 'Immutable values not same shape'\n",
        "# For each continous value get the std, mean, and min/max and plug them in the new catalog['continuous_stats']\n",
        "new_catalog_n['continuous_stats'] = {}\n",
        "for col_i in new_catalog_n['continuous']:\n",
        "    new_catalog_n['continuous_stats'][col_i] = {}\n",
        "    new_catalog_n['continuous_stats'][col_i]['std'] = data_train[col_i].std()\n",
        "    new_catalog_n['continuous_stats'][col_i]['mean'] = data_train[col_i].mean()\n",
        "    new_catalog_n['continuous_stats'][col_i]['min'] = data_train[col_i].min()\n",
        "    new_catalog_n['continuous_stats'][col_i]['max'] = data_train[col_i].max()\n"
      ],
      "metadata": {
        "id": "hm9OzZqJd8kw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hpr = {\n",
        "      \"data_name\": \"data_name\",\n",
        "      \"n_search_samples\": 300,\n",
        "      \"p_norm\": 1,\n",
        "      \"step\": 0.1,\n",
        "      \"max_iter\": 10,\n",
        "      \"clamp\": True,\n",
        "      \"binary_cat_features\": True,\n",
        "      \"vae_params\": {\n",
        "          \"layers\": [len(model.feature_input_order), 20, 10, 7],\n",
        "          \"train\": True,\n",
        "          \"lambda_reg\": 1e-6,\n",
        "          \"epochs\": 5,\n",
        "          \"lr\": 1e-3,\n",
        "          \"batch_size\": 16,\n",
        "      },\n",
        "      \"tree_params\": {\n",
        "          \"min_entries_per_label\": 1000,\n",
        "          \"grid_search_jobs\": -1,\n",
        "          \"min_weight_gini\": 100, # set to 0.5 since here both class have same prob,\n",
        "          \"max_search\" : 100,\n",
        "          \"grid_search\": {\n",
        "                \"cv\": 1,\n",
        "                \"splitter\": [\"best\"],\n",
        "                \"criterion\": [\"gini\"],\n",
        "                \"max_depth\": [6],\n",
        "                \"min_samples_split\": [2],\n",
        "                \"min_samples_leaf\": [1],\n",
        "                \"max_features\": [None] #Note changing this will result in removing features that we might want to keep\n",
        "          }\n",
        "      }\n",
        "    }\n",
        "# Conditions Violations add it at the beginning before going to sampling\n",
        "# Immutable, e.g. gender imutable all directions\n",
        "# Age should be greater than x okay, bs decrease \n",
        "# Our method take care of those imutability\n",
        "# \n",
        "# Decision tree validation train \n",
        "# DOn't cross. validation\n",
        "# Don't retrain\n",
        "# Just to retrain\n",
        "#julia here\n",
        "tbtest = TreeBasedContrastiveExplanation(trainData, model, hpr, data_catalog= new_catalog_n)\n",
        "\n",
        "#### NEW 2 BENCHMARKING\n",
        "benchmark = Benchmark(model, tbtest, data_test.head(10).copy().reset_index(drop=True))\n",
        "distances = benchmark.compute_distances()\n",
        "benchmark.run_benchmark().head(1)"
      ],
      "metadata": {
        "id": "T5o6qaF7QlVZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "c0f3c8e7-4dc5-42d3-9894-b17200101a35"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Distance_1  Distance_2  Distance_3  Distance_4  Constraint_Violation  \\\n",
              "0         1.0    0.049349    0.002435    0.049349                     0   \n",
              "\n",
              "   Redundancy  y-Nearest-Neighbours  Success_Rate  Average_Time  \n",
              "0           0                   0.4           0.8      0.500715  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53a78ea9-9c86-4dc7-abd2-3db3bba0ec39\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Distance_1</th>\n",
              "      <th>Distance_2</th>\n",
              "      <th>Distance_3</th>\n",
              "      <th>Distance_4</th>\n",
              "      <th>Constraint_Violation</th>\n",
              "      <th>Redundancy</th>\n",
              "      <th>y-Nearest-Neighbours</th>\n",
              "      <th>Success_Rate</th>\n",
              "      <th>Average_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.049349</td>\n",
              "      <td>0.002435</td>\n",
              "      <td>0.049349</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.500715</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53a78ea9-9c86-4dc7-abd2-3db3bba0ec39')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53a78ea9-9c86-4dc7-abd2-3db3bba0ec39 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53a78ea9-9c86-4dc7-abd2-3db3bba0ec39');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### NEW 2 BENCHMARKING\n",
        "benchmark = Benchmark(model, tbtest, data_test.head(500).copy().reset_index(drop=True))\n",
        "distances = benchmark.compute_distances()\n",
        "benchmark.run_benchmark().head(1).to_markdown()"
      ],
      "metadata": {
        "id": "0BbHfthBkFPp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8fb621cd-40f4-4f2b-d1e7-4ee7c579feee"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|    |   Distance_1 |   Distance_2 |   Distance_3 |   Distance_4 |   Constraint_Violation |   Redundancy |   y-Nearest-Neighbours |   Success_Rate |   Average_Time |\\n|---:|-------------:|-------------:|-------------:|-------------:|-----------------------:|-------------:|-----------------------:|---------------:|---------------:|\\n|  0 |            1 |    0.0473877 |   0.00224559 |    0.0473877 |                      0 |            0 |                 0.2625 |           0.64 |       0.543212 |'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark.run_benchmark().head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "syv93WHcCSQq",
        "outputId": "f4906bed-ad1a-4fc2-ad56-bdd8950cd08e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Distance_1  Distance_2  Distance_3  Distance_4  Constraint_Violation  \\\n",
              "0         1.0    0.047388    0.002246    0.047388                     0   \n",
              "\n",
              "   Redundancy  y-Nearest-Neighbours  Success_Rate  Average_Time  \n",
              "0           0                0.2625          0.64      0.543212  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e1e7e52-7441-4ee2-9078-26ecb5fe540a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Distance_1</th>\n",
              "      <th>Distance_2</th>\n",
              "      <th>Distance_3</th>\n",
              "      <th>Distance_4</th>\n",
              "      <th>Constraint_Violation</th>\n",
              "      <th>Redundancy</th>\n",
              "      <th>y-Nearest-Neighbours</th>\n",
              "      <th>Success_Rate</th>\n",
              "      <th>Average_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.047388</td>\n",
              "      <td>0.002246</td>\n",
              "      <td>0.047388</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2625</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.543212</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e1e7e52-7441-4ee2-9078-26ecb5fe540a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e1e7e52-7441-4ee2-9078-26ecb5fe540a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e1e7e52-7441-4ee2-9078-26ecb5fe540a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs = GrowingSpheres(model)\n",
        "benchmark = Benchmark(model, gs, data_test.head(500).copy().reset_index(drop=True))\n",
        "distances = benchmark.compute_distances()\n",
        "benchmark.run_benchmark().head(1)"
      ],
      "metadata": {
        "id": "mJllIajWCn1l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "d467ec15-4014-4bad-9a32-a6ab537c5ca8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Distance_1  Distance_2  Distance_3  Distance_4  Constraint_Violation  \\\n",
              "0         5.0    0.283595    0.022528    0.128064                     0   \n",
              "\n",
              "   Redundancy  y-Nearest-Neighbours  Success_Rate  Average_Time  \n",
              "0           4              0.163591         0.802      0.020714  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-694b1201-9617-4f7f-9a39-a8e93e002321\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Distance_1</th>\n",
              "      <th>Distance_2</th>\n",
              "      <th>Distance_3</th>\n",
              "      <th>Distance_4</th>\n",
              "      <th>Constraint_Violation</th>\n",
              "      <th>Redundancy</th>\n",
              "      <th>y-Nearest-Neighbours</th>\n",
              "      <th>Success_Rate</th>\n",
              "      <th>Average_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.283595</td>\n",
              "      <td>0.022528</td>\n",
              "      <td>0.128064</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.163591</td>\n",
              "      <td>0.802</td>\n",
              "      <td>0.020714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-694b1201-9617-4f7f-9a39-a8e93e002321')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-694b1201-9617-4f7f-9a39-a8e93e002321 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-694b1201-9617-4f7f-9a39-a8e93e002321');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = setup[\"dice\"][\"hyperparams\"]\n",
        "dice = Dice(model, hyperparams)\n",
        "benchmark = Benchmark(model, dice, data_test.head(500).copy().reset_index(drop=True))\n",
        "distances = benchmark.compute_distances()\n",
        "benchmark.run_benchmark().head(1)"
      ],
      "metadata": {
        "id": "15B_x2UB2hNQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "bfdaba34-7937-4521-8eb8-4c15af99eddc"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Distance_1  Distance_2  Distance_3  Distance_4  Constraint_Violation  \\\n",
              "0         1.0    0.376118    0.141465    0.376118                     0   \n",
              "\n",
              "   Redundancy  y-Nearest-Neighbours  Success_Rate  Average_Time  \n",
              "0           0                0.6628           1.0      0.128937  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0eba1a21-952a-42f7-9185-bc435c3047ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Distance_1</th>\n",
              "      <th>Distance_2</th>\n",
              "      <th>Distance_3</th>\n",
              "      <th>Distance_4</th>\n",
              "      <th>Constraint_Violation</th>\n",
              "      <th>Redundancy</th>\n",
              "      <th>y-Nearest-Neighbours</th>\n",
              "      <th>Success_Rate</th>\n",
              "      <th>Average_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.376118</td>\n",
              "      <td>0.141465</td>\n",
              "      <td>0.376118</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6628</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.128937</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0eba1a21-952a-42f7-9185-bc435c3047ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0eba1a21-952a-42f7-9185-bc435c3047ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0eba1a21-952a-42f7-9185-bc435c3047ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = setup[\"face_knn\"][\"hyperparams\"]\n",
        "face = Face(model, hyperparams)\n",
        "benchmark = Benchmark(model, face, data_test.head(500).copy().reset_index(drop=True))\n",
        "distances = benchmark.compute_distances()\n",
        "benchmark.run_benchmark().head()"
      ],
      "metadata": {
        "id": "mbRNKKMS4U7L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "e0a882e5-c71c-4d92-fbfc-e984a1ea5afa"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Distance_1  Distance_2  Distance_3  Distance_4  Constraint_Violation  \\\n",
              "0         3.0    0.134774    0.006125    0.051781                     1   \n",
              "1         7.0    3.536217    3.100423    1.000000                     1   \n",
              "2         7.0    3.666194    3.162509    1.000000                     1   \n",
              "3         5.0    0.894451    0.182147    0.266667                     1   \n",
              "4         5.0    1.451391    1.089023    1.000000                     1   \n",
              "\n",
              "   Redundancy  y-Nearest-Neighbours  Success_Rate  Average_Time  \n",
              "0           2                0.5856           1.0      6.058938  \n",
              "1           4                   NaN           NaN           NaN  \n",
              "2           3                   NaN           NaN           NaN  \n",
              "3           1                   NaN           NaN           NaN  \n",
              "4           3                   NaN           NaN           NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4f25058-0446-405e-9d04-0ed8477e9bed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Distance_1</th>\n",
              "      <th>Distance_2</th>\n",
              "      <th>Distance_3</th>\n",
              "      <th>Distance_4</th>\n",
              "      <th>Constraint_Violation</th>\n",
              "      <th>Redundancy</th>\n",
              "      <th>y-Nearest-Neighbours</th>\n",
              "      <th>Success_Rate</th>\n",
              "      <th>Average_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.134774</td>\n",
              "      <td>0.006125</td>\n",
              "      <td>0.051781</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.5856</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.058938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.0</td>\n",
              "      <td>3.536217</td>\n",
              "      <td>3.100423</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.0</td>\n",
              "      <td>3.666194</td>\n",
              "      <td>3.162509</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.894451</td>\n",
              "      <td>0.182147</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.451391</td>\n",
              "      <td>1.089023</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4f25058-0446-405e-9d04-0ed8477e9bed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4f25058-0446-405e-9d04-0ed8477e9bed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4f25058-0446-405e-9d04-0ed8477e9bed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from carla.recourse_methods import CCHVAE\n",
        "hyperparams = setup['cchvae'][\"hyperparams\"]\n",
        "hyperparams[\"data_name\"] = data_name\n",
        "hyperparams[\"vae_params\"][\"layers\"] = [\n",
        "    len(model.feature_input_order)\n",
        "] + hyperparams[\"vae_params\"][\"layers\"]\n",
        "cchvae = CCHVAE(model, hyperparams)\n",
        "benchmark = Benchmark(cchvae, face, data_test.head(500).copy().reset_index(drop=True))\n",
        "distances = benchmark.compute_distances()\n",
        "benchmark.run_benchmark().head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGePgmqLL19-",
        "outputId": "abe5cedc-3ba7-42b6-8e9d-18e8f6e8dd2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Start training of Variational Autoencoder... [models.py fit]\n",
            "[INFO] [Epoch: 0/5] [objective: 0.379] [models.py fit]\n",
            "[INFO] [ELBO train: 0.38] [models.py fit]\n",
            "[INFO] [ELBO train: 0.13] [models.py fit]\n",
            "[INFO] [ELBO train: 0.12] [models.py fit]\n",
            "[INFO] [ELBO train: 0.12] [models.py fit]\n",
            "[INFO] [ELBO train: 0.12] [models.py fit]\n",
            "[INFO] ... finished training of Variational Autoencoder. [models.py fit]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from carla.recourse_methods import CCHVAE\n",
        "hyperparams = setup[method][\"hyperparams\"]\n",
        "hyperparams[\"data_name\"] = data_name\n",
        "hyperparams[\"vae_params\"][\"layers\"] = [\n",
        "    len(model.feature_input_order)\n",
        "] + hyperparams[\"vae_params\"][\"layers\"]\n",
        "cchvae = CCHVAE(model, hyperparams)\n",
        "benchmark = Benchmark(cchvae, face, data_test.head(500).copy().reset_index(drop=True))\n",
        "distances = benchmark.compute_distances()\n",
        "benchmark.run_benchmark().head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLyVzZVuQF9U",
        "outputId": "caf38fda-3743-4221-d8a0-00dbce1e9363"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "777"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}